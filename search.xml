<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>计算机网络-面试常见问题2</title>
      <link href="/2023/03/25/2023-03-25-ji-suan-ji-wang-luo-mian-shi-chang-jian-wen-ti-2/"/>
      <url>/2023/03/25/2023-03-25-ji-suan-ji-wang-luo-mian-shi-chang-jian-wen-ti-2/</url>
      
        <content type="html"><![CDATA[<h1 id="面试常见问题2"><a href="#面试常见问题2" class="headerlink" title="面试常见问题2"></a>面试常见问题2</h1><h2 id="1-HTTP常见的状态码有哪些？"><a href="#1-HTTP常见的状态码有哪些？" class="headerlink" title="1. HTTP常见的状态码有哪些？"></a>1. HTTP常见的状态码有哪些？</h2><p>常见状态码：</p><ul><li>200：服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。</li><li>301 ： (永久移动) 请求的网页已永久移动到新位置。 服务器返回此响应(对 GET 或 HEAD 请求的响应)时，会自动将请求者转到新位置。</li><li>302：(临时移动) 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。</li><li>400 ：客户端请求有语法错误，不能被服务器所理解。</li><li>403 ：服务器收到请求，但是拒绝提供服务。</li><li>404 ：(未找到) 服务器找不到请求的网页。</li><li>500： (服务器内部错误) 服务器遇到错误，无法完成请求。</li></ul><p>状态码开头代表类型：</p><p><img src="http://blog-img.coolsen.cn/img/image-20210525114439748.png"></p><h2 id="2-状态码301和302的区别是什么？"><a href="#2-状态码301和302的区别是什么？" class="headerlink" title="2. 状态码301和302的区别是什么？"></a>2. 状态码301和302的区别是什么？</h2><p><strong>共同点</strong>：301和302状态码都表示重定向，就是说浏览器在拿到服务器返回的这个状态码后会自动跳转到一个新的URL地址，这个地址可以从响应的Location首部中获取（<strong>用户看到的效果就是他输入的地址A瞬间变成了另一个地址B</strong>）。<br><strong>不同点</strong>：301表示旧地址A的资源已经被永久地移除了(这个资源不可访问了)，搜索引擎在抓取新内容的同时也将旧的网址交换为重定向之后的网址；302表示旧地址A的资源还在（仍然可以访问），这个重定向只是临时地从旧地址A跳转到地址B，搜索引擎会抓取新的内容而保存旧的网址。 SEO中302好于301。</p><p><strong>补充，重定向原因</strong>：</p><ol><li>网站调整（如改变网页目录结构）；</li><li>网页被移到一个新地址；</li><li>网页扩展名改变(如应用需要把.php改成.Html或.shtml)。</li></ol><h2 id="3-HTTP-常用的请求方式？"><a href="#3-HTTP-常用的请求方式？" class="headerlink" title="3. HTTP 常用的请求方式？"></a>3. HTTP 常用的请求方式？</h2><table><thead><tr><th>方法</th><th>作用</th></tr></thead><tbody><tr><td>GET</td><td>获取资源</td></tr><tr><td>POST</td><td>传输实体主体</td></tr><tr><td>PUT</td><td>上传文件</td></tr><tr><td>DELETE</td><td>删除文件</td></tr><tr><td>HEAD</td><td>和GET方法类似，但只返回报文首部，不返回报文实体主体部分</td></tr><tr><td>PATCH</td><td>对资源进行部分修改</td></tr><tr><td>OPTIONS</td><td>查询指定的URL支持的方法</td></tr><tr><td>CONNECT</td><td>要求用隧道协议连接代理</td></tr><tr><td>TRACE</td><td>服务器会将通信路径返回给客户端</td></tr></tbody></table><p>为了方便记忆，可以将PUT、DELETE、POST、GET理解为客户端对服务端的增删改查。</p><ul><li>PUT：上传文件，向服务器添加数据，可以看作增</li><li>DELETE：删除文件</li><li>POST：传输数据，向服务器提交数据，对服务器数据进行更新。</li><li>GET：获取资源，查询服务器资源</li></ul><h2 id="4-GET请求和POST请求的区别？"><a href="#4-GET请求和POST请求的区别？" class="headerlink" title="4. GET请求和POST请求的区别？"></a>4. GET请求和POST请求的区别？</h2><p><strong>使用上的区别</strong>：</p><ul><li><p>GET使用URL或Cookie传参，而POST将数据放在BODY中”，这个是因为HTTP协议用法的约定。</p></li><li><p>GET方式提交的数据有长度限制，则POST的数据则可以非常大”，这个是因为它们使用的操作系统和浏览器设置的不同引起的区别。</p></li><li><p>POST比GET安全，因为数据在地址栏上不可见”，这个说法没毛病，但依然不是GET和POST本身的区别。</p></li></ul><p><strong>本质区别</strong></p><p>GET和POST最大的区别主要是GET请求是幂等性的，POST请求不是。这个是它们本质区别。</p><p>幂等性是指一次和多次请求某一个资源应该具有同样的副作用。简单来说意味着对同一URL的多个请求应该返回同样的结果。</p><h2 id="5-解释一下HTTP长连接和短连接？"><a href="#5-解释一下HTTP长连接和短连接？" class="headerlink" title="5. 解释一下HTTP长连接和短连接？"></a>5. 解释一下HTTP长连接和短连接？</h2><p><strong>在HTTP/1.0中，默认使用的是短连接</strong>。也就是说，浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。如果客户端浏览器访问的某个HTML或其他类型的 Web页中包含有其他的Web资源，如JavaScript文件、图像文件、CSS文件等；当浏览器每遇到这样一个Web资源，就会建立一个HTTP会话。</p><p>但从 <strong>HTTP/1.1起，默认使用长连接</strong>，用以保持连接特性。使用长连接的HTTP协议，会在响应头有加入这行代码：<code>Connection:keep-alive</code></p><p>在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的 TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接要客户端和服务端都支持长连接。</p><p><strong>HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。</strong></p><h2 id="6-HTTP请求报文和响应报文的格式？"><a href="#6-HTTP请求报文和响应报文的格式？" class="headerlink" title="6. HTTP请求报文和响应报文的格式？"></a>6. HTTP请求报文和响应报文的格式？</h2><p><strong>请求报文格式</strong>：</p><ol><li>请求行（请求方法+URI协议+版本）</li><li>请求头部</li><li>空行</li><li>请求主体</li></ol><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup">GET/sample.jspHTTP/1.1 请求行Accept:image/gif.image/jpeg, 请求头部Accept-Language:zh-cnConnection:Keep-AliveHost:localhostUser-Agent:Mozila/4.0(compatible;MSIE5.01;Window NT5.0)Accept-Encoding:gzip,deflateusername=jinqiao&amp;password=1234 请求主体<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>响应报文</strong>：</p><ol><li>状态行（版本+状态码+原因短语）</li><li>响应首部</li><li>空行</li><li>响应主体</li></ol><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup">HTTP/1.1 200 OKServer:Apache Tomcat/5.0.12Date:Mon,6Oct2003 13:23:42 GMTContent-Length:112<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>html</span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>head</span><span class="token punctuation">&gt;</span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>title</span><span class="token punctuation">&gt;</span></span>HTTP响应示例<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>title</span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>head</span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>body</span><span class="token punctuation">&gt;</span></span>        Hello HTTP!    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>body</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>html</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="7-HTTP1-0和HTTP1-1的区别"><a href="#7-HTTP1-0和HTTP1-1的区别" class="headerlink" title="7. HTTP1.0和HTTP1.1的区别?"></a>7. HTTP1.0和HTTP1.1的区别?</h2><ul><li><p><strong>长连接</strong>：HTTP 1.1支持长连接（Persistent Connection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启<code>Connection： keep-alive</code>，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。</p></li><li><p><strong>缓存处理</strong>：在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略，可供选择的缓存头来控制缓存策略。</p></li><li><p><strong>带宽优化及网络连接的使用</strong>：HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。</p></li><li><p><strong>错误通知的管理</strong>：在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。</p></li><li><p><strong>Host头处理</strong>：在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。</p></li></ul><h2 id="8-HTTP1-1和-HTTP2-0的区别？"><a href="#8-HTTP1-1和-HTTP2-0的区别？" class="headerlink" title="8. HTTP1.1和 HTTP2.0的区别？"></a>8. HTTP1.1和 HTTP2.0的区别？</h2><p>HTTP2.0相比HTTP1.1支持的特性：</p><ul><li><p><strong>新的二进制格式</strong>：HTTP1.1的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认0和1的组合。基于这种考虑HTTP2.0的协议解析决定采用二进制格式，实现方便且健壮。</p></li><li><p><strong>多路复用</strong>，即连接共享，即每一个request都是用作连接共享机制的。一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。</p></li><li><p><strong>头部压缩</strong>，HTTP1.1的头部（header）带有大量信息，而且每次都要重复发送；HTTP2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。</p></li><li><p><strong>服务端推送</strong>：服务器除了对最初请求的响应外，服务器还可以额外的向客户端推送资源，而无需客户端明确的请求。</p></li></ul><h2 id="9-HTTP-与-HTTPS-的区别？"><a href="#9-HTTP-与-HTTPS-的区别？" class="headerlink" title="9. HTTP 与 HTTPS 的区别？"></a>9. HTTP 与 HTTPS 的区别？</h2><table><thead><tr><th align="center"></th><th align="center">HTTP</th><th>HTTPS</th></tr></thead><tbody><tr><td align="center">端口</td><td align="center">80</td><td>443</td></tr><tr><td align="center">安全性</td><td align="center">无加密，安全性较差</td><td>有加密机制，安全性较高</td></tr><tr><td align="center">资源消耗</td><td align="center">较少</td><td>由于加密处理，资源消耗更多</td></tr><tr><td align="center">是否需要证书</td><td align="center">不需要</td><td>需要</td></tr><tr><td align="center">协议</td><td align="center">运行在TCP协议之上</td><td>运行在SSL协议之上，SSL运行在TCP协议之上</td></tr></tbody></table><h2 id="10-HTTPS-的优缺点"><a href="#10-HTTPS-的优缺点" class="headerlink" title="10. HTTPS 的优缺点?"></a>10. HTTPS 的优缺点?</h2><p><strong>优点</strong>：</p><ul><li><p>安全性：</p><ul><li><p>使用HTTPS协议可认证用户和服务器，确保数据发送到正确的客户机和服务器；</p></li><li><p>HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全，可防止数据在传输过程中不被窃取、改变，确保数据的完整性。</p></li><li><p>HTTPS是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。</p></li></ul></li><li><p>SEO方面：谷歌曾在2014年8月份调整搜索引擎算法，并称“比起同等HTTP网站，采用HTTPS加密的网站在搜索结果中的排名将会更高”。</p></li></ul><p><strong>缺点</strong>：</p><ul><li>在相同网络环境中，HTTPS 相比 HTTP 无论是响应时间还是耗电量都有大幅度上升。</li><li>HTTPS 的安全是有范围的，在黑客攻击、服务器劫持等情况下几乎起不到作用。</li><li>在现有的证书机制下，中间人攻击依然有可能发生。</li><li>HTTPS 需要更多的服务器资源，也会导致成本的升高。</li></ul><h2 id="11-讲一讲HTTPS-的原理？"><a href="#11-讲一讲HTTPS-的原理？" class="headerlink" title="11. 讲一讲HTTPS 的原理？"></a>11. 讲一讲HTTPS 的原理？</h2><p><img src="http://blog-img.coolsen.cn/img/image-20210525160006424.png"></p><blockquote><p>图片来源：<a href="https://segmentfault.com/a/1190000021494676">https://segmentfault.com/a/1190000021494676</a></p></blockquote><p>加密流程按图中的序号分为：</p><ol><li><p>客户端请求 HTTPS 网址，然后连接到 server 的 443 端口 (HTTPS 默认端口，类似于 HTTP 的80端口)。</p></li><li><p>采用 HTTPS 协议的服务器必须要有一套数字 CA (Certification Authority)证书。颁发证书的同时会产生一个私钥和公钥。私钥由服务端自己保存，不可泄漏。公钥则是附带在证书的信息中，可以公开的。证书本身也附带一个证书电子签名，这个签名用来验证证书的完整性和真实性，可以防止证书被篡改。</p></li><li><p>服务器响应客户端请求，将证书传递给客户端，证书包含公钥和大量其他信息，比如证书颁发机构信息，公司信息和证书有效期等。</p></li><li><p>客户端解析证书并对其进行验证。如果证书不是可信机构颁布，或者证书中的域名与实际域名不一致，或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。</p><p>如果证书没有问题，客户端就会从服务器证书中取出服务器的公钥A。然后客户端还会生成一个随机码 KEY，并使用公钥A将其加密。</p></li><li><p>客户端把加密后的随机码 KEY 发送给服务器，作为后面对称加密的密钥。</p></li><li><p>服务器在收到随机码 KEY 之后会使用私钥B将其解密。经过以上这些步骤，客户端和服务器终于建立了安全连接，完美解决了对称加密的密钥泄露问题，接下来就可以用对称加密愉快地进行通信了。</p></li><li><p>服务器使用密钥 (随机码 KEY)对数据进行对称加密并发送给客户端，客户端使用相同的密钥 (随机码 KEY)解密数据。</p></li><li><p>双方使用对称加密愉快地传输所有数据。</p></li></ol><h2 id="12-在浏览器中输入www-baidu-com后执行的全部过程？"><a href="#12-在浏览器中输入www-baidu-com后执行的全部过程？" class="headerlink" title="12. 在浏览器中输入www.baidu.com后执行的全部过程？"></a>12. 在浏览器中输入<a href="http://www.baidu.com后执行的全部过程？">www.baidu.com后执行的全部过程？</a></h2><ol><li><p>域名解析（域名 <a href="http://www.baidu.com/">www.baidu.com </a>变为 ip 地址）。</p><p><strong>浏览器搜索自己的DNS缓存</strong>（维护一张域名与IP的对应表）；若没有，则搜索<strong>操作系统的DNS缓存</strong>（维护一张域名与IP的对应表）；若没有，则搜索操作系统的<strong>hosts文件</strong>（维护一张域名与IP的对应表）。</p><p>若都没有，则找 tcp/ip 参数中设置的首选 dns 服务器，即<strong>本地 dns 服务器</strong>（递归查询），<strong>本地域名服务器查询自己的dns缓存</strong>，如果没有，则进行迭代查询。将本地dns服务器将IP返回给操作系统，同时缓存IP。</p></li><li><p>发起 tcp 的三次握手，建立 tcp 连接。浏览器会以一个随机端口（1024-65535）向服务端的 web 程序 <strong>80</strong> 端口发起 tcp 的连接。</p></li><li><p>建立 tcp 连接后发起 http 请求。</p></li><li><p>服务器响应 http 请求，客户端得到 html 代码。服务器 web 应用程序收到 http 请求后，就开始处理请求，处理之后就返回给浏览器 html 文件。</p></li><li><p>浏览器解析 html 代码，并请求 html 中的资源。</p></li><li><p>浏览器对页面进行渲染，并呈现给用户。</p></li></ol><p>附一张形象的图片：<img src="http://blog-img.coolsen.cn/img/image-20210525172545204.png"></p><h2 id="13-什么是-Cookie-和-Session"><a href="#13-什么是-Cookie-和-Session" class="headerlink" title="13. 什么是 Cookie 和 Session ?"></a>13. 什么是 Cookie 和 Session ?</h2><p><strong>什么是 Cookie</strong></p><p>HTTP Cookie（也叫 Web Cookie或浏览器 Cookie）是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。通常，它用于告知服务端两个请求是否来自同一浏览器，如保持用户的登录状态。Cookie 使基于无状态的 HTTP 协议记录稳定的状态信息成为了可能。</p><p>Cookie 主要用于以下三个方面：</p><ul><li>会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）</li><li>个性化设置（如用户自定义设置、主题等）</li><li>浏览器行为跟踪（如跟踪分析用户行为等）</li></ul><p><strong>什么是 Session</strong></p><p>Session 代表着服务器和客户端一次会话的过程。Session 对象存储特定用户会话所需的属性及配置信息。这样，当用户在应用程序的 Web 页之间跳转时，存储在 Session 对象中的变量将不会丢失，而是在整个用户会话中一直存在下去。当客户端关闭会话，或者 Session 超时失效时会话结束。</p><h2 id="14-Cookie-和-Session-是如何配合的呢？"><a href="#14-Cookie-和-Session-是如何配合的呢？" class="headerlink" title="14. Cookie 和 Session 是如何配合的呢？"></a>14. Cookie 和 Session 是如何配合的呢？</h2><p>用户第一次请求服务器的时候，服务器根据用户提交的相关信息，创建对应的 Session ，请求返回时将此 Session 的唯一标识信息 SessionID 返回给浏览器，浏览器接收到服务器返回的 SessionID 信息后，会将此信息存入到 Cookie 中，同时 Cookie 记录此 SessionID 属于哪个域名。</p><p>当用户第二次访问服务器的时候，请求会自动判断此域名下是否存在 Cookie 信息，如果存在自动将 Cookie 信息也发送给服务端，服务端会从 Cookie 中获取 SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到说明用户没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。</p><p>根据以上流程可知，SessionID 是连接 Cookie 和 Session 的一道桥梁，大部分系统也是根据此原理来验证用户登录状态。</p><h2 id="15-Cookie和Session的区别？"><a href="#15-Cookie和Session的区别？" class="headerlink" title="15. Cookie和Session的区别？"></a>15. Cookie和Session的区别？</h2><ul><li>作用范围不同，Cookie 保存在客户端（浏览器），Session 保存在服务器端。</li><li>存取方式的不同，Cookie 只能保存 ASCII，Session 可以存任意数据类型，一般情况下我们可以在 Session 中保持一些常用变量信息，比如说 UserId 等。</li><li>有效期不同，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效。</li><li>隐私策略不同，Cookie 存储在客户端，比较容易遭到不法获取，早期有人将用户的登录名和密码存储在 Cookie 中导致信息被窃取；Session 存储在服务端，安全性相对 Cookie 要好一些。</li><li>存储大小不同， 单个 Cookie 保存的数据不能超过 4K，Session 可存储数据远高于 Cookie。</li></ul><h2 id="16-如何考虑分布式-Session-问题？"><a href="#16-如何考虑分布式-Session-问题？" class="headerlink" title="16. 如何考虑分布式 Session 问题？"></a>16. 如何考虑分布式 Session 问题？</h2><p>在互联网公司为了可以支撑更大的流量，后端往往需要多台服务器共同来支撑前端用户请求，那如果用户在 A 服务器登录了，第二次请求跑到服务 B 就会出现登录失效问题。</p><p>分布式 Session 一般会有以下几种解决方案：</p><ul><li><strong>客户端存储</strong>：直接将信息存储在cookie中，cookie是存储在客户端上的一小段数据，客户端通过http协议和服务器进行cookie交互，通常用来存储一些不敏感信息</li></ul><ul><li><strong>Nginx ip_hash 策略</strong>：服务端使用 Nginx 代理，每个请求按访问 IP 的 hash 分配，这样来自同一 IP 固定访问一个后台服务器，避免了在服务器 A 创建 Session，第二次分发到服务器 B 的现象。</li><li><strong>Session 复制</strong>：任何一个服务器上的 Session 发生改变（增删改），该节点会把这个 Session 的所有内容序列化，然后广播给所有其它节点。</li><li><strong>共享 Session</strong>：服务端无状态话，将用户的 Session 等信息使用缓存中间件（如Redis）来统一管理，保障分发到每一个服务器的响应结果都一致。</li></ul><p>建议采用共享 Session的方案。</p><h2 id="17-什么是DDos攻击？"><a href="#17-什么是DDos攻击？" class="headerlink" title="17. 什么是DDos攻击？"></a>17. 什么是DDos攻击？</h2><p>DDos全称Distributed Denial of Service，分布式拒绝服务攻击。最基本的DOS攻击过程如下：</p><ol><li>客户端向服务端发送请求链接数据包。</li><li>服务端向客户端发送确认数据包。</li><li>客户端不向服务端发送确认数据包，服务器一直等待来自客户端的确认</li></ol><p>DDoS则是采用分布式的方法，通过在网络上占领多台“肉鸡”，用多台计算机发起攻击。</p><p>DOS攻击现在基本没啥作用了，因为服务器的性能都很好，而且是多台服务器共同作用，1V1的模式黑客无法占上风。对于DDOS攻击，预防方法有：</p><ul><li><strong>减少SYN timeout时间</strong>。在握手的第三步，服务器会等待30秒-120秒的时间，减少这个等待时间就能释放更多的资源。</li><li><strong>限制同时打开的SYN半连接数目。</strong></li></ul><h2 id="18-什么是XSS攻击？"><a href="#18-什么是XSS攻击？" class="headerlink" title="18. 什么是XSS攻击？"></a>18. 什么是XSS攻击？</h2><p>XSS也称 cross-site scripting，<strong>跨站脚本</strong>。这种攻击是<strong>由于服务器将攻击者存储的数据原原本本地显示给其他用户所致的</strong>。比如一个存在XSS漏洞的论坛，用户发帖时就可以引入<strong>带有＜script＞标签的代码</strong>，导致恶意代码的执行。</p><p>预防措施有：</p><ul><li>前端：过滤。</li><li>后端：转义，比如go自带的处理器就具有转义功能。</li></ul><h2 id="19-SQL注入是什么，如何避免SQL注入？"><a href="#19-SQL注入是什么，如何避免SQL注入？" class="headerlink" title="19. SQL注入是什么，如何避免SQL注入？"></a>19. SQL注入是什么，如何避免SQL注入？</h2><p>SQL 注入就是在用户输入的字符串中加入 SQL 语句，如果在设计不良的程序中忽略了检查，那么这些注入进去的 SQL 语句就会被数据库服务器误认为是正常的 SQL 语句而运行，攻击者就可以执行计划外的命令或访问未被授权的数据。</p><p><strong>SQL注入的原理主要有以下 4 点</strong></p><ul><li>恶意拼接查询</li><li>利用注释执行非法命令</li><li>传入非法参数</li><li>添加额外条件</li></ul><p><strong>避免SQL注入的一些方法</strong>：</p><ul><li>限制数据库权限，给用户提供仅仅能够满足其工作的最低权限。</li><li>对进入数据库的特殊字符（’”\尖括号&amp;*;等）转义处理。</li><li>提供参数化查询接口，不要直接使用原生SQL。</li></ul><h2 id="20-负载均衡算法有哪些？"><a href="#20-负载均衡算法有哪些？" class="headerlink" title="20. 负载均衡算法有哪些？"></a>20. 负载均衡算法有哪些？</h2><p>多台服务器以对称的方式组成一个服务器集合，每台服务器都具有等价的地位，能互相分担负载。</p><ul><li>轮询法：将请求按照顺序轮流的分配到服务器上。大锅饭，不能发挥某些高性能服务器的优势。</li><li>随机法：随机获取一台，和轮询类似。</li><li>哈希法：通过ip地址哈希化来确定要选择的服务器编号。好处是,每次客户端访问的服务器都是同一个服务器，能很好地利用session或者cookie。</li><li>加权轮询：根据服务器性能不同加权。</li></ul><h2 id="巨人的肩膀"><a href="#巨人的肩膀" class="headerlink" title="巨人的肩膀"></a>巨人的肩膀</h2><p><a href="https://juejin.cn/post/6844903890840715271">https://juejin.cn/post/6844903890840715271</a></p><p><a href="https://www.justdojava.com/2019/11/03/Network_interview_question/">https://www.justdojava.com/2019/11/03/Network_interview_question/</a></p><p><a href="https://juejin.cn/post/6844903489596833800">https://juejin.cn/post/6844903489596833800</a></p><p><a href="https://segmentfault.com/a/1190000021494676">https://segmentfault.com/a/1190000021494676</a></p><p><a href="https://jiangren.work/2020/02/16/">https://jiangren.work/2020/02/16/</a></p><p><a href="https://www.cnblogs.com/ityouknow/p/10856177.html">https://www.cnblogs.com/ityouknow/p/10856177.html</a></p><p><a href="https://juejin.cn/post/6844903575684907016">https://juejin.cn/post/6844903575684907016</a></p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 知识总结 </tag>
            
            <tag> S6复习 </tag>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机网络-面试常见问题1</title>
      <link href="/2023/03/25/2022-09-25-ji-suan-ji-wang-luo-mian-shi-chang-jian-wen-ti-1/"/>
      <url>/2023/03/25/2022-09-25-ji-suan-ji-wang-luo-mian-shi-chang-jian-wen-ti-1/</url>
      
        <content type="html"><![CDATA[<h1 id="面试常见问题"><a href="#面试常见问题" class="headerlink" title="面试常见问题"></a>面试常见问题</h1><h2 id="1-计算机网络的各层协议及作用？"><a href="#1-计算机网络的各层协议及作用？" class="headerlink" title="1. 计算机网络的各层协议及作用？"></a>1. 计算机网络的各层协议及作用？</h2><p>计算机网络体系可以大致分为一下三种，OSI七层模型、TCP/IP四层模型和五层模型。</p><ul><li>OSI七层模型：大而全，但是比较复杂、而且是先有了理论模型，没有实际应用。</li><li>TCP/IP四层模型：是由实际应用发展总结出来的，从实质上讲，TCP/IP只有最上面三层，最下面一层没有什么具体内容，TCP/IP参考模型没有真正描述这一层的实现。</li><li>五层模型：五层模型只出现在计算机网络教学过程中，这是对七层模型和四层模型的一个折中，既简洁又能将概念阐述清楚。</li></ul><p><img src="http://blog-img.coolsen.cn/img/image-20210519165421341.png" alt="计算机网络体系结构"></p><p>七层网络体系结构各层的主要功能：</p><ul><li><p>应用层：为应用程序提供交互服务。在互联网中的应用层协议很多，如域名系统DNS，支持万维网应用的HTTP协议，支持电子邮件的SMTP协议等。</p></li><li><p>表示层：主要负责数据格式的转换，如加密解密、转换翻译、压缩解压缩等。</p></li><li><p>会话层：负责在网络中的两节点之间建立、维持和终止通信，如服务器验证用户登录便是由会话层完成的。</p></li><li><p>运输层：有时也译为传输层，向主机进程提供通用的数据传输服务。该层主要有以下两种协议：</p><ul><li>TCP：提供面向连接的、可靠的数据传输服务；</li><li>UDP：提供无连接的、尽最大努力的数据传输服务，但不保证数据传输的可靠性。</li></ul></li><li><p>网络层：选择合适的路由和交换结点，确保数据及时传送。主要包括IP协议。</p></li><li><p>数据链路层：数据链路层通常简称为链路层。将网络层传下来的IP数据包组装成帧，并再相邻节点的链路上传送帧。</p></li><li><p><code>物理层</code>：实现相邻节点间比特流的透明传输，尽可能屏蔽传输介质和通信手段的差异。</p></li></ul><h2 id="2-TCP和UDP的区别？"><a href="#2-TCP和UDP的区别？" class="headerlink" title="2. TCP和UDP的区别？"></a>2. TCP和UDP的区别？</h2><p><strong>对比如下</strong>：</p><table><thead><tr><th align="left"></th><th align="left">UDP</th><th align="left">TCP</th></tr></thead><tbody><tr><td align="left">是否连接</td><td align="left">无连接</td><td align="left">面向连接</td></tr><tr><td align="left">是否可靠</td><td align="left">不可靠传输，不使用流量控制和拥塞控制</td><td align="left">可靠传输，使用流量控制和拥塞控制</td></tr><tr><td align="left">是否有序</td><td align="left">无序</td><td align="left">有序，消息在传输过程中可能会乱序，TCP 会重新排序</td></tr><tr><td align="left">传输速度</td><td align="left">快</td><td align="left">慢</td></tr><tr><td align="left">连接对象个数</td><td align="left">支持一对一，一对多，多对一和多对多交互通信</td><td align="left">只能是一对一通信</td></tr><tr><td align="left">传输方式</td><td align="left">面向报文</td><td align="left">面向字节流</td></tr><tr><td align="left">首部开销</td><td align="left">首部开销小，仅8字节</td><td align="left">首部最小20字节，最大60字节</td></tr><tr><td align="left">适用场景</td><td align="left">适用于实时应用（IP电话、视频会议、直播等）</td><td align="left">适用于要求可靠传输的应用，例如文件传输</td></tr></tbody></table><p><strong>总结</strong>：</p><p>TCP 用于在传输层有必要实现可靠传输的情况，UDP 用于对高速传输和实时性有较高要求的通信。TCP 和 UDP 应该根据应用目的按需使用。</p><h2 id="3-UDP-和-TCP-对应的应用场景是什么？"><a href="#3-UDP-和-TCP-对应的应用场景是什么？" class="headerlink" title="3. UDP 和 TCP 对应的应用场景是什么？"></a>3. UDP 和 TCP 对应的应用场景是什么？</h2><p> TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：</p><ul><li>FTP文件传输</li><li>HTTP / HTTPS</li></ul><p>UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：</p><ul><li>包总量较少的通信，如 DNS 、SNMP等</li><li>视频、音频等多媒体通信</li><li>广播通信</li></ul><p><img src="http://blog-img.coolsen.cn/img/image-20210519180008296.png"></p><h2 id="4-详细介绍一下-TCP-的三次握手机制？"><a href="#4-详细介绍一下-TCP-的三次握手机制？" class="headerlink" title="4. 详细介绍一下 TCP 的三次握手机制？"></a>4. 详细介绍一下 TCP 的三次握手机制？</h2><p><img src="http://blog-img.coolsen.cn/img/image-20210520161056918.png"></p><blockquote><p>图片来自：<a href="https://juejin.cn/post/6844904005315854343">https://juejin.cn/post/6844904005315854343</a></p></blockquote><p>三次握手机制：</p><ul><li><p>第一次握手：客户端请求建立连接，向服务端发送一个<strong>同步报文</strong>（SYN=1），同时选择一个随机数 seq = x 作为<strong>初始序列号</strong>，并进入SYN_SENT状态，等待服务器确认。</p></li><li><p>第二次握手：：服务端收到连接请求报文后，如果同意建立连接，则向客户端发送<strong>同步确认报文</strong>（SYN=1，ACK=1），确认号为 ack = x + 1，同时选择一个随机数 seq = y 作为初始序列号，此时服务器进入SYN_RECV状态。</p></li><li><p>第三次握手：客户端收到服务端的确认后，向服务端发送一个<strong>确认报文</strong>（ACK=1），确认号为 ack = y + 1，序列号为 seq = x + 1，客户端和服务器进入ESTABLISHED状态，完成三次握手。</p></li></ul><p>理想状态下，TCP连接一旦建立，在通信双方中的任何一方主动关闭连接之前，TCP 连接都将被一直保持下去。</p><h2 id="5-为什么需要三次握手，而不是两次？"><a href="#5-为什么需要三次握手，而不是两次？" class="headerlink" title="5. 为什么需要三次握手，而不是两次？"></a>5. 为什么需要三次握手，而不是两次？</h2><p>主要有三个原因：</p><ol><li><p>防止已过期的连接请求报文突然又传送到服务器，因而产生错误和资源浪费。</p><p>在双方两次握手即可建立连接的情况下，假设客户端发送 A 报文段请求建立连接，由于网络原因造成 A 暂时无法到达服务器，服务器接收不到请求报文段就不会返回确认报文段。</p><p>客户端在长时间得不到应答的情况下重新发送请求报文段 B，这次 B 顺利到达服务器，服务器随即返回确认报文并进入 ESTABLISHED 状态，客户端在收到 确认报文后也进入 ESTABLISHED 状态，双方建立连接并传输数据，之后正常断开连接。</p><p>此时姗姗来迟的 A 报文段才到达服务器，服务器随即返回确认报文并进入 ESTABLISHED 状态，但是已经进入 CLOSED 状态的客户端无法再接受确认报文段，更无法进入 ESTABLISHED 状态，这将导致服务器长时间单方面等待，造成资源浪费。</p></li><li><p>三次握手才能让双方均确认自己和对方的发送和接收能力都正常。</p><p>第一次握手：客户端只是发送处请求报文段，什么都无法确认，而服务器可以确认自己的接收能力和对方的发送能力正常；</p><p>第二次握手：客户端可以确认自己发送能力和接收能力正常，对方发送能力和接收能力正常；</p><p>第三次握手：服务器可以确认自己发送能力和接收能力正常，对方发送能力和接收能力正常；</p><p>可见三次握手才能让双方都确认自己和对方的发送和接收能力全部正常，这样就可以愉快地进行通信了。</p></li><li><p>告知对方自己的初始序号值，并确认收到对方的初始序号值。</p><p>TCP 实现了可靠的数据传输，原因之一就是 TCP 报文段中维护了序号字段和确认序号字段，通过这两个字段双方都可以知道在自己发出的数据中，哪些是已经被对方确认接收的。这两个字段的值会在初始序号值得基础递增，如果是两次握手，只有发起方的初始序号可以得到确认，而另一方的初始序号则得不到确认。</p></li></ol><h2 id="6-为什么要三次握手，而不是四次？"><a href="#6-为什么要三次握手，而不是四次？" class="headerlink" title="6. 为什么要三次握手，而不是四次？"></a>6. 为什么要三次握手，而不是四次？</h2><p>因为三次握手已经可以确认双方的发送接收能力正常，双方都知道彼此已经准备好，而且也可以完成对双方初始序号值得确认，也就无需再第四次握手了。</p><ul><li>第一次握手：服务端确认“自己收、客户端发”报文功能正常。</li><li>第二次握手：客户端确认“自己发、自己收、服务端收、客户端发”报文功能正常，客户端认为连接已建立。</li><li>第三次握手：服务端确认“自己发、客户端收”报文功能正常，此时双方均建立连接，可以正常通信。</li></ul><h2 id="7-什么是-SYN洪泛攻击？如何防范？"><a href="#7-什么是-SYN洪泛攻击？如何防范？" class="headerlink" title="7. 什么是 SYN洪泛攻击？如何防范？"></a>7. 什么是 SYN洪泛攻击？如何防范？</h2><p>SYN洪泛攻击属于 DOS 攻击的一种，它利用 TCP 协议缺陷，通过发送大量的半连接请求，耗费 CPU 和内存资源。</p><p>原理：</p><ul><li>在三次握手过程中，服务器发送 <code>[SYN/ACK]</code> 包（第二个包）之后、收到客户端的 <code>[ACK]</code> 包（第三个包）之前的 TCP 连接称为半连接（half-open connect），此时服务器处于 <code>SYN_RECV</code>（等待客户端响应）状态。如果接收到客户端的 <code>[ACK]</code>，则 TCP 连接成功，如果未接受到，则会<strong>不断重发请求</strong>直至成功。</li><li>SYN 攻击的攻击者在短时间内<strong>伪造大量不存在的 IP 地址</strong>，向服务器不断地发送 <code>[SYN]</code> 包，服务器回复 <code>[SYN/ACK]</code> 包，并等待客户的确认。由于源地址是不存在的，服务器需要不断的重发直至超时。</li><li>这些伪造的 <code>[SYN]</code> 包将长时间占用未连接队列，影响了正常的 SYN，导致目标系统运行缓慢、网络堵塞甚至系统瘫痪。</li></ul><p>检测：当在服务器上看到大量的半连接状态时，特别是源 IP 地址是随机的，基本上可以断定这是一次 SYN 攻击。</p><p>防范：</p><ul><li>通过防火墙、路由器等过滤网关防护。</li><li>通过加固 TCP/IP 协议栈防范，如增加最大半连接数，缩短超时时间。</li><li>SYN cookies技术。SYN Cookies 是对 TCP 服务器端的三次握手做一些修改，专门用来防范 SYN 洪泛攻击的一种手段。</li></ul><h2 id="8-三次握手连接阶段，最后一次ACK包丢失，会发生什么？"><a href="#8-三次握手连接阶段，最后一次ACK包丢失，会发生什么？" class="headerlink" title="8. 三次握手连接阶段，最后一次ACK包丢失，会发生什么？"></a>8. 三次握手连接阶段，最后一次ACK包丢失，会发生什么？</h2><p><strong>服务端：</strong></p><ul><li>第三次的ACK在网络中丢失，那么服务端该TCP连接的状态为SYN_RECV,并且会根据 TCP的超时重传机制，会等待3秒、6秒、12秒后重新发送SYN+ACK包，以便客户端重新发送ACK包。</li><li>如果重发指定次数之后，仍然未收到 客户端的ACK应答，那么一段时间后，服务端自动关闭这个连接。</li></ul><p><strong>客户端：</strong></p><p>客户端认为这个连接已经建立，如果客户端向服务端发送数据，服务端将以RST包（Reset，标示复位，用于异常的关闭连接）响应。此时，客户端知道第三次握手失败。</p><h2 id="9-详细介绍一下-TCP-的四次挥手过程？"><a href="#9-详细介绍一下-TCP-的四次挥手过程？" class="headerlink" title="9. 详细介绍一下 TCP 的四次挥手过程？"></a>9. 详细介绍一下 TCP 的四次挥手过程？</h2><p><img src="http://blog-img.coolsen.cn/img/image-20210520180127547.png"></p><blockquote><p>图片来源：<a href="https://juejin.im/post/5ddd1f30e51d4532c42c5abe">https://juejin.im/post/5ddd1f30e51d4532c42c5abe</a></p></blockquote><ul><li><p>第一次挥手：客户端向服务端发送连接释放报文（FIN=1，ACK=1），主动关闭连接，同时等待服务端的确认。</p><ul><li>序列号 seq = u，即客户端上次发送的报文的最后一个字节的序号 + 1</li><li>确认号 ack = k, 即服务端上次发送的报文的最后一个字节的序号 + 1</li></ul></li><li><p>第二次挥手：服务端收到连接释放报文后，立即发出<strong>确认报文</strong>（ACK=1），序列号 seq = k，确认号 ack = u + 1。</p><p>这时 TCP 连接处于半关闭状态，即客户端到服务端的连接已经释放了，但是服务端到客户端的连接还未释放。这表示客户端已经没有数据发送了，但是服务端可能还要给客户端发送数据。</p></li><li><p>第三次挥手：服务端向客户端发送连接释放报文（FIN=1，ACK=1），主动关闭连接，同时等待 A 的确认。</p><ul><li>序列号 seq = w，即服务端上次发送的报文的最后一个字节的序号 + 1。</li><li>确认号 ack = u + 1，与第二次挥手相同，因为这段时间客户端没有发送数据</li></ul></li><li><p>第四次挥手：客户端收到服务端的连接释放报文后，立即发出<strong>确认报文</strong>（ACK=1），序列号 seq = u + 1，确认号为 ack = w + 1。</p><p>此时，客户端就进入了 <code>TIME-WAIT</code> 状态。注意此时客户端到 TCP 连接还没有释放，必须经过 2*MSL（最长报文段寿命）的时间后，才进入 <code>CLOSED</code> 状态。而服务端只要收到客户端发出的确认，就立即进入 <code>CLOSED</code> 状态。可以看到，服务端结束 TCP 连接的时间要比客户端早一些。</p></li></ul><h2 id="10-为什么连接的时候是三次握手，关闭的时候却是四次握手？"><a href="#10-为什么连接的时候是三次握手，关闭的时候却是四次握手？" class="headerlink" title="10. 为什么连接的时候是三次握手，关闭的时候却是四次握手？"></a>10. 为什么连接的时候是三次握手，关闭的时候却是四次握手？</h2><p>服务器在收到客户端的 FIN 报文段后，可能还有一些数据要传输，所以不能马上关闭连接，但是会做出应答，返回 ACK 报文段.</p><p>接下来可能会继续发送数据，在数据发送完后，服务器会向客户单发送 FIN 报文，表示数据已经发送完毕，请求关闭连接。服务器的<strong>ACK和FIN一般都会分开发送</strong>，从而导致多了一次，因此一共需要四次挥手。</p><h2 id="11-为什么客户端的-TIME-WAIT-状态必须等待-2MSL-？"><a href="#11-为什么客户端的-TIME-WAIT-状态必须等待-2MSL-？" class="headerlink" title="11. 为什么客户端的 TIME-WAIT 状态必须等待 2MSL ？"></a>11. 为什么客户端的 TIME-WAIT 状态必须等待 2MSL ？</h2><p>主要有两个原因：</p><ol><li><p>确保 ACK 报文能够到达服务端，从而使服务端正常关闭连接。</p><p>第四次挥手时，客户端第四次挥手的 ACK 报文不一定会到达服务端。服务端会超时重传 FIN/ACK 报文，此时如果客户端已经断开了连接，那么就无法响应服务端的二次请求，这样服务端迟迟收不到 FIN/ACK 报文的确认，就无法正常断开连接。</p><p>MSL 是报文段在网络上存活的最长时间。客户端等待 2MSL 时间，即「客户端 ACK 报文 1MSL 超时 + 服务端 FIN 报文 1MSL 传输」，就能够收到服务端重传的 FIN/ACK 报文，然后客户端重传一次 ACK 报文，并重新启动 2MSL 计时器。如此保证服务端能够正常关闭。</p><p>如果服务端重发的 FIN 没有成功地在 2MSL 时间里传给客户端，服务端则会继续超时重试直到断开连接。</p></li><li><p>防止已失效的连接请求报文段出现在之后的连接中。</p></li></ol><p>   TCP 要求在 2MSL 内不使用相同的序列号。客户端在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以保证本连接持续的时间内产生的所有报文段都从网络中消失。这样就可以使下一个连接中不会出现这种旧的连接请求报文段。或者即使收到这些过时的报文，也可以不处理它。</p><h2 id="12-如果已经建立了连接，但是客户端出现故障了怎么办？"><a href="#12-如果已经建立了连接，但是客户端出现故障了怎么办？" class="headerlink" title="12. 如果已经建立了连接，但是客户端出现故障了怎么办？"></a>12. 如果已经建立了连接，但是客户端出现故障了怎么办？</h2><p>或者说，如果三次握手阶段、四次挥手阶段的包丢失了怎么办？如“服务端重发 FIN丢失”的问题。</p><p>简而言之，通过<strong>定时器 + 超时重试机制</strong>，尝试获取确认，直到最后会自动断开连接。</p><p>具体而言，TCP 设有一个保活计时器。服务器每收到一次客户端的数据，都会重新复位这个计时器，时间通常是设置为 2 小时。若 2 小时还没有收到客户端的任何数据，服务器就开始重试：每隔 75 分钟发送一个探测报文段，若一连发送 10 个探测报文后客户端依然没有回应，那么服务器就认为连接已经断开了。</p><h2 id="13-TIME-WAIT-状态过多会产生什么后果？怎样处理？"><a href="#13-TIME-WAIT-状态过多会产生什么后果？怎样处理？" class="headerlink" title="13. TIME-WAIT 状态过多会产生什么后果？怎样处理？"></a>13. TIME-WAIT 状态过多会产生什么后果？怎样处理？</h2><p>从服务器来讲，短时间内关闭了大量的Client连接，就会造成服务器上出现大量的TIME_WAIT连接，严重消耗着服务器的资源，此时部分客户端就会显示连接不上。</p><p>从客户端来讲，客户端TIME_WAIT过多，就会导致端口资源被占用，因为端口就65536个，被占满就会导致无法创建新的连接。</p><p><strong>解决办法：</strong></p><ul><li><p>服务器可以设置 SO_REUSEADDR 套接字选项来避免 TIME_WAIT状态，此套接字选项告诉内核，即使此端口正忙（处于<br>TIME_WAIT状态），也请继续并重用它。</p></li><li><p>调整系统内核参数，修改/etc/sysctl.conf文件，即修改<code>net.ipv4.tcp_tw_reuse 和 tcp_timestamps</code></p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">net.ipv4.tcp_tw_reuse <span class="token operator">=</span> <span class="token number">1</span> 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；net.ipv4.tcp_tw_recycle <span class="token operator">=</span> <span class="token number">1</span> 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p>强制关闭，发送 RST 包越过TIME_WAIT状态，直接进入CLOSED状态。</p></li></ul><h2 id="14-TIME-WAIT-是服务器端的状态-还是客户端的状态"><a href="#14-TIME-WAIT-是服务器端的状态-还是客户端的状态" class="headerlink" title="14. TIME_WAIT 是服务器端的状态?还是客户端的状态?"></a>14. TIME_WAIT 是服务器端的状态?还是客户端的状态?</h2><p>TIME_WAIT 是主动断开连接的一方会进入的状态，一般情况下，都是客户端所处的状态;服务器端一般设置不主动关闭连接。</p><p>TIME_WAIT 需要等待 2MSL，在大量短连接的情况下，TIME_WAIT会太多，这也会消耗很多系统资源。对于服务器来说，在 HTTP 协议里指定 KeepAlive（浏览器重用一个 TCP 连接来处理多个 HTTP 请求），由浏览器来主动断开连接，可以一定程度上减少服务器的这个问题。</p><h2 id="15-TCP协议如何保证可靠性？"><a href="#15-TCP协议如何保证可靠性？" class="headerlink" title="15. TCP协议如何保证可靠性？"></a>15. TCP协议如何保证可靠性？</h2><p>TCP主要提供了检验和、序列号/确认应答、超时重传、滑动窗口、拥塞控制和 流量控制等方法实现了可靠性传输。</p><ul><li><p>检验和：通过检验和的方式，接收端可以检测出来数据是否有差错和异常，假如有差错就会直接丢弃TCP段，重新发送。</p></li><li><p>序列号/确认应答：</p><p>序列号的作用不仅仅是应答的作用，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据。</p><p>TCP传输的过程中，每次接收方收到数据后，都会对传输方进行确认应答。也就是发送ACK报文，这个ACK报文当中带有对应的确认序列号，告诉发送方，接收到了哪些数据，下一次的数据从哪里发。</p></li><li><p>滑动窗口：滑动窗口既提高了报文传输的效率，也避免了发送方发送过多的数据而导致接收方无法正常处理的异常。</p></li><li><p>超时重传：超时重传是指发送出去的数据包到接收到确认包之间的时间，如果超过了这个时间会被认为是丢包了，需要重传。最大超时时间是动态计算的。</p></li><li><p>拥塞控制：在数据传输过程中，可能由于网络状态的问题，造成网络拥堵，此时引入拥塞控制机制，在保证TCP可靠性的同时，提高性能。</p></li><li><p>流量控制：如果主机A 一直向主机B发送数据，不考虑主机B的接受能力，则可能导致主机B的接受缓冲区满了而无法再接受数据，从而会导致大量的数据丢包，引发重传机制。而在重传的过程中，若主机B的接收缓冲区情况仍未好转，则会将大量的时间浪费在重传数据上，降低传送数据的效率。所以引入流量控制机制，主机B通过告诉主机A自己接收缓冲区的大小，来使主机A控制发送的数据量。流量控制与TCP协议报头中的窗口大小有关。</p></li></ul><h2 id="16-详细讲一下TCP的滑动窗口？"><a href="#16-详细讲一下TCP的滑动窗口？" class="headerlink" title="16. 详细讲一下TCP的滑动窗口？"></a>16. 详细讲一下TCP的滑动窗口？</h2><p>在进行数据传输时，如果传输的数据比较大，就需要拆分为多个数据包进行发送。TCP 协议需要对数据进行确认后，才可以发送下一个数据包。这样一来，就会在等待确认应答包环节浪费时间。</p><p>为了避免这种情况，TCP引入了窗口概念。窗口大小指的是不需要等待确认应答包而可以继续发送数据包的最大值。</p><p><img src="http://blog-img.coolsen.cn/img/image-20210520214432214.png"></p><p>从上面的图可以看到滑动窗口左边的是已发送并且被确认的分组，滑动窗口右边是还没有轮到的分组。</p><p>滑动窗口里面也分为两块，一块是已经发送但是未被确认的分组，另一块是窗口内等待发送的分组。随着已发送的分组不断被确认，窗口内等待发送的分组也会不断被发送。整个窗口就会往右移动，让还没轮到的分组进入窗口内。</p><p>可以看到滑动窗口起到了一个限流的作用，也就是说当前滑动窗口的大小决定了当前 TCP 发送包的速率，而滑动窗口的大小取决于拥塞控制窗口和流量控制窗口的两者间的最小值。</p><h2 id="17-详细讲一下拥塞控制？"><a href="#17-详细讲一下拥塞控制？" class="headerlink" title="17. 详细讲一下拥塞控制？"></a>17. 详细讲一下拥塞控制？</h2><p>TCP 一共使用了四种算法来实现拥塞控制：</p><ul><li><p>慢开始 (slow-start)；</p></li><li><p>拥塞避免 (congestion avoidance)；</p></li><li><p>快速重传 (fast retransmit)；</p></li><li><p>快速恢复 (fast recovery)。</p></li></ul><p>发送方维持一个叫做拥塞窗口cwnd（congestion window）的状态变量。当cwndssthresh时，改用拥塞避免算法。</p><p><strong>慢开始：</strong>不要一开始就发送大量的数据，由小到大逐渐增加拥塞窗口的大小。</p><p><strong>拥塞避免：</strong>拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1而不是加倍。这样拥塞窗口按线性规律缓慢增长。</p><p><strong>快重传：</strong>我们可以剔除一些不必要的拥塞报文，提高网络吞吐量。比如接收方在<strong>收到一个失序的报文段后就立即发出重复确认，而不要等到自己发送数据时捎带确认。</strong>快重传规定：发送方只要<strong>一连收到三个</strong>重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。</p><p><img src="http://blog-img.coolsen.cn/img/image-20210520214123058.png"></p><p><strong>快恢复：</strong>主要是配合快重传。当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半（为了预防网络发生拥塞），但<strong>接下来并不执行慢开始算法</strong>，因为如果网络出现拥塞的话就不会收到好几个重复的确认，收到三个重复确认说明网络状况还可以。</p><p><img src="http://blog-img.coolsen.cn/img/image-20210520214146324.png"></p><h2 id="巨人的肩膀"><a href="#巨人的肩膀" class="headerlink" title="巨人的肩膀"></a>巨人的肩膀</h2><p><a href="https://segmentfault.com/a/1190000021815671">https://segmentfault.com/a/1190000021815671</a></p><p><a href="https://juejin.cn/post/6844904005315854343">https://juejin.cn/post/6844904005315854343</a></p><p><a href="https://www.nowcoder.com/discuss/568071">https://www.nowcoder.com/discuss/568071</a></p><p><a href="https://blog.csdn.net/yrx420909/article/details/104483455">https://blog.csdn.net/yrx420909/article/details/104483455</a></p><p><a href="https://www.cnblogs.com/xiaolincoding/p/12638546.html">https://www.cnblogs.com/xiaolincoding/p/12638546.html</a></p><p><a href="https://imageslr.com/2020/07/07/tcp-shake-wave.html">https://imageslr.com/2020/07/07/tcp-shake-wave.html</a></p><p><a href="https://cloud.tencent.com/developer/article/1537628">https://cloud.tencent.com/developer/article/1537628</a></p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 知识总结 </tag>
            
            <tag> S6复习 </tag>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统-面试常见问题</title>
      <link href="/2023/03/25/2023-03-25-cao-zuo-xi-tong-mian-shi-chang-jian-wen-ti/"/>
      <url>/2023/03/25/2023-03-25-cao-zuo-xi-tong-mian-shi-chang-jian-wen-ti/</url>
      
        <content type="html"><![CDATA[<h1 id="操作系统面试常见问题"><a href="#操作系统面试常见问题" class="headerlink" title="操作系统面试常见问题"></a>操作系统面试常见问题</h1><h2 id="1-进程和线程的区别？"><a href="#1-进程和线程的区别？" class="headerlink" title="1. 进程和线程的区别？"></a>1. 进程和线程的区别？</h2><ul><li>调度：进程是资源管理的基本单位，线程是程序执行的基本单位。</li><li>切换：线程上下文切换比进程上下文切换要快得多。</li><li>拥有资源： 进程是拥有资源的一个独立单位，线程不拥有系统资源，但是可以访问隶属于进程的资源。</li><li>系统开销： 创建或撤销进程时，系统都要为之分配或回收系统资源，如内存空间，I/O设备等，OS所付出的开销显著大于在创建或撤销线程时的开销，进程切换的开销也远大于线程切换的开销。</li></ul><h2 id="2-协程与线程的区别？"><a href="#2-协程与线程的区别？" class="headerlink" title="2. 协程与线程的区别？"></a>2. 协程与线程的区别？</h2><ul><li>线程和进程都是同步机制，而协程是异步机制。</li><li>线程是抢占式，而协程是非抢占式的。需要用户释放使用权切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力。</li><li>一个线程可以有多个协程，一个进程也可以有多个协程。</li><li>协程不被操作系统内核管理，而完全是由程序控制。线程是被分割的CPU资源，协程是组织好的代码流程，线程是协程的资源。但协程不会直接使用线程，协程直接利用的是执行器关联任意线程或线程池。</li><li>协程能保留上一次调用时的状态。</li></ul><h2 id="3-并发和并行有什么区别？"><a href="#3-并发和并行有什么区别？" class="headerlink" title="3. 并发和并行有什么区别？"></a>3. 并发和并行有什么区别？</h2><p>并发就是在一段时间内，多个任务都会被处理；但在某一时刻，只有一个任务在执行。单核处理器可以做到并发。比如有两个进程<code>A</code>和<code>B</code>，<code>A</code>运行一个时间片之后，切换到<code>B</code>，<code>B</code>运行一个时间片之后又切换到<code>A</code>。因为切换速度足够快，所以宏观上表现为在一段时间内能同时运行多个程序。</p><p>并行就是在同一时刻，有多个任务在执行。这个需要多核处理器才能完成，在微观上就能同时执行多条指令，不同的程序被放到不同的处理器上运行，这个是物理上的多个进程同时进行。</p><h2 id="4-进程与线程的切换流程？"><a href="#4-进程与线程的切换流程？" class="headerlink" title="4. 进程与线程的切换流程？"></a>4. 进程与线程的切换流程？</h2><p>进程切换分两步：</p><p>1、切换<strong>页表</strong>以使用新的地址空间，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。</p><p>2、切换内核栈和硬件上下文。</p><p>对于linux来说，线程和进程的最大区别就在于地址空间，对于线程切换，第1步是不需要做的，第2步是进程和线程切换都要做的。</p><p>因为每个进程都有自己的虚拟地址空间，而线程是共享所在进程的虚拟地址空间的，因此同一个进程中的线程进行线程切换时不涉及虚拟地址空间的转换。</p><h2 id="5-为什么虚拟地址空间切换会比较耗时？"><a href="#5-为什么虚拟地址空间切换会比较耗时？" class="headerlink" title="5. 为什么虚拟地址空间切换会比较耗时？"></a>5. 为什么虚拟地址空间切换会比较耗时？</h2><p>进程都有自己的虚拟地址空间，把虚拟地址转换为物理地址需要查找页表，页表查找是一个很慢的过程，因此通常使用Cache来缓存常用的地址映射，这样可以加速页表查找，这个Cache就是TLB（translation Lookaside Buffer，TLB本质上就是一个Cache，是用来加速页表查找的）。</p><p>由于每个进程都有自己的虚拟地址空间，那么显然每个进程都有自己的页表，那么<strong>当进程切换后页表也要进行切换，页表切换后TLB就失效了</strong>，Cache失效导致命中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢，而线程切换则不会导致TLB失效，因为线程无需切换地址空间，因此我们通常说线程切换要比较进程切换块，原因就在这里。</p><h2 id="6-进程间通信方式有哪些？"><a href="#6-进程间通信方式有哪些？" class="headerlink" title="6. 进程间通信方式有哪些？"></a>6. 进程间通信方式有哪些？</h2><ul><li><p>管道：管道这种通讯方式有两种限制，一是半双工的通信，数据只能单向流动，二是只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。</p><p>管道可以分为两类：匿名管道和命名管道。匿名管道是单向的，只能在有亲缘关系的进程间通信；命名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。</p></li><li><p>信号 ： 信号是一种比较复杂的通信方式，信号可以在任何时候发给某一进程，而无需知道该进程的状态。</p><blockquote><p> <strong>Linux系统中常用信号</strong>：<br> （1）<strong>SIGHUP</strong>：用户从终端注销，所有已启动进程都将收到该进程。系统缺省状态下对该信号的处理是终止进程。</p><p> （2）<strong>SIGINT</strong>：程序终止信号。程序运行过程中，按<code>Ctrl+C</code>键将产生该信号。</p><p> （3）<strong>SIGQUIT</strong>：程序退出信号。程序运行过程中，按<code>Ctrl+\\</code>键将产生该信号。</p><p> （4）<strong>SIGBUS和SIGSEGV</strong>：进程访问非法地址。</p><p> （5）<strong>SIGFPE</strong>：运算中出现致命错误，如除零操作、数据溢出等。</p><p> （6）<strong>SIGKILL</strong>：用户终止进程执行信号。shell下执行<code>kill -9</code>发送该信号。</p><p> （7）<strong>SIGTERM</strong>：结束进程信号。shell下执行<code>kill 进程pid</code>发送该信号。</p><p> （8）<strong>SIGALRM</strong>：定时器信号。</p><p> （9）<strong>SIGCLD</strong>：子进程退出信号。如果其父进程没有忽略该信号也没有处理该信号，则子进程退出后将形成僵尸进程。</p></blockquote></li><li><p>信号量：信号量是一个<strong>计数器</strong>，可以用来控制多个进程对共享资源的访问。它常作为一种<strong>锁机制</strong>，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。</p></li><li><p>消息队列：消息队列是消息的链接表，包括Posix消息队列和System V消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。</p></li><li><p>共享内存：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。</p></li><li><p>Socket：与其他通信机制不同的是，它可用于不同机器间的进程通信。</p></li></ul><p><strong>优缺点</strong>：</p><ul><li><p>管道：速度慢，容量有限；</p></li><li><p>Socket：任何进程间都能通讯，但速度慢；</p></li><li><p>消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题；</p></li><li><p>信号量：不能传递复杂消息，只能用来同步；</p></li><li><p>共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存。</p></li></ul><h2 id="7-进程间同步的方式有哪些？"><a href="#7-进程间同步的方式有哪些？" class="headerlink" title="7. 进程间同步的方式有哪些？"></a>7. 进程间同步的方式有哪些？</h2><p>1、临界区：通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。</p><p>优点：保证在某一时刻只有一个线程能访问数据的简便办法。</p><p>缺点：虽然临界区同步速度很快，但却只能用来同步本进程内的线程，而不可用来同步多个进程中的线程。</p><p>2、互斥量：为协调共同对一个共享资源的单独访问而设计的。互斥量跟临界区很相似，比临界区复杂，互斥对象只有一个，只有拥有互斥对象的线程才具有访问资源的权限。</p><p>优点：使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享。</p><p>缺点：</p><ul><li><p>互斥量是可以命名的，也就是说它可以跨越进程使用，所以创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量。</p></li><li><p>通过互斥量可以指定资源被独占的方式使用，但如果有下面一种情况通过互斥量就无法处理，比如现在一位用户购买了一份三个并发访问许可的数据库系统，可以根据用户购买的访问许可数量来决定有多少个线程/进程能同时进行数据库操作，这时候如果利用互斥量就没有办法完成这个要求，信号量对象可以说是一种资源计数器。</p></li></ul><p>3、信号量：为控制一个具有有限数量用户资源而设计。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。互斥量是信号量的一种特殊情况，当信号量的最大资源数=1就是互斥量了。</p><p>优点：适用于对Socket（套接字）程序中线程的同步。</p><p>缺点:</p><ul><li><p>信号量机制必须有公共内存，不能用于分布式操作系统，这是它最大的弱点；</p></li><li><p>信号量机制功能强大，但使用时对信号量的操作分散， 而且难以控制，读写和维护都很困难，加重了程序员的编码负担；</p></li><li><p>核心操作P-V分散在各用户程序的代码中，不易控制和管理，一旦错误，后果严重，且不易发现和纠正。</p></li></ul><p>4、事件： 用来通知线程有一些事件已发生，从而启动后继任务的开始。</p><p>优点：事件对象通过通知操作的方式来保持线程的同步，并且可以实现不同进程中的线程同步操作。</p><h2 id="8-线程同步的方式有哪些？"><a href="#8-线程同步的方式有哪些？" class="headerlink" title="8. 线程同步的方式有哪些？"></a>8. 线程同步的方式有哪些？</h2><p>1、临界区：当多个线程访问一个独占性共享资源时，可以使用临界区对象。拥有临界区的线程可以访问被保护起来的资源或代码段，其他线程若想访问，则被挂起，直到拥有临界区的线程放弃临界区为止，以此达到用原子方式操 作共享资源的目的。</p><p>2、事件：事件机制，则允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。</p><p>3、互斥量：互斥对象和临界区对象非常相似，只是其允许在进程间使用，而临界区只限制与同一进程的各个线程之间使用，但是更节省资源，更有效率。</p><p>4、信号量：当需要一个计数器来限制可以使用某共享资源的线程数目时，可以使用“信号量”对象。</p><p>区别：</p><ul><li><p>互斥量与临界区的作用非常相似，但互斥量是可以命名的，也就是说互斥量可以跨越进程使用，但创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量 。因为互斥量是跨进程的互斥量一旦被创建，就可以通过名字打开它。</p></li><li><p>互斥量，信号量，事件都可以被跨越进程使用来进行同步数据操作。</p></li></ul><h2 id="9-线程的分类？"><a href="#9-线程的分类？" class="headerlink" title="9. 线程的分类？"></a>9. 线程的分类？</h2><p>从线程的运行空间来说，分为用户级线程（user-level thread, ULT）和内核级线程（kernel-level, KLT）</p><p><strong>内核级线程</strong>：这类线程依赖于内核，又称为内核支持的线程或轻量级进程。无论是在用户程序中的线程还是系统进程中的线程，它们的创建、撤销和切换都由内核实现。比如英特尔i5-8250U是4核8线程，这里的线程就是内核级线程</p><p><strong>用户级线程</strong>：它仅存在于用户级中，这种线程是<strong>不依赖于操作系统核心</strong>的。应用进程利用<strong>线程库来完成其创建和管理</strong>，速度比较快，<strong>操作系统内核无法感知用户级线程的存在</strong>。</p><h2 id="10-什么是临界区，如何解决冲突？"><a href="#10-什么是临界区，如何解决冲突？" class="headerlink" title="10. 什么是临界区，如何解决冲突？"></a>10. 什么是临界区，如何解决冲突？</h2><p>每个进程中访问临界资源的那段程序称为临界区，<strong>一次仅允许一个进程使用的资源称为临界资源。</strong></p><p>解决冲突的办法：</p><ul><li>如果有若干进程要求进入空闲的临界区，<strong>一次仅允许一个进程进入</strong>，如已有进程进入自己的临界区，则其它所有试图进入临界区的进程必须等待；</li><li>进入临界区的进程要在<strong>有限时间内退出</strong>。</li><li>如果进程不能进入自己的临界区，则应<strong>让出CPU</strong>，避免进程出现“忙等”现象。</li></ul><h2 id="11-什么是死锁？死锁产生的条件？"><a href="#11-什么是死锁？死锁产生的条件？" class="headerlink" title="11. 什么是死锁？死锁产生的条件？"></a>11. 什么是死锁？死锁产生的条件？</h2><p><strong>什么是死锁</strong>：</p><p>在两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗的讲就是两个或多个进程无限期的阻塞、相互等待的一种状态。</p><p><strong>死锁产生的四个必要条件</strong>：（有一个条件不成立，则不会产生死锁）</p><ul><li>互斥条件：一个资源一次只能被一个进程使用</li><li>请求与保持条件：一个进程因请求资源而阻塞时，对已获得资源保持不放</li><li>不剥夺条件：进程获得的资源，在未完全使用完之前，不能强行剥夺</li><li>循环等待条件：若干进程之间形成一种头尾相接的环形等待资源关系</li></ul><h3 id="如何处理死锁问题"><a href="#如何处理死锁问题" class="headerlink" title="如何处理死锁问题"></a><strong>如何处理死锁问题</strong></h3><p>常用的处理死锁的方法有：死锁预防、死锁避免、死锁检测、死锁解除、鸵鸟策略。</p><p><strong>（1）死锁的预防：</strong>基本思想就是确保死锁发生的四个必要条件中至少有一个不成立：</p><blockquote><ul><li>① 破除资源互斥条件</li><li>② 破除“请求与保持”条件：实行资源预分配策略，进程在运行之前，必须一次性获取所有的资源。缺点：在很多情况下，无法预知进程执行前所需的全部资源，因为进程是动态执行的，同时也会降低资源利用率，导致降低了进程的并发性。</li><li>③ 破除“不可剥夺”条件：允许进程强行从占有者那里夺取某些资源。当一个已经保持了某些不可被抢占资源的进程，提出新的资源请求而不能得到满足时，它必须释放已经保持的所有资源，待以后需要时再重新申请。这意味着进程已经占有的资源会被暂时被释放，或者说被抢占了。</li><li>④ 破除“循环等待”条件：实行资源有序分配策略，对所有资源排序编号，按照顺序获取资源，将紧缺的，稀少的采用较大的编号，在申请资源时必须按照编号的顺序进行，一个进程只有获得较小编号的进程才能申请较大编号的进程。</li></ul></blockquote><p><strong>（2）死锁避免：</strong></p><p>死锁预防通过约束资源请求，防止4个必要条件中至少一个的发生，可以通过直接或间接预防方法，但是都会导致低效的资源使用和低效的进程执行。而死锁避免则允许前三个必要条件，但是通过动态地检测资源分配状态，以确保循环等待条件不成立，从而确保系统处于安全状态。所谓安全状态是指：如果系统能按某个顺序为每个进程分配资源（不超过其最大值），那么系统状态是安全的，换句话说就是，如果存在一个安全序列，那么系统处于安全状态。银行家算法是经典的死锁避免的算法。</p><p><strong>（3）死锁检测：</strong></p><p>死锁预防策略是非常保守的，他们通过限制访问资源和在进程上强加约束来解决死锁的问题。死锁检测则是完全相反，它不限制资源访问或约束进程行为，只要有可能，被请求的资源就被授权给进程。但是操作系统会周期性地执行一个算法检测前面的循环等待的条件。死锁检测算法是通过资源分配图来检测是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有存在环，也就是检测到死锁的发生。</p><blockquote><ul><li>（1）如果进程-资源分配图中无环路，此时系统没有死锁。 </li><li>（2）如果进程-资源分配图中有环路，且每个资源类中只有一个资源，则系统发生死锁。 </li><li>（3）如果进程-资源分配图中有环路，且所涉及的资源类有多个资源，则不一定会发生死锁。</li></ul></blockquote><p><strong>（4）死锁解除：</strong></p><p>死锁解除的常用方法就是终止进程和资源抢占，回滚。所谓进程终止就是简单地终止一个或多个进程以打破循环等待，包括两种方式：终止所有死锁进程和一次只终止一个进程直到取消死锁循环为止；所谓资源抢占就是从一个或者多个死锁进程那里抢占一个或多个资源。</p><p><strong>（5）鸵鸟策略：</strong></p><p>把头埋在沙子里，假装根本没发生问题。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任何措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。</p><h2 id="12-进程调度策略有哪几种？"><a href="#12-进程调度策略有哪几种？" class="headerlink" title="12. 进程调度策略有哪几种？"></a>12. 进程调度策略有哪几种？</h2><ul><li><p><strong>先来先服务</strong>：非抢占式的调度算法，按照请求的顺序进行调度。有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。另外，对<code>I/O</code>密集型进程也不利，因为这种进程每次进行<code>I/O</code>操作之后又得重新排队。</p></li><li><p><strong>短作业优先</strong>：非抢占式的调度算法，按估计运行时间最短的顺序进行调度。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。</p></li><li><p><strong>最短剩余时间优先</strong>：最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。</p></li><li><p><strong>时间片轮转</strong>：将所有就绪进程按 <code>FCFS</code> 的原则排成一个队列，每次调度时，把 <code>CPU</code> 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 <code>CPU</code> 时间分配给队首的进程。</p><p>时间片轮转算法的效率和时间片的大小有很大关系：因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。 而如果时间片过长，那么实时性就不能得到保证。 </p></li><li><p><strong>优先级调度</strong>：为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。</p></li></ul><h2 id="13-进程有哪些状态？"><a href="#13-进程有哪些状态？" class="headerlink" title="13. 进程有哪些状态？"></a>13. 进程有哪些状态？</h2><p>进程一共有<code>5</code>种状态，分别是创建、就绪、运行（执行）、终止、阻塞。 </p><p><img src="http://blog-img.coolsen.cn/img/A61F5B5322ED49038C64BDD82D341987" alt="进程五种状态转换图"></p><ul><li>运行状态就是进程正在<code>CPU</code>上运行。在单处理机环境下，每一时刻最多只有一个进程处于运行状态。 </li><li>就绪状态就是说进程已处于准备运行的状态，即进程获得了除<code>CPU</code>之外的一切所需资源，一旦得到<code>CPU</code>即可运行。 </li><li>阻塞状态就是进程正在等待某一事件而暂停运行，比如等待某资源为可用或等待<code>I/O</code>完成。即使<code>CPU</code>空闲，该进程也不能运行。</li></ul><p><strong>运行态→阻塞态</strong>：往往是由于等待外设，等待主存等资源分配或等待人工干预而引起的。<br><strong>阻塞态→就绪态</strong>：则是等待的条件已满足，只需分配到处理器后就能运行。<br><strong>运行态→就绪态</strong>：不是由于自身原因，而是由外界原因使运行状态的进程让出处理器，这时候就变成就绪态。例如时间片用完，或有更高优先级的进程来抢占处理器等。<br><strong>就绪态→运行态</strong>：系统按某种策略选中就绪队列中的一个进程占用处理器，此时就变成了运行态。</p><h2 id="14-什么是分页？"><a href="#14-什么是分页？" class="headerlink" title="14. 什么是分页？"></a>14. 什么是分页？</h2><p>把内存空间划分为<strong>大小相等且固定的块</strong>，作为主存的基本单位。因为程序数据存储在不同的页面中，而页面又离散的分布在内存中，<strong>因此需要一个页表来记录映射关系，以实现从页号到物理块号的映射。</strong></p><p>访问分页系统中内存数据需要<strong>两次的内存访问</strong> (一次是从内存中访问页表，从中找到指定的物理块号，加上页内偏移得到实际物理地址；第二次就是根据第一次得到的物理地址访问内存取出数据)。</p><p><img src="http://blog-img.coolsen.cn/img/image-20210610173249387.png"></p><h2 id="15-什么是分段？"><a href="#15-什么是分段？" class="headerlink" title="15. 什么是分段？"></a>15. 什么是分段？</h2><p><strong>分页是为了提高内存利用率，而分段是为了满足程序员在编写代码的时候的一些逻辑需求(比如数据共享，数据保护，动态链接等)。</strong></p><p>分段内存管理当中，<strong>地址是二维的，一维是段号，二维是段内地址；其中每个段的长度是不一样的，而且每个段内部都是从0开始编址的</strong>。由于分段管理中，每个段内部是连续内存分配，但是段和段之间是离散分配的，因此也存在一个逻辑地址到物理地址的映射关系，相应的就是段表机制。</p><p><img src="http://blog-img.coolsen.cn/img/image-20210610173410509.png"></p><h2 id="16-分页和分段有什区别？"><a href="#16-分页和分段有什区别？" class="headerlink" title="16. 分页和分段有什区别？"></a>16. 分页和分段有什区别？</h2><ul><li>分页对程序员是透明的，但是分段需要程序员显式划分每个段。 </li><li>分页的地址空间是一维地址空间，分段是二维的。 </li><li>页的大小不可变，段的大小可以动态改变。 </li><li>分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。</li></ul><h2 id="17-什么是交换空间？"><a href="#17-什么是交换空间？" class="headerlink" title="17. 什么是交换空间？"></a>17. 什么是交换空间？</h2><p>操作系统把物理内存(physical RAM)分成一块一块的小内存，每一块内存被称为<strong>页(page)<strong>。当内存资源不足时，</strong>Linux把某些页的内容转移至硬盘上的一块空间上，以释放内存空间</strong>。硬盘上的那块空间叫做<strong>交换空间</strong>(swap space),而这一过程被称为交换(swapping)。<strong>物理内存和交换空间的总容量就是虚拟内存的可用容量。</strong></p><p>用途：</p><ul><li>物理内存不足时一些不常用的页可以被交换出去，腾给系统。</li><li>程序启动时很多内存页被用来初始化，之后便不再需要，可以交换出去。</li></ul><h2 id="18-物理地址、逻辑地址、有效地址、线性地址、虚拟地址的区别"><a href="#18-物理地址、逻辑地址、有效地址、线性地址、虚拟地址的区别" class="headerlink" title="18. 物理地址、逻辑地址、有效地址、线性地址、虚拟地址的区别?"></a>18. 物理地址、逻辑地址、有效地址、线性地址、虚拟地址的区别?</h2><p>物理地址就是内存中真正的地址，它就相当于是你家的门牌号，你家就肯定有这个门牌号，具有唯一性。<strong>不管哪种地址，最终都会映射为物理地址</strong>。</p><p>在<code>实模式</code>下，段基址 + 段内偏移经过地址加法器的处理，经过地址总线传输，最终也会转换为<code>物理地址</code>。</p><p>但是在<code>保护模式</code>下，段基址 + 段内偏移被称为<code>线性地址</code>，不过此时的段基址不能称为真正的地址，而是会被称作为一个<code>选择子</code>的东西，选择子就是个索引，相当于数组的下标，通过这个索引能够在 GDT 中找到相应的段描述符，段描述符记录了<strong>段的起始、段的大小</strong>等信息，这样便得到了基地址。如果此时没有开启内存分页功能，那么这个线性地址可以直接当做物理地址来使用，直接访问内存。如果开启了分页功能，那么这个线性地址又多了一个名字，这个名字就是<code>虚拟地址</code>。</p><p>不论在实模式还是保护模式下，段内偏移地址都叫做<code>有效地址</code>。有效抵制也是逻辑地址。</p><p>线性地址可以看作是<code>虚拟地址</code>，虚拟地址不是真正的物理地址，但是虚拟地址会最终被映射为物理地址。下面是虚拟地址 -&gt; 物理地址的映射。</p><p><img src="http://blog-img.coolsen.cn/img/image-20210807152300643.png" alt="image-20210807152300643"></p><h2 id="19-页面替换算法有哪些？"><a href="#19-页面替换算法有哪些？" class="headerlink" title="19. 页面替换算法有哪些？"></a>19. 页面替换算法有哪些？</h2><p>在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。</p><p><img src="http://blog-img.coolsen.cn/img/image-20210807152232136.png" alt="image-20210807152232136"></p><ul><li><code>最优算法</code>在当前页面中置换最后要访问的页面。不幸的是，没有办法来判定哪个页面是最后一个要访问的，<code>因此实际上该算法不能使用</code>。然而，它可以作为衡量其他算法的标准。</li><li><code>NRU</code> 算法根据 R 位和 M 位的状态将页面分为四类。从编号最小的类别中随机选择一个页面。NRU 算法易于实现，但是性能不是很好。存在更好的算法。</li><li><code>FIFO</code> 会跟踪页面加载进入内存中的顺序，并把页面放入一个链表中。有可能删除存在时间最长但是还在使用的页面，因此这个算法也不是一个很好的选择。</li><li><code>第二次机会</code>算法是对 FIFO 的一个修改，它会在删除页面之前检查这个页面是否仍在使用。如果页面正在使用，就会进行保留。这个改进大大提高了性能。</li><li><code>时钟</code> 算法是第二次机会算法的另外一种实现形式，时钟算法和第二次算法的性能差不多，但是会花费更少的时间来执行算法。</li><li><code>LRU</code> 算法是一个非常优秀的算法，但是没有<code>特殊的硬件(TLB)</code>很难实现。如果没有硬件，就不能使用 LRU 算法。</li><li><code>NFU</code> 算法是一种近似于 LRU 的算法，它的性能不是非常好。</li><li><code>老化</code> 算法是一种更接近 LRU 算法的实现，并且可以更好的实现，因此是一个很好的选择</li><li>最后两种算法都使用了工作集算法。工作集算法提供了合理的性能开销，但是它的实现比较复杂。<code>WSClock</code> 是另外一种变体，它不仅能够提供良好的性能，而且可以高效地实现。</li></ul><p><strong>最好的算法是老化算法和WSClock算法</strong>。他们分别是基于 LRU 和工作集算法。他们都具有良好的性能并且能够被有效的实现。还存在其他一些好的算法，但实际上这两个可能是最重要的。</p><h2 id="20-什么是缓冲区溢出？有什么危害？"><a href="#20-什么是缓冲区溢出？有什么危害？" class="headerlink" title="20. 什么是缓冲区溢出？有什么危害？"></a>20. 什么是缓冲区溢出？有什么危害？</h2><p>缓冲区溢出是指当计算机向缓冲区填充数据时超出了缓冲区本身的容量，溢出的数据覆盖在合法数据上。</p><p>危害有以下两点：</p><ul><li>程序崩溃，导致拒绝额服务</li><li>跳转并且执行一段恶意代码</li></ul><p>造成缓冲区溢出的主要原因是程序中没有仔细检查用户输入。</p><h2 id="21-什么是虚拟内存？"><a href="#21-什么是虚拟内存？" class="headerlink" title="21. 什么是虚拟内存？"></a>21. 什么是虚拟内存？</h2><p>虚拟内存就是说，让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。虚拟内存使用部分加载的技术，让一个进程或者资源的某些页面加载进内存，从而能够加载更多的进程，甚至能加载比内存大的进程，这样看起来好像内存变大了，这部分内存其实包含了磁盘或者硬盘，并且就叫做虚拟内存。</p><h2 id="22-虚拟内存的实现方式有哪些"><a href="#22-虚拟内存的实现方式有哪些" class="headerlink" title="22. 虚拟内存的实现方式有哪些?"></a>22. 虚拟内存的实现方式有哪些?</h2><p>虚拟内存中，允许将一个作业分多次调入内存。釆用连续分配方式时，会使相当一部分内存空间都处于暂时或<code>永久</code>的空闲状态，造成内存资源的严重浪费，而且也无法从逻辑上扩大内存容量。因此，虚拟内存的实需要建立在离散分配的内存管理方式的基础上。虚拟内存的实现有以下三种方式：</p><ul><li>请求分页存储管理。</li><li>请求分段存储管理。</li><li>请求段页式存储管理。</li></ul><h2 id="23-讲一讲IO多路复用？"><a href="#23-讲一讲IO多路复用？" class="headerlink" title="23. 讲一讲IO多路复用？"></a>23. 讲一讲IO多路复用？</h2><p><strong>IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。IO多路复用适用如下场合</strong>：</p><ul><li>当客户处理多个描述字时（一般是交互式输入和网络套接口），必须使用I/O复用。</li><li>当一个客户同时处理多个套接口时，而这种情况是可能的，但很少出现。</li><li>如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用。</li><li>如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用。</li><li>如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用。</li><li>与多进程和多线程技术相比，I/O多路复用技术的最大优势是系统开销小，系统不必创建进程/线程，也不必维护这些进程/线程，从而大大减小了系统的开销。</li></ul><h2 id="24-硬链接和软链接有什么区别？"><a href="#24-硬链接和软链接有什么区别？" class="headerlink" title="24. 硬链接和软链接有什么区别？"></a>24. 硬链接和软链接有什么区别？</h2><ul><li>硬链接就是在目录下创建一个条目，记录着文件名与 <code>inode</code> 编号，这个 <code>inode</code> 就是源文件的 <code>inode</code>。删除任意一个条目，文件还是存在，只要引用数量不为 <code>0</code>。但是硬链接有限制，它不能跨越文件系统，也不能对目录进行链接。</li><li>符号链接文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 <code>Windows</code> 的快捷方式。当源文件被删除了，链接文件就打不开了。因为记录的是路径，所以可以为目录建立符号链接。</li></ul><h2 id="25-中断的处理过程"><a href="#25-中断的处理过程" class="headerlink" title="25. 中断的处理过程?"></a>25. 中断的处理过程?</h2><ol><li>保护现场：将当前执行程序的相关数据保存在寄存器中，然后入栈。</li><li>开中断：以便执行中断时能响应较高级别的中断请求。</li><li>中断处理</li><li>关中断：保证恢复现场时不被新中断打扰</li><li>恢复现场：从堆栈中按序取出程序数据，恢复中断前的执行状态。</li></ol><h2 id="26-中断和轮询有什么区别？"><a href="#26-中断和轮询有什么区别？" class="headerlink" title="26. 中断和轮询有什么区别？"></a>26. 中断和轮询有什么区别？</h2><ul><li>轮询：CPU对<strong>特定设备</strong>轮流询问。中断：通过<strong>特定事件</strong>提醒CPU。</li><li>轮询：效率低等待时间长，CPU利用率不高。中断：容易遗漏问题，CPU利用率不高。</li></ul><h2 id="27-什么是用户态和内核态？"><a href="#27-什么是用户态和内核态？" class="headerlink" title="27. 什么是用户态和内核态？"></a>27. 什么是用户态和内核态？</h2><p>用户态和系统态是操作系统的两种运行状态：</p><blockquote><ul><li>内核态：内核态运行的程序可以访问计算机的任何数据和资源，不受限制，包括外围设备，比如网卡、硬盘等。处于内核态的 CPU 可以从一个程序切换到另外一个程序，并且占用 CPU 不会发生抢占情况。</li><li>用户态：用户态运行的程序只能受限地访问内存，只能直接读取用户程序的数据，并且不允许访问外围设备，用户态下的 CPU 不允许独占，也就是说 CPU 能够被其他程序获取。</li></ul></blockquote><p>将操作系统的运行状态分为用户态和内核态，主要是为了对访问能力进行限制，防止随意进行一些比较危险的操作导致系统的崩溃，比如设置时钟、内存清理，这些都需要在内核态下完成 。</p><h2 id="28-用户态和内核态是如何切换的"><a href="#28-用户态和内核态是如何切换的" class="headerlink" title="28. 用户态和内核态是如何切换的?"></a>28. 用户态和内核态是如何切换的?</h2><p>所有的用户进程都是运行在用户态的，但是我们上面也说了，用户程序的访问能力有限，一些比较重要的比如从硬盘读取数据，从键盘获取数据的操作则是内核态才能做的事情，而这些数据却又对用户程序来说非常重要。所以就涉及到两种模式下的转换，即<strong>用户态 -&gt; 内核态 -&gt; 用户态</strong>，而唯一能够做这些操作的只有 <code>系统调用</code>，而能够执行系统调用的就只有 <code>操作系统</code>。</p><p>一般用户态 -&gt; 内核态的转换我们都称之为 trap 进内核，也被称之为 <code>陷阱指令(trap instruction)</code>。</p><p>他们的工作流程如下：</p><p><img src="http://blog-img.coolsen.cn/img/image-20210807152619210.png" alt="image-20210807152619210"></p><ul><li>首先用户程序会调用 <code>glibc</code> 库，glibc 是一个标准库，同时也是一套核心库，库中定义了很多关键 API。</li><li>glibc 库知道针对不同体系结构调用<code>系统调用</code>的正确方法，它会根据体系结构应用程序的二进制接口设置用户进程传递的参数，来准备系统调用。</li><li>然后，glibc 库调用<code>软件中断指令(SWI)</code> ，这个指令通过更新 <code>CPSR</code> 寄存器将模式改为超级用户模式，然后跳转到地址 <code>0x08</code> 处。</li><li>到目前为止，整个过程仍处于用户态下，在执行 SWI 指令后，允许进程执行内核代码，MMU 现在允许内核虚拟内存访问</li><li>从地址 0x08 开始，进程执行加载并跳转到中断处理程序，这个程序就是 ARM 中的 <code>vector_swi()</code>。</li><li>在 vector_swi() 处，从 SWI 指令中提取系统调用号 SCNO，然后使用 SCNO 作为系统调用表 <code>sys_call_table</code> 的索引，调转到系统调用函数。</li><li>执行系统调用完成后，将还原用户模式寄存器，然后再以用户模式执行。</li></ul><h2 id="29-Unix-常见的IO模型："><a href="#29-Unix-常见的IO模型：" class="headerlink" title="29. Unix 常见的IO模型："></a>29. Unix 常见的IO模型：</h2><p>对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段：</p><blockquote><ul><li>等待数据准备就绪 (Waiting for the data to be ready)</li><li>将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)</li></ul></blockquote><p>正式因为这两个阶段，linux系统产生了下面五种网络模式的方案：</p><blockquote><ul><li>阻塞式IO模型(blocking IO model)</li><li>非阻塞式IO模型(noblocking IO model)</li><li>IO复用式IO模型(IO multiplexing model)</li><li>信号驱动式IO模型(signal-driven IO model)</li><li>异步IO式IO模型(asynchronous IO model)</li></ul></blockquote><p>对于这几种 IO 模型的详细说明，可以参考这篇文章：<a href="https://juejin.cn/post/6942686874301857800#heading-13">https://juejin.cn/post/6942686874301857800#heading-13</a></p><p>其中，IO多路复用模型指的是：使用单个进程同时处理多个网络连接IO，他的原理就是select、poll、epoll 不断轮询所负责的所有 socket，当某个socket有数据到达了，就通知用户进程。该模型的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。</p><h2 id="30-select、poll-和-epoll-之间的区别"><a href="#30-select、poll-和-epoll-之间的区别" class="headerlink" title="30. select、poll 和 epoll 之间的区别?"></a>30. select、poll 和 epoll 之间的区别?</h2><p>（1）select：时间复杂度 O(n)</p><p>select 仅仅知道有 I/O 事件发生，但并不知道是哪几个流，所以只能无差别轮询所有流，找出能读出数据或者写入数据的流，并对其进行操作。所以 select 具有 O(n) 的无差别轮询复杂度，同时处理的流越多，无差别轮询时间就越长。</p><p>（2）poll：时间复杂度 O(n)</p><p>poll 本质上和 select 没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个 fd 对应的设备状态， 但是它没有最大连接数的限制，原因是它是基于链表来存储的。</p><p>（3）epoll：时间复杂度 O(1)</p><p>epoll 可以理解为 event poll，不同于忙轮询和无差别轮询，epoll 会把哪个流发生了怎样的 I/O 事件通知我们。所以说 epoll 实际上是事件驱动（每个事件关联上 fd）的。</p><blockquote><p>select，poll，epoll 都是 IO 多路复用的机制。I/O 多路复用就是通过一种机制监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），就通知程序进行相应的读写操作。但 select，poll，epoll 本质上都是同步 I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步 I/O 则无需自己负责进行读写，异步 I/O 的实现会负责把数据从内核拷贝到用户空间。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 知识总结 </tag>
            
            <tag> 操作系统 </tag>
            
            <tag> S6复习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>前端-文件路径</title>
      <link href="/2023/03/22/qian-duan-wen-jian-lu-jing/"/>
      <url>/2023/03/22/qian-duan-wen-jian-lu-jing/</url>
      
        <content type="html"><![CDATA[<h1 id="文件路径"><a href="#文件路径" class="headerlink" title="文件路径"></a>文件路径</h1><h2 id="相对路径"><a href="#相对路径" class="headerlink" title="相对路径"></a>相对路径</h2><p>在表示相对路径中，单点表示当前目录，双点表示上一级目录，反斜杠“/”表示分隔目录；</p><p>相对路径特殊符号有以下几种表示意义：</p><ul><li>以“./”开头，代表当前目录和文件目录在同一个目录里，“./”也可以省略不写！</li><li>以”../“开头：向上走一级，代表目标文件在当前文件所在的上一级目录；</li><li>以”../../“开头：向上走两级，代表父级的父级目录，也就是上上级目录，再说明白点，就是上一级目录的上一级目录</li><li>以”/”开头，代表根目录</li></ul><h2 id="vue路径别名"><a href="#vue路径别名" class="headerlink" title="vue路径别名"></a>vue路径别名</h2><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora//20230322170329_FfNiTe_image-20230322170328464.png" alt="配置"></p><p>效果：@直接到src文件夹</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora//20230322170421_jsP76k_image-20230322170420999.png" alt="使用"></p>]]></content>
      
      
      <categories>
          
          <category> 并行程序设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 知识总结 </tag>
            
            <tag> S6课上 </tag>
            
            <tag> 前端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>并行程序设计-并行复习</title>
      <link href="/2023/02/10/bing-xing-fu-xi/"/>
      <url>/2023/02/10/bing-xing-fu-xi/</url>
      
        <content type="html"><![CDATA[<h1 id="并行复习"><a href="#并行复习" class="headerlink" title="并行复习"></a>并行复习</h1><h2 id="并行硬件与并行软件"><a href="#并行硬件与并行软件" class="headerlink" title="并行硬件与并行软件"></a>并行硬件与并行软件</h2><h3 id="冯诺依曼瓶颈"><a href="#冯诺依曼瓶颈" class="headerlink" title="冯诺依曼瓶颈"></a>冯诺依曼瓶颈</h3><p>cpu去主存储器中去指令的过程比cpu执行指令要慢很多</p><p>三方面改进：</p><h4 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h4><p>CPU Cache是一组相比于 CPU 主存更能快速访问的内存区域</p><h4 id="虚拟内存（了解）"><a href="#虚拟内存（了解）" class="headerlink" title="虚拟内存（了解）"></a>虚拟内存（了解）</h4><p>主存中放不下，把不常用的放到虚拟内存中</p><h4 id="低层次并行"><a href="#低层次并行" class="headerlink" title="低层次并行"></a>低层次并行</h4><p>1）指令级并行 </p><p>不是多核</p><p>让多个处理器或者功能单元 同时执行指令</p><p>两种实现方式</p><ul><li><p>流水线</p><ul><li><p>![image-20230220164322035](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220164322035.png)</p><p>7000ns➡️1006ns</p></li></ul></li><li><p>多发射</p><ul><li>复制功能单元来同时执行程序中的不同指令</li><li>静态多发射：功能单元在<strong>编译</strong>时调度</li><li>动态多发射：功能单元在运行时间调度。  <strong>超标量</strong></li></ul></li></ul><p>超标量</p><p>必须找出能同时执行的指令</p><p>猜测</p><p>![image-20230220170043087](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220170043087.png)</p><p>2）硬件多线程</p><p>分为3种</p><ul><li>细粒度 每条指令完成后都切换</li><li>粗粒度 只切换那些需要等待较长时间而阻塞的线程</li><li>同步多线程/超线程 真正意义上的同时 一个核上多个线程</li></ul><h3 id="Cache相关概念"><a href="#Cache相关概念" class="headerlink" title="Cache相关概念"></a>Cache相关概念</h3><p>局部性原理</p><p>程序访问完一个存储区域往往会访问接下来的区域</p><ul><li>空间的局部性</li><li>时间的局部性</li></ul><p>cache命中</p><p>cache缺失 </p><p>cache的问题</p><ul><li>写直达：当CPU向Cache中写数据时，高速缓存行会立即写入主存中</li><li>写回：数据不是立即更新到主存中，而是将发生数据更新的高速缓存行标记为脏。当发生高速缓存行替换时，标记为脏的高速缓存行被写入主存中</li></ul><p>Cache一致性</p><p>![image-20230220203121263](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220203121263.png)</p><p>z1的值取决于什么时候更新x</p><p>解决</p><ul><li>监听Cache一致性协议</li><li>基于目录的Cache一致性协议</li></ul><p>![image-20230221163041208](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230221163041208.png)</p><h3 id="并行、多线程相关概念"><a href="#并行、多线程相关概念" class="headerlink" title="并行、多线程相关概念"></a>并行、多线程相关概念</h3><p>1.1.3</p><h3 id="SIMD-MIMD（共享内存、分布式内存、网络连接等）"><a href="#SIMD-MIMD（共享内存、分布式内存、网络连接等）" class="headerlink" title="SIMD MIMD（共享内存、分布式内存、网络连接等）"></a>SIMD MIMD（共享内存、分布式内存、网络连接等）</h3><p>Flynn‘s分类法</p><p> ![image-20230220171506418](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220171506418.png)</p><h4 id="SIMD"><a href="#SIMD" class="headerlink" title="SIMD"></a>SIMD</h4><p>数据并行</p><p>将数据分配给多个处理器实现并行</p><p>相同指令来操作数据子集</p><p>缺点</p><ul><li>所有ALU要么执行相同的指令，要么同时处于空闲状态</li><li>ALU同步操作</li><li>ALU没有指令存储器 一次只能执行一条指令</li><li>SIMD并行在大型数据并行问题上有用，但是处理其他并行问题并不优秀</li></ul><p>向量处理器</p><p>对数组或者数据向量进行操作</p><p>向量寄存器 能够存储多个数组成的向量并操作</p><p>向量指令 在向量上操作</p><p>向量化和流水化的功能单元 对向量中每个元素做同样的操作</p><p>优点</p><ul><li>速度快 容易使用 向量编译器擅长识别向量化的代码</li><li>编译器能够提供代码为什么不能向量化的原因</li><li>内存带宽高 每个加载的数据都会使用</li></ul><p>缺点</p><ul><li>不能处理不规则数据结构和其他的并行结构</li><li>可扩展性受限   可扩展性：处理更大问题的能力</li></ul><p>GPU</p><p><strong>使用SIMD并行</strong></p><p>并不是纯粹的SIMD系统</p><h4 id="MIMD"><a href="#MIMD" class="headerlink" title="MIMD"></a>MIMD</h4><p>多指令流多数据流</p><p>完全独立的处理单元或者核</p><p>每个处理单元或者核都有自己的控制单元和ALU</p><p>分为：</p><p>1）共享内存系统</p><p>内存共享</p><p>处理器通过访问共享的内存来隐式通信</p><p>一个/多个多核处理器 一块芯片上有多个CPU或者核</p><p>![image-20230220175039016](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220175039016.png)</p><p>分为两类</p><ul><li><p>一致内存访问系统</p><p>![image-20230220190140406](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220190140406.png)</p></li><li><p>非一致内存访问系统</p><p>![image-20230220190203183](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220190203183.png)</p></li></ul><p>2）分布式内存系统</p><p>集群</p><p>大多数混合系统</p><p>![image-20230220190316207](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220190316207.png)</p><h4 id="互连网络"><a href="#互连网络" class="headerlink" title="互连网络"></a>互连网络</h4><p>分为两类</p><ul><li>共享内存互连网络</li><li>分布式内存互连网络</li></ul><h5 id="共享内存互连网络"><a href="#共享内存互连网络" class="headerlink" title="共享内存互连网络"></a>共享内存互连网络</h5><p>1）总线互连</p><p>随着连接到总线的设备数量增加，竞争增加，性能会下降</p><p>2）交换互连网络</p><p>交换器</p><p>交叉开关矩阵  </p><p>![image-20230220191320436](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220191320436.png)</p><h5 id="分布式内存互连网络"><a href="#分布式内存互连网络" class="headerlink" title="分布式内存互连网络"></a>分布式内存互连网络</h5><p>分为两种</p><ul><li>直接互连 </li><li>间接互连</li></ul><p>1）直接互连</p><p>每个交换器都与一个处理器-内存对直接相连，交换器之间也互相连接</p><p>![image-20230220191821362](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220191821362.png)</p><p>和总线互连不同：P1，P2，P3可以同时信息交换，因为有交换器控制</p><p>2）间接互连（了解）</p><p>交换器不一定与处理器直接相连</p><p>例子</p><ul><li>交叉开关矩阵  和共享内存网络中的交叉矩阵不同   </li><li>Omega网络</li></ul><h5 id="评价网络好坏-（掌握）"><a href="#评价网络好坏-（掌握）" class="headerlink" title="评价网络好坏 （掌握）"></a>评价网络好坏 （掌握）</h5><p>等分<strong>宽度</strong>  针对分布式内存网络 中的 直接互连网络</p><p>衡量同时通信的链路数目 连接性</p><p>计算方法：计数去除最少的链路数从而将节点分为两份</p><p>环 等分宽度=2</p><p>![image-20230220194912747](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220194912747.png)</p><p>二维网格结构 p为处理器数目 </p><p>![image-20230220194747171](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220194747171.png)</p><p>带宽：传输数据的速度</p><p>等分带宽=带宽✖️等分宽度</p><p>如果在环中，链路的带宽是10亿位每秒，等分带 宽就是20亿位每秒</p><p>全相连网络 </p><p>![image-20230220195555960](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220195555960.png)</p><p>超立方体</p><p>递归构造</p><p>维度 d。</p><p>节点数<br>$$<br>p=2^d<br>$$<br>等分宽度<br>$$<br>p/2<br>$$</p><p>总结</p><table><thead><tr><th align="center">结构</th><th>环</th><th>二维环面</th><th></th><th>超立方体</th><th>全相连</th></tr></thead><tbody><tr><td align="center">等分宽度</td><td>2</td><td>![image-20230220200426667](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220200426667.png)</td><td></td><td>p/2</td><td>![image-20230220200530472](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220200530472.png)</td></tr></tbody></table><h3 id="并行程序设计的复杂性"><a href="#并行程序设计的复杂性" class="headerlink" title="并行程序设计的复杂性"></a>并行程序设计的复杂性</h3><ul><li>足够的并发度</li><li>并发粒度<ul><li>独立的计算任务的大小</li></ul></li><li>局部性<ul><li>临近数据</li></ul></li><li>负载均衡<ul><li>处理器任务量相近</li></ul></li><li>协调和同步</li></ul><h3 id="并行算法设计（竞争条件-数据依赖-同步等概念）"><a href="#并行算法设计（竞争条件-数据依赖-同步等概念）" class="headerlink" title="并行算法设计（竞争条件 数据依赖 同步等概念）"></a>并行算法设计（竞争条件 数据依赖 同步等概念）</h3><p>额外开销</p><ul><li>进程间通信 最大开销</li><li>进程空闲 负载不均、同步操作、不能并行化的部分</li><li>额外计算</li></ul><p>W8L1里面</p><p>看书</p><p>或者W4L1乱七八糟</p><p>飞书共享空间ppt上没有</p><p>原子性:一组操作要么全部执行，要么全不执行。</p><p>临界区:一个更新共享资源的<strong>代码段</strong>，一次只能允许一个线程执行该代码段</p><p>竞争条件:多个进程/线程尝试<strong>更新同一个共享资源</strong>时，结果可能是无法预测的，则存在竞争条件。</p><p>数据依赖(data dependence):两个<strong>内存操作的序</strong>，为了保证结果的正确性，必须保持这个序。</p><p>同步(synchronization) :在时间上强制使执各行进程/线程在某一点等待，确保各进程/线程的正常顺 序和对共享可写数据的正确访问。</p><p>互斥:任何时刻都只有一个线程在执行<br>互斥量:互斥锁的简称，用来限制每次只有一个线程能进入临界区。保证了一个线程独享临界区。<br>障碍:阻碍线程继续执行，在此程序点等待，直到所有参与线程都达到障碍点才能继续执行</p><h3 id="并行算法性能分析（加速比-效率-可扩展性-阿姆达尔定律）"><a href="#并行算法性能分析（加速比-效率-可扩展性-阿姆达尔定律）" class="headerlink" title="并行算法性能分析（加速比 效率 可扩展性 阿姆达尔定律）"></a>并行算法性能分析（加速比 效率 可扩展性 阿姆达尔定律）</h3><p>串行：时间复杂度</p><h4 id="加速比。"><a href="#加速比。" class="headerlink" title="加速比。"></a>加速比。</h4><p>谁比谁‼️ 串行比并行</p><p>![image-20230220215838708](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220215838708.png)</p><p>选最优（没有最优的话选择普遍使用的）</p><p>例子：n个数相加</p><p>串行 O（n）</p><p>并行 树形结构 深度为logn 包括加法时间   数据传输时间=启动传输时间+传输过程时间 Tp=O（3logn）</p><p>![image-20230220220921233](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220220921233.png)</p><p>例子</p><p>串行起泡排序150s 串行快速排序30s 并行起泡排序40</p><p>S=<strong>30</strong>/40=0.75</p><p>p为核数</p><ul><li>一般S&lt;=p</li><li>S=p 称该并行算法有<strong>线性加速比</strong></li><li>S&gt;p 超线性加速比 （了解即可</li></ul><h4 id="阿姆达尔定律"><a href="#阿姆达尔定律" class="headerlink" title="阿姆达尔定律"></a>阿姆达尔定律</h4><p>可并行化比例有限</p><p>![image-20230220223405214](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220223405214.png)</p><p>只和a和p有关系，和时间没关系</p><p>例子</p><p>![image-20230220223151683](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220223151683.png)</p><p>S&lt;10</p><p>阿姆达尔定律：通过并行化产生的加速比受限</p><h4 id="效率"><a href="#效率" class="headerlink" title="效率"></a>效率</h4><p>![image-20230220223729564](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230220223729564.png)</p><p> 例子</p><p>串行排序算法例子🌟</p><h4 id="可扩展性"><a href="#可扩展性" class="headerlink" title="可扩展性"></a>可扩展性</h4><p>强可扩展。  问题规模不变。 很难达到</p><p>弱可扩展   问题规模增大</p><h2 id="SIMD-1"><a href="#SIMD-1" class="headerlink" title="SIMD"></a>SIMD</h2><p>适合应用的特点</p><ul><li>连续存储的</li><li>短数据类型 8、16、32位</li><li>流式数据处理 时间局部性 数据流重用</li></ul><h3 id="选择"><a href="#选择" class="headerlink" title="选择"></a>选择</h3><p>应用 </p><p>SSE AVX CUDA GPU 协处理器Xeon Phi 没有占压倒优势 科学计算</p><p>向量长度=寄存器宽度/类型大小</p><p>C/C++：内置函数、 intrinsics</p><h3 id="SIMD编程的问题（打包解包、对其开销、控制流开销）"><a href="#SIMD编程的问题（打包解包、对其开销、控制流开销）" class="headerlink" title="SIMD编程的问题（打包解包、对其开销、控制流开销）"></a>SIMD编程的问题（打包解包、对其开销、控制流开销）</h3><p>打包解包开销</p><p>打包 拷贝到连续内存区域</p><p>解包 拷贝回内存</p><p>对齐开销</p><p>未对齐的数据可能产生不正确的结果a</p><p>控制流 所有语句必须执行</p><p>分支语句</p><p>存在控制流问题时，SIMD不是一个好的编程模型</p><h3 id="SIMD编程-W6L1"><a href="#SIMD编程-W6L1" class="headerlink" title="SIMD编程  W6L1"></a>SIMD编程  W6L1</h3><p>X86 32位</p><p>X64 64位 </p><p>SSE <strong>8个128位</strong>的向量寄存器</p><p>AVX <strong>16个256位</strong>的向量寄存器</p><p>MMX 8个64位</p><p>支持数据类型 128位=16字节</p><p>整数 16字节、8short</p><table><thead><tr><th>数据类型</th><th>名字</th><th>字节</th><th>能放几个</th></tr></thead><tbody><tr><td>dqword</td><td></td><td>16</td><td>1</td></tr><tr><td>short</td><td></td><td>2</td><td>8</td></tr><tr><td>int</td><td></td><td>4</td><td>4</td></tr><tr><td>long</td><td></td><td>8</td><td>2</td></tr><tr><td>float</td><td>单精度浮点数</td><td>4</td><td>4</td></tr><tr><td>double</td><td>双精度浮点数</td><td>8</td><td>2</td></tr><tr><td>char</td><td></td><td>2</td><td></td></tr></tbody></table><p>SSE指令</p><ul><li>数据移动指令 将数据移入/出向量寄存器</li><li>算术指令 多个数据（2doubles，4floats上的算术指令）</li><li>逻辑指令 多个数据上的逻辑运算</li><li>比较指令 多个数据上的比较运算</li><li>洗牌指令 在SIMD寄存器内移动数据</li></ul><p>SSE版本向量乘法</p><p>![image-20230221152105512](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230221152105512.png)</p><p>![image-20230221152048150](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230221152048150.png)</p><h2 id="Pthread"><a href="#Pthread" class="headerlink" title="Pthread"></a>Pthread</h2><p>并行程序设计的复杂性</p><p>Pthread一些基础API</p><p>同步相关概念</p><p>![image-20230221200946496](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230221200946496.png)</p><p>忙等待 互斥量 信号量 障碍 </p><p>负载均衡 任务划分</p><p>![image-20230224185347606](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230224185347606.png)</p><h2 id="MPI"><a href="#MPI" class="headerlink" title="MPI"></a>MPI</h2><p>![image-20230224194958501](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230224194958501.png)</p><p>隔离了独立地址空间</p><p>不会有数据竞争 但是可能有通信错误</p><p>暴露了执行模型，迫使程序员思考局部性，两点对性能都有好处</p><p>代码复杂</p><p>无共享变量 通信、同步都需要调用函数完成</p><p>提供以下类别的函数</p><p>通信</p><p>点对点通信 消息从特定的发送进程到特定的接受进程</p><p>多处理器参与的组通信</p><p>同步</p><p>障碍</p><p>无锁 没有共享变量需要保护</p><p>查询</p><p>允许接受的量比指定少，接收到更多数据就是错误</p><p>强数据类型传输</p><p>消息中的数据用三元组（地址、个数、类型）描述</p><p>send receive完成了数据传输 同步</p><h3 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h3><p>![image-20230224215719598](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230224215719598.png)</p><h3 id="混合编程"><a href="#混合编程" class="headerlink" title="混合编程"></a>混合编程</h3><p>![image-20230224221353584](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230224221353584.png)</p><p>所有MPI实现均支持MPI_THREAD_SINGLE</p><h2 id="绪论"><a href="#绪论" class="headerlink" title="绪论"></a>绪论</h2><h3 id="推动并行计算的原因"><a href="#推动并行计算的原因" class="headerlink" title="推动并行计算的原因"></a>推动并行计算的原因</h3><p>频率已经不是处理器发展的主角 </p><p>功耗/散热的限制 </p><p>性能上升放缓 </p><p>多核、众核成为之后CPU的发展趋势</p><h3 id="超算发展"><a href="#超算发展" class="headerlink" title="超算发展"></a>超算发展</h3><p>Top 1 Frontier：性能最强，能效最高</p><p>我国Top1：神威·太湖之光 自研的 2016</p><p>2020年，Summit，获得戈登贝尔奖的是中美合 作的团队 夺冠，“基于机器学习将分子动力学 计算精度极限推广到1亿个原子”</p>]]></content>
      
      
      <categories>
          
          <category> 并行程序设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 并行程序设计 </tag>
            
            <tag> 知识总结 </tag>
            
            <tag> S5复习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>并行程序设计-实验5.MPI编程练习</title>
      <link href="/2022/11/28/mpi-bian-cheng-lian-xi-shi-yan-bao-gao/"/>
      <url>/2022/11/28/mpi-bian-cheng-lian-xi-shi-yan-bao-gao/</url>
      
        <content type="html"><![CDATA[<h1 id="MPI-编程练习实验报告"><a href="#MPI-编程练习实验报告" class="headerlink" title="MPI 编程练习实验报告"></a>MPI 编程练习实验报告</h1><h2 id="实验内容"><a href="#实验内容" class="headerlink" title="实验内容"></a>实验内容</h2><ul><li>实现第5章课件中的梯形积分法的MPI编程熟悉并掌握MPI编程方法，规模自行设定，可探讨不同规模对不同实现方式的影响。</li><li>对于课件中“多个数组排序”的任务不均衡案例进行MPI编程实现，规模可自己设定、调整。</li><li>附加：实现高斯消去法解线性方程组的MPI编程，与SSE（或AVX）编程结合，并与Pthread、OpenMP（结合SSE或AVX）版本对比，规模自己设定。</li></ul><h2 id="实验一：梯形积分"><a href="#实验一：梯形积分" class="headerlink" title="实验一：梯形积分"></a>实验一：梯形积分</h2><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>本实验分别使用MPI、Pthread和OpenMP三种方法，实现了梯形积分法。并通过调整梯形积分法划分成小梯形的个数规模，来比较不同编程方式的异同。</p><p>具体案例为：对于下图中给出的梯形积分法，实现并行编程。每个线程或进程计算a到b区间中的某一段的梯形面积，最后求取全局和得到结果。</p><p>![image-20230102165554905](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230102165554905.png)</p><h3 id="程序设计与实现"><a href="#程序设计与实现" class="headerlink" title="程序设计与实现"></a>程序设计与实现</h3><h4 id="MPI实现"><a href="#MPI实现" class="headerlink" title="MPI实现"></a>MPI实现</h4><p>实验共用到了3台主机的进程进行计算。每个进程根据自己的my_rank进程号得到自身的计算任务，完成局部和的计算后，（除0号进程外）使用MPI_Send将结果发送至0号进程；0号进程使用MPI_Recv阻塞式地接受其他进程传回的结果，并计算全局和。同时，0号进程还完成计时、输出结果的任务。具体的实现代码如下：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">#include &lt;stdio.h&gt;#include &lt;algorithm&gt;#include&lt;cstdlib&gt;#include&lt;ctime&gt;#include&lt;mpi.h&gt;//待积分的f(x)double f(double x) {    return 1;}//计算局部和double Trap(double a, double b, int count, double h) {    double my_result, x;    int i;    my_result = (f(a) + f(b)) / 2.0;    //局部求和，避免过多通信    for (i = 1; i &lt; count; i++) {        x = a + i * h;        my_result += f(x);    }    my_result *= h;    return my_result;}//主函数int main(){    int my_rank, comm_sz, n = 1000;    double a = 0, b = 5000;    double h = (b - a) / n;    double global_result;    clock_t start, end;    double time;    MPI_Init(NULL, NULL);    MPI_Comm_rank(MPI_COMM_WORLD, &amp;my_rank);    MPI_Comm_size(MPI_COMM_WORLD, &amp;comm_sz);    //0号进程开始计时    if (my_rank == 0) {        start = clock();    }    int local_n = n / comm_sz;    int local_a = a + my_rank * local_n * h;    int local_b = local_a + local_n * h;    //将未除尽的任务数分配给最后一个进程    if (my_rank == comm_sz - 1) {        local_n = n - (comm_sz - 1) * local_n;        local_b = b;    }    //每个进程计算自身分配的任务的局部和    double local_result = Trap(local_a, local_b, local_n, h);    //其他进程将局部和发送给0号进程    if (my_rank != 0) {        MPI_Send(&amp;local_result, 1, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD);    }    //0号进程收集局部和并求全局和    else {        global_result = local_result;        for (int source = 1; source &lt; comm_sz; source++)        {            MPI_Recv(&amp;local_result, 1, MPI_DOUBLE, source, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);            global_result += local_result;        }        //完成计算，0号进程停止计时        end = clock();        time = (end - start) / CLOCKS_PER_SEC;    }    //0号进程打印出结果    if (my_rank == 0) {        printf("划分成小梯形的块数: %d\n", n);        printf("计算结果是: %.15e\n", global_result);        printf("总共耗时: %f\n\nms", time);    }    MPI_Finalize();    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Pthread实现"><a href="#Pthread实现" class="headerlink" title="Pthread实现"></a>Pthread实现</h4><p>对于每个线程，先求局部和最后全局求和，避免过多通信。同时注意给全局和加锁保证结果的正确性。代码实现如下：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">void pthread_trap(double a,double b,int n,double*global_result_p,int thread_count){    pthread_param params[thread_count];    pthread_t threads[thread_count];    pthread_mutex_t amutex;    pthread_mutex_init(&amp;amutex,NULL);    for(int i=0;i&lt;thread_count;i++){        //为每个线程参数赋值        params[i].a=a;        params[i].b=b;        params[i].n=n;        params[i].global_result_p=global_result_p;        params[i].thread_count=thread_count;        params[i].my_rank=i;        params[i].amutex=&amp;amutex;        //创建线程        pthread_create(&amp;threads[i],NULL,pthread_trap,(void*)&amp;params[i]);    }    //销毁线程    for(int i=0;i&lt;thread_count;i++){        pthread_join(threads[i],NULL);    }    //销毁互斥量锁    pthread_mutex_destroy(&amp;amutex);}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中每个线程执行的函数如下：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">void* pthread_trap(void* p){    //恢复获取参数    pthread_param* params=(pthread_param*) p;    double h,x,my_result;    double local_a,local_b;    int local_n;    int my_rank=params-&gt;my_rank;    int thread_count=params-&gt;thread_count;    h=(params-&gt;b-params-&gt;a)/params-&gt;n;    local_n=params-&gt;n/thread_count;    local_a=params-&gt;a+my_rank*local_n*h;    local_b=local_a+local_n*h;    my_result=(f(local_a)+f(local_b))/2.0;    //先局部求和，避免过多通信    for(int i=1;i&lt;=local_n-1;i++){        x=local_a+i*h;        my_result+=f(x);    }    my_result=my_result*h;    //使用互斥量 amutex 上锁保证全局求和正确性    pthread_mutex_lock(params-&gt;amutex);    *params-&gt;global_result_p+=my_result;    pthread_mutex_unlock(params-&gt;amutex);}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="OpenMP实现"><a href="#OpenMP实现" class="headerlink" title="OpenMP实现"></a>OpenMP实现</h4><p>利用OpenMP的相关方法实现多线程并行编程，对于每个线程，先求局部和最后全局求和，避免过多通信。同时注意给全局和加锁保证结果的正确性。代码实现如下：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">#pragma omp parallel num_threads(thread_count)trap(a,b,n,&amp;global_result);void trap(double a,double b,int n,double*global_result_p){    double h,x,my_result;    double local_a,local_b;    int local_n;    int my_rank=omp_get_thread_num();    int thread_count=omp_get_num_threads();    h=(b-a)/n;    local_n=n/thread_count;    local_a=a+my_rank*local_n*h;    local_b=local_a+local_n*h;    my_result=(f(local_a)+f(local_b))/2.0;    //先局部求和，避免过多通信    for(int i=1;i&lt;=local_n-1;i++){        x=local_a+i*h;        my_result+=f(x);    }    my_result=my_result*h;    //用临界区保证全局求和正确性    #pragma omp critical        *global_result_p+=my_result;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="实验设计"><a href="#实验设计" class="headerlink" title="实验设计"></a>实验设计</h3><h4 id="不同任务规模下三种方法执行时间对比"><a href="#不同任务规模下三种方法执行时间对比" class="headerlink" title="不同任务规模下三种方法执行时间对比"></a>不同任务规模下三种方法执行时间对比</h4><p>待计算函数为 f(x) = 1；待计算区间为0到5000。将积分区域分别划分为100，1000，10000，100000个小梯形，比较3种方法在这些不同的任务规模下执行效率的差异。</p><h4 id="计时方法"><a href="#计时方法" class="headerlink" title="计时方法"></a>计时方法</h4><ul><li><p>MPI版本使用的计时方法如下：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">start = clock();end = clock();time = (end - start) / CLOCKS_PER_SEC;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>Pthread和OpenMP版本继续沿用之前实验中用到的计时方法</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">QueryPerformanceFrequency((LARGE_INTEGER *)&amp;freq);QueryPerformanceCounter((LARGE_INTEGER *)&amp;head);          QueryPerformanceCounter((LARGE_INTEGER *)&amp;tail);  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ul><h3 id="不同规模下3种方法的结果展示与对比"><a href="#不同规模下3种方法的结果展示与对比" class="headerlink" title="不同规模下3种方法的结果展示与对比"></a>不同规模下3种方法的结果展示与对比</h3><h4 id="程序输出结果"><a href="#程序输出结果" class="headerlink" title="程序输出结果"></a>程序输出结果</h4><p>待计算函数为 f(x) = 1；待计算区间为0到5000</p><ol><li><p>将MPI的运行环境及程序部署到华为鲲鹏云服务器上，得到示例输出如下：</p><p>![image-20230102211323833](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230102211323833.png)</p></li><li><p>编辑器为codeblocks，编译器为mingw64，得到Pthread版本和OpenMP版本的示例输出如下：</p><p>![image-20230102193907704](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230102193907704.png)</p><p>从上述截图中看出，三种实现方式均按照预期效果输出，程序正确。</p></li></ol><h4 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h4><p>按照上述的实验设计执行程序，得到经过分析处理后的图表如下：</p><table><thead><tr><th></th><th>100</th><th>1000</th><th>10000</th><th>100000</th></tr></thead><tbody><tr><td>MPI</td><td>4ms</td><td>5ms</td><td>11ms</td><td>13ms</td></tr><tr><td>Pthread</td><td>13ms</td><td>15ms</td><td>16ms</td><td>19ms</td></tr><tr><td>OpenMP</td><td>7ms</td><td>9ms</td><td>12ms</td><td>14ms</td></tr></tbody></table><p>![image-20230102211927911](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230102211927911.png)</p><p>根据上述图表可以看出，几种实现方式的性能差异并不明显，可能是因为该计算任务本身复杂度较低，三种方式均能快速完成，故无法很好地展现出不同方法的性能差异。单从本实验的表现来看，MPI的执行效率相对来说更高一点，可能是因为多台主机多个进程多个CPU确实会更快一些。当然，这种性能上的优秀表现仅在平均值中体现（上述图表中的数据是多次实验取平均后得到的结果），在某些情况下，MPI方法的执行时间也会出现较长的现象，猜想可能是因为使用云服务器传输数据的过程耗时较长导致。</p><h3 id="实验总结"><a href="#实验总结" class="headerlink" title="实验总结"></a>实验总结</h3><p>通过本实验，我熟悉并掌握MPI编程方法，在探讨不同规模对不同实现方式的影响，我了解到了多台主机共同完成同一计算任务的思想以及在本实验中的优秀表现。不过本实验中MPI、Pthread、OpenMP三种方法的性能差异并不是特别明显，这也是本实验可以继续改进优化的一个方向。</p><h2 id="实验二：数组排序的任务分配不均衡案例复现"><a href="#实验二：数组排序的任务分配不均衡案例复现" class="headerlink" title="实验二：数组排序的任务分配不均衡案例复现"></a>实验二：数组排序的任务分配不均衡案例复现</h2><h3 id="问题描述-1"><a href="#问题描述-1" class="headerlink" title="问题描述"></a>问题描述</h3><p>对ARR_NUM个长度为ARR_LEN的一维数组进行排序，使用MPI编程，每个进程处理一部分数组排序的任务。若数组分布不均衡，如前二分之一的数组全部升序，后二分之一的数组全部逆序，则每个进程分得的任务负载可能也会不均衡。</p><h3 id="程序设计与实现-1"><a href="#程序设计与实现-1" class="headerlink" title="程序设计与实现"></a>程序设计与实现</h3><p>实验共用到了3台主机的进程完成数组排序。根据进程号连续划分任务，每个进程完成排序之后，将自己执行任务的耗时传送给0号进程，最终0号进程接受各个进程完成排序任务的时间并输出。具体的实现代码如下：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">#include &lt;iostream&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;time.h&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;mpi.h&gt;using namespace std;//数组数量const int ARR_NUM = 3000;//每个数组的长度const int ARR_LEN = 300;//进程数量/主机数量const int PROCESS_NUM = 3;//每个进程处理的数组数量const int seg = ARR_NUM / PROCESS_NUM;vector&lt;int&gt; arr[ARR_NUM];// 初始化待排序数组，使得// 第一段：完全逆序// 第二段：1/2逆序，1/2升序// 第三段：1/4逆序，3/4升序// 第四段：完全升序void init(void) {    int ratio;    srand(unsigned(time(nullptr)));    for (int i = 0; i &lt; ARR_NUM; i++) {        arr[i].resize(ARR_LEN);        if (i &lt; seg)ratio = 0;        else if (i &lt; seg * 2)ratio = 32;        else ratio = 128;        if ((rand() &amp; 127) &lt; ratio) {            for (int j = 0; j &lt; ARR_LEN; j++) {                arr[i][j] = ARR_LEN - j;            }        }        else {            for (int j = 0; j &lt; ARR_LEN; j++) {                arr[i][j] = j;            }        }    }}//主函数int main() {    int my_rank, comm_sz;    clock_t start, end;    double time;    //初始化数组    init();    MPI_Init(NULL, NULL);    MPI_Comm_rank(MPI_COMM_WORLD, &amp;my_rank);    MPI_Comm_size(MPI_COMM_WORLD, &amp;comm_sz);    //根据进程号分配任务    int startTask = my_rank * seg;    int endTask = startTask + seg;    //排序    start = clock();    for (int i = startTask; i &lt; endTask; i++) {        sort(arr[i].begin(), arr[i].end());    }    end = clock();    time = (end - start);    //其他进程将本进程的运行时间发送给0号进程    if (my_rank != 0) {        MPI_Send(&amp;time, 1, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD);    }    //0号进程打印各个进程的运行时间    else if (my_rank == 0) {        printf("各进程运行时间如下:\n");        printf("0号进程: %fms\n", time);        for (int source = 1; source &lt; comm_sz; source++) {            MPI_Recv(&amp;time, 1, MPI_DOUBLE, source, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);            printf("%d号进程: %fms\n", source, time);        }    }    MPI_Finalize();    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="实验设计-1"><a href="#实验设计-1" class="headerlink" title="实验设计"></a>实验设计</h3><ul><li>使用init函数生成分布不均的数组；</li><li>使用与实验一（梯形积分法）中相同的计时方法。</li><li>改变数组规模，分别处理500，1000，1500，2000，2500，3000个长度为300的数组，比较在不同规模下各个进程的时间差异，从而理解任务负载不均衡对效率的影响。</li></ul><h3 id="结果展示与对比分析"><a href="#结果展示与对比分析" class="headerlink" title="结果展示与对比分析"></a>结果展示与对比分析</h3><h4 id="程序输出结果-1"><a href="#程序输出结果-1" class="headerlink" title="程序输出结果"></a>程序输出结果</h4><p>将MPI的运行环境及程序部署到华为鲲鹏云服务器上，得到示例输出如下：</p><p>注：本实验给每台主机分配了1个进程（在config文件中设置），总共有3个进程共同执行排序任务，故执行命令时为“3”</p><p>![截屏2023-01-02 21.32.52](/Users/zhangxiaoni/Desktop/截屏2023-01-02 21.32.52.png)</p><h4 id="图表结果分析"><a href="#图表结果分析" class="headerlink" title="图表结果分析"></a>图表结果分析</h4><p>经过分析处理后得到的图表结果展示如下：</p><table><thead><tr><th></th><th>500</th><th>1000</th><th>1500</th><th>2000</th><th>2500</th><th>3000</th></tr></thead><tbody><tr><td>0号进程</td><td>5240ms</td><td>10564ms</td><td>15789ms</td><td>21170ms</td><td>26619ms</td><td>31875ms</td></tr><tr><td>1号进程</td><td>5095ms</td><td>10224ms</td><td>15539ms</td><td>20340ms</td><td>25586ms</td><td>30774ms</td></tr><tr><td>2号进程</td><td>4712ms</td><td>9346ms</td><td>13974ms</td><td>18574ms</td><td>23425ms</td><td>28067ms</td></tr></tbody></table><p> ![image-20230102214239527](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230102214239527.png)</p><p>从上述图表中，我们大致可以看出，由于数据分布不均衡，各个进程的执行时间存在差异，具体表现为：0号、1号、2号进程的执行效率依次增大，这与他们各自的任务负载是保持一致的。在实际情况中，这些负载任务复杂度较高、执行时间较长的进程，会拖慢任务解决的整体时长，这是我们不希望看到的。</p><h3 id="实验总结-1"><a href="#实验总结-1" class="headerlink" title="实验总结"></a>实验总结</h3><p>​通过本实验，我了解到数据分布均衡对于多进程、多线程程序的重要性。如果任务分布不均，将会出现执行效率较低的进程拖慢任务解决的整体效率的情况。因此，并行编程时控制任务规模、控制任务分配的粗细粒度、控制进程或线程的数量，使得程序在数据分布不均衡的情况下也能有较为优秀的表现就显得很重要。当然，也可以在程序执行任务之前，对数据进行处理，达到各个进程分配的数据分布都较为均衡的效果。</p><h2 id="附加实验：高斯消去法解线性方程组"><a href="#附加实验：高斯消去法解线性方程组" class="headerlink" title="附加实验：高斯消去法解线性方程组"></a>附加实验：高斯消去法解线性方程组</h2><h3 id="问题描述-2"><a href="#问题描述-2" class="headerlink" title="问题描述"></a>问题描述</h3><p>对于给定的线性方程组Ax=b，使用MPI编程，完成对于线性方程组的高斯消元。</p><h3 id="程序设计与实现-2"><a href="#程序设计与实现-2" class="headerlink" title="程序设计与实现"></a>程序设计与实现</h3><p>每个进程完成部分行的消元计算任务，然后使用barrier功能，使得所有进程均完成第k行的消元后再计算下一行的消元。程序实现的具体代码如下：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">#include &lt;stdio.h&gt;#include&lt;iostream&gt;#include &lt;algorithm&gt;#include&lt;cstdlib&gt;#include&lt;ctime&gt;#include&lt;mpi.h&gt;using namespace std;const int n = 900;const int NUM_PROC = 3;float a[n][n], b[n], c[n];void init() {    for (int i = 0; i &lt; n; i++) {        for (int j = 0; j &lt; n; j++) {            a[i][j] = rand() % (1000 - 1) + 1;        }        b[i] = rand() % (1000 - 1) + 1;    }}int main() {    int my_rank, comm_sz, left, right;    int source;    clock_t start, finish;    double sec;    init();    MPI_Init(NULL, NULL);    MPI_Comm_rank(MPI_COMM_WORLD, &amp;my_rank);    MPI_Comm_size(MPI_COMM_WORLD, &amp;comm_sz);    start = clock();    for (int k = 0; k &lt; n - 1; k++) {        int seg = (n - (k + 1)) / NUM_PROC;        left = my_rank * seg;        right = (my_rank + 1) * seg;        for (int i = left; i &lt; right; i++) {            c[i] = a[i][k] / a[k][k];        }        for (int i = left; i &lt; right; i++) {            for (int j = 0; j &lt; n; j++) {                a[i][j] = a[i][j] - c[i] * a[k][j];            }            b[i] = b[i] - c[i] * b[k];        }        MPI_Barrier(MPI_COMM_WORLD);    }    finish = clock();    sec = finish - start;    if (my_rank != 0) {        MPI_Send(&amp;sec, 1, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD);    }    else {        printf("0号进程: %f\n", sec);        for (source = 1; source &lt; comm_sz; source++) {            MPI_Recv(&amp;sec, 1, MPI_DOUBLE, source, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);            printf("%d号进程: %f\n", source, sec);        }    }    MPI_Finalize();    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="实验总结-2"><a href="#实验总结-2" class="headerlink" title="实验总结"></a>实验总结</h3><p>该部分尝试对高斯消元法进行了的MPI的编程实现，其中也遇到了很多困难，比如数据依赖等问题。经过反复尝试，我实现了高斯消元MPI的解法，使得我对于MPI编程中需要注意的内存共享的问题有了更深刻的理解。</p>]]></content>
      
      
      <categories>
          
          <category> 并行程序设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 并行程序设计 </tag>
            
            <tag> S5课上 </tag>
            
            <tag> 实验报告 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>并行程序设计-第六讲.MPI编程</title>
      <link href="/2022/11/13/di-liu-jiang-mpi-bian-cheng/"/>
      <url>/2022/11/13/di-liu-jiang-mpi-bian-cheng/</url>
      
        <content type="html"><![CDATA[<h1 id="第六讲-MPI编程"><a href="#第六讲-MPI编程" class="headerlink" title="第六讲 MPI编程"></a>第六讲 MPI编程</h1><h2 id="MPI概念和基本原语"><a href="#MPI概念和基本原语" class="headerlink" title="MPI概念和基本原语"></a>MPI概念和基本原语</h2><h3 id="消息传递和MPI"><a href="#消息传递和MPI" class="headerlink" title="消息传递和MPI"></a>消息传递和MPI</h3><ul><li>消息传递是超级计算机和集群主要的编程模型</li><li>MPI是什么<ul><li>消息传递编程模型标准，取代专有库</li><li>编程角度</li><li>基于单程序多数据流（SPMD）</li><li>隔离了独立地址空间<ul><li>不会有数据竞争，但可能有通信错误</li></ul></li></ul></li></ul><h3 id="消息传递库特性"><a href="#消息传递库特性" class="headerlink" title="消息传递库特性"></a>消息传递库特性</h3><ul><li><p>所有通信、同步都需调用函数完成</p><ul><li><strong>无共享变量</strong></li></ul></li><li><p>提供如下类别的函数</p><ul><li><p>通信</p><ul><li>点对点通信：消息从特性的发送<strong>进程</strong>（点A）发送到特定的接收进程（点B）</li><li>多处理器参与的组通信<ul><li>移动数据：广播、散发/收集</li><li>计算并移动数据：归约、全归约</li></ul></li></ul></li><li><p>同步</p><ul><li>障碍</li><li>无锁机制，因为没有共享变量需要保护</li></ul></li><li><p>查询</p><ul><li>多少个进程？哪个是我？有处于等待状态的信息？</li></ul></li></ul></li></ul><h3 id="基本接口"><a href="#基本接口" class="headerlink" title="基本接口"></a>基本接口</h3><ul><li>MPI_Comm_size报告进程数<ul><li>int MPI_Comm_size(MPI_Comm comm,int *size)</li></ul></li><li>MPI_Comm_rank报告识别调用进程的rank，值从0～size-1<ul><li>int MPI_Comm_rank(MPI_Comm comm,int *rank)</li></ul></li></ul><h4 id="编译–Linux平台"><a href="#编译–Linux平台" class="headerlink" title="编译–Linux平台"></a>编译–Linux平台</h4><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221121144656484.png" alt="image-20221121144656484"></p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221121144808070.png" alt="image-20221121144808070"></p><h4 id="运行MPI程序"><a href="#运行MPI程序" class="headerlink" title="运行MPI程序"></a>运行MPI程序</h4><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221121145434261.png" alt="image-20221121145434261"></p><h4 id="MPI初始化和结束处理"><a href="#MPI初始化和结束处理" class="headerlink" title="MPI初始化和结束处理"></a>MPI初始化和结束处理</h4><ul><li><p>MPI_Init</p><ul><li>令MPI进行必要的初始化工作</li><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221121145615335.png" alt="image-20221121145615335"></li></ul></li><li><p>MPI_Finalize</p><ul><li>告诉MPI程序已结束，进行清理工作</li><li>int MPI_Finalize(void)</li></ul></li></ul><h4 id="MPI程序基本结构"><a href="#MPI程序基本结构" class="headerlink" title="MPI程序基本结构"></a>MPI程序基本结构</h4><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221121145951697.png" alt="image-20221121145951697"></p><h3 id="MPI消息传递"><a href="#MPI消息传递" class="headerlink" title="MPI消息传递"></a>MPI消息传递</h3><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221121150207143.png" alt="image-20221121150207143"></p><ul><li>消息传递最基本的函数：<ul><li>send <ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221121151703266.png" alt="image-20221121151703266"></li></ul></li><li>receive<ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221121151832262.png" alt="image-20221121151832262"></li></ul></li></ul></li><li><h2 id="需要明确-如何描述数据-MPI强数据类型-在传输之前必须指明数据是什么类型、数据个数等信息-如何标识进程-rank-接收方如何识别信息"><a href="#需要明确-如何描述数据-MPI强数据类型-在传输之前必须指明数据是什么类型、数据个数等信息-如何标识进程-rank-接收方如何识别信息" class="headerlink" title="需要明确- 如何描述数据  - MPI强数据类型  - 在传输之前必须指明数据是什么类型、数据个数等信息- 如何标识进程  - rank- 接收方如何识别信息"></a>需要明确<br>- 如何描述数据<br>  - MPI强数据类型<br>  - 在传输之前必须指明数据是什么类型、数据个数等信息<br>- 如何标识进程<br>  - rank<br>- 接收方如何识别信息</h2><ul><li>操作完成意味着什么</li></ul></li></ul><h3 id="一些基本概念"><a href="#一些基本概念" class="headerlink" title="一些基本概念"></a>一些基本概念</h3><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221121152126455.png" alt="image-20221121152126455"></p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221121152225212.png" alt="image-20221121152225212"></p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221121152446813.png" alt="image-20221121152446813"></p><p>这块看pppt</p><h2 id="MPI编程模型"><a href="#MPI编程模型" class="headerlink" title="MPI编程模型"></a>MPI编程模型</h2>]]></content>
      
      
      <categories>
          
          <category> 并行程序设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 并行程序设计 </tag>
            
            <tag> S5课上 </tag>
            
            <tag> 知识总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>并行程序设计-实验4.OpenMP编程练习</title>
      <link href="/2022/10/22/openmp-bian-cheng-lian-xi/"/>
      <url>/2022/10/22/openmp-bian-cheng-lian-xi/</url>
      
        <content type="html"><![CDATA[<h1 id="OpenMP-编程练习"><a href="#OpenMP-编程练习" class="headerlink" title="OpenMP 编程练习"></a>OpenMP 编程练习</h1><h2 id="实验内容"><a href="#实验内容" class="headerlink" title="实验内容"></a>实验内容</h2><ol><li>分别实现课件中的梯形积分法的 Pthread、OpenMP 版本， 熟悉并掌握 OpenMP 编程方法，探讨两种编程方式的异同。</li><li>对于课件中“多个数组排序”的任务不均衡案例进行 OpenMP 编程实现（规模可自己调整），并探索不同循环调度方案的优劣。提示：可从任务分块的大小、线程数的多少、静态动态多线程结合等方面进行尝试，探索规律。</li><li>附加题：实现高斯消去法解线性方程组的 OpenMP 编程，与 SSE/AVX 编程结合，并探索优化任务分配方法。</li></ol><h2 id="梯形积分法"><a href="#梯形积分法" class="headerlink" title="梯形积分法"></a>梯形积分法</h2><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>​对于下图中给出的梯形积分法，实现多线程编程。每个线程实现 a 到 b 区间中的某一段的梯形积分的计算。</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221204172704931.png" alt="image-20221204172704931"></p><h3 id="算法设计与实现"><a href="#算法设计与实现" class="headerlink" title="算法设计与实现"></a>算法设计与实现</h3><h4 id="使用Pthread实现"><a href="#使用Pthread实现" class="headerlink" title="使用Pthread实现"></a>使用Pthread实现</h4><p>​对于每个线程，先求局部和最后全局求和，避免过多通信。同时注意给全局和加锁保证结果的正确性。代码实现如下：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">void calculate_differential(int i) {    double x = a + i * h;    double currArea = func(x) * h;    pthread_mutex_lock(&amp;barrier_mutex);    totalPthread += currArea;    pthread_mutex_unlock(&amp;barrier_mutex);}void *Cal_pthread(void *parm) {    int task = 0;    while (true) {        pthread_mutex_lock(&amp;barrier_mutex);        next_task += seg;        task = next_task;        pthread_mutex_unlock(&amp;barrier_mutex);        if (task &gt;= n + seg)            break;        else {            for (int i = task - seg; i &lt; (task &lt; n ? task : n); i++) {                calculate_differential(i);            }        }    }    pthread_exit(nullptr);}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="使用OpenMP实现"><a href="#使用OpenMP实现" class="headerlink" title="使用OpenMP实现"></a>使用OpenMP实现</h4><p>​利用 OpenMP 的相关方法实现多线程并行编程，思路与 Pthread 编程类似。代码实现如下：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">void Trap(double a, double b, double h, int n, double *global_result_p) {    double x, my_result;    double local_a, local_b;    int i, local_n;    int my_rank = omp_get_thread_num();    int thread_count = omp_get_num_threads();    local_n = n / thread_count;    local_a = a + my_rank * local_n * h;    local_b = local_a + local_n * h;    my_result = (func(local_a) + func(local_b)) / 2.0;    for (i = 1; i &lt;= local_n; i++) {        x = local_a + i * h;        my_result += func(x);    }    my_result = my_result * h;# pragma omp critical    *global_result_p += my_result;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="实验结果分析"><a href="#实验结果分析" class="headerlink" title="实验结果分析"></a>实验结果分析</h3><p>​将待积分的函数设置为2*x^2-x，积分区间从2到10，将整个图形划分为2000个小梯形。根据实验结果，可以看出多线程和OpenMP实验结果相同，梯形面积都为613.333。</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221204211530816.png" alt="image-20221204211530816"></p><h3 id="Pthread-和-OpenMP-两种编程方式异同比较"><a href="#Pthread-和-OpenMP-两种编程方式异同比较" class="headerlink" title="Pthread 和 OpenMP 两种编程方式异同比较"></a>Pthread 和 OpenMP 两种编程方式异同比较</h3><ol><li>Pthread 在程序启动时创建线程，再将工作分配到线程上。然而，这种方法需要相当多的线程指定代码，而且不能保证能够随着可用处理器的数量而合理地进行扩充。OpenMP 不需要指定数量，在有循环的地方加上代码，修改设置文件即可。OpenMP 非常方便，因为它不会将软件锁定在事先设定的线程数量中，但是相对的查错更难也更麻烦。 </li><li>OpenMP 和 Pthread 之间的区别主要在编译的方式上，OpenMP 的编译需要添加编译器预 处理指令#pragma，创建线程等后续工作要编译器来完成。而 pthread 就是一个库，所有的 并行线程创建都需要我们自己完成，较 OpenMP 麻烦一点。但如果开发人员需要精细纹理的控制，Pthread 能够提供更大范围的原函数，属于更优的选择。 </li><li>OpenMP 的编译指示还有另一项重要优势：通过禁用 OpenMP 支持，代码可用作为单 一线程应用进行编译。当调试程序时，以这样的方式编译代码拥有巨大优势。如果没有这种选择，开发人员会经常发现很难说明复杂的代码是否能够正确工作，因为线程问题或因为与线程无关的设计错误。</li></ol><h2 id="数组排序的任务分配不均衡案例复现"><a href="#数组排序的任务分配不均衡案例复现" class="headerlink" title="数组排序的任务分配不均衡案例复现"></a>数组排序的任务分配不均衡案例复现</h2><h3 id="问题描述-1"><a href="#问题描述-1" class="headerlink" title="问题描述"></a>问题描述</h3><p>​对 ARR_NUM 个长度为 ARR_LEN 的一维数组进行排序，使用 OpenMP 多线程编程，每个线程处理一部分数组。若数组分布不均衡，如前二分之一的数组全部升序，后二分之一的数组全部逆序，则每个线程分得的任务负载可能也会不均衡。</p><h3 id="算法设计与实现-1"><a href="#算法设计与实现-1" class="headerlink" title="算法设计与实现"></a>算法设计与实现</h3><h4 id="均匀随机初始化数组"><a href="#均匀随机初始化数组" class="headerlink" title="均匀随机初始化数组"></a>均匀随机初始化数组</h4><p>​完全随机生成的各个数组内数据顺序完全随机，基本无差异。将数组列数设置为 2000，行数设置为 2000，线程数设置为 4，生成的数据大小范围在 0~10000 之间。</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">void init_uniform(void) {    srand(unsigned(time(nullptr)));    for (int i = 0; i &lt; ARR_NUM; i++) {        for (int j = 0; j &lt; ARR_LEN; j++)            arr[i][j] = rand() % 10000;    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="不均匀随机初始化数组"><a href="#不均匀随机初始化数组" class="headerlink" title="不均匀随机初始化数组"></a>不均匀随机初始化数组</h4><p>​不均匀随机初始化待排序数组，使得第一段数组完全逆序，第二段数组中 1/2 逆序，1/2 升序，第三段数组中 1/4 逆序，3/4 升序，第四段数组中完全升序。</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">// 不均匀初始化数组void init_uneven(void){    int ratio;    srand(unsigned(time(nullptr)));    for (int i = 0; i &lt; ARR_NUM; i++){        if(i &lt; seg) ratio = 0;        else if(i &lt; seg * 2) ratio = 32;        else if(i &lt; seg * 3) ratio = 64;        else ratio = 128;        if((rand() &amp; 127) &lt; ratio){            for(int j = 0; j &lt; ARR_LEN; j++)                arr[i][j] = ARR_LEN - j;        } else{            for(int j = 0; j &lt; ARR_LEN; j++)                arr[i][j] = j;        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="使用OpenMP对某块数组进行排序"><a href="#使用OpenMP对某块数组进行排序" class="headerlink" title="使用OpenMP对某块数组进行排序"></a>使用OpenMP对某块数组进行排序</h4><p>​指定task = next_arr += seg;在同一时间只能被一条线程执行，每次对seg块的数组进行排序。完成后线程再次领取新的任务，直至所有数组均已排序完成。</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">// OpenMP排序void OpenMP_sort() {    int task = 0;    while (true) {#pragma omp critical        task = next_arr += seg;        if (task &gt;= ARR_NUM + seg)            break;        for (int i = task - seg; i &lt; (task &lt; ARR_NUM ? task : ARR_NUM); i++)            sort_bubbling(arr[i]);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="控制粒度粗细"><a href="#控制粒度粗细" class="headerlink" title="控制粒度粗细"></a>控制粒度粗细</h4><p>​通过改变seg的大小，控制排序时每个线程分得的行数大小，从而改变粒度粗细。</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">    // 粗细粒度变化    THREAD_NUM = 4;    init_uniform();    rollover(arr, arrtemp);    for (seg = 10; seg &lt;= 100; seg += 10) {        rollover(arrtemp, arr);        next_arr = 0;        gettimeofday(&amp;startTime, NULL);#pragma omp parallel num_threads(THREAD_NUM)        OpenMP_sort();        gettimeofday(&amp;stopTime, NULL);    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="实验结果分析-1"><a href="#实验结果分析-1" class="headerlink" title="实验结果分析"></a>实验结果分析</h3><h4 id="均匀随机分布的数组排序"><a href="#均匀随机分布的数组排序" class="headerlink" title="均匀随机分布的数组排序"></a>均匀随机分布的数组排序</h4><h5 id="粒度变化"><a href="#粒度变化" class="headerlink" title="粒度变化"></a>粒度变化</h5><p>​程序输出样例如下：</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221204210335474.png" alt="image-20221204210335474"></p><p>​经过分析处理后得到的图表结果展示如下：</p><table><thead><tr><th>seg</th><th>10</th><th>20</th><th>30</th><th>40</th><th>50</th><th>60</th><th>70</th><th>80</th><th>90</th><th>100</th></tr></thead><tbody><tr><td>time</td><td>2234.3</td><td>2212.9</td><td>2208.4</td><td>2252.2</td><td>2202.4</td><td>2341.8</td><td>2290.4</td><td>2442.8</td><td>2324.2</td><td>2193.8</td></tr></tbody></table><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221204210451419.png" alt="image-20221204210451419"></p><p>​从上述实验结果可以看出，在数组完全随机，数组内数据分布均匀的情况下，粒度从40增加到90时，耗时波动起伏较大；在粒度大小为80时，耗时达到峰值。同时可以看出，在粒度大小等于50时，耗时处于低谷。</p><p>​证明在数组均匀随机分布的情况下，粒度大小的变化会对耗时产生较大影响，选择合适粒度能够显著提高排序速度。</p><h5 id="线程变化"><a href="#线程变化" class="headerlink" title="线程变化"></a>线程变化</h5><p>​程序输出样例如下：</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221204210323877.png" alt="image-20221204210323877"></p><p>​经过分析处理后得到的图表结果展示如下：</p><table><thead><tr><th>thread</th><th>2</th><th>4</th><th>6</th><th>8</th><th>10</th><th>12</th><th>14</th><th>16</th><th>18</th><th>20</th></tr></thead><tbody><tr><td>time</td><td>4206.8</td><td>2253.7</td><td>1551.8</td><td>1216.4</td><td>1045.5</td><td>909.5</td><td>824.9</td><td>784.9</td><td>791.1</td><td>788.9</td></tr></tbody></table><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221204210121608.png" alt="image-20221204210121608"></p><p>​从实验结果可以看出，在数组均匀随机分布的情况下，随着线程数增加，实验耗时逐渐减小。当线程数大于12时，耗时趋于平缓。证明在线程数等于12时，排序速度已经达到较高水平，无需再增加线程数。</p><h4 id="不均匀随机分布的数组排序"><a href="#不均匀随机分布的数组排序" class="headerlink" title="不均匀随机分布的数组排序"></a>不均匀随机分布的数组排序</h4><h5 id="粒度变化-1"><a href="#粒度变化-1" class="headerlink" title="粒度变化"></a>粒度变化</h5><p>​程序输出样例如下：</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221204210400115.png" alt="image-20221204210400115"></p><p>​经过分析处理后得到的图表结果展示如下：</p><table><thead><tr><th>seg</th><th>10</th><th>20</th><th>30</th><th>40</th><th>50</th><th>60</th><th>70</th><th>80</th><th>90</th><th>100</th></tr></thead><tbody><tr><td>time</td><td>2221.5</td><td>2235.3</td><td>2211</td><td>2277.9</td><td>2229.2</td><td>2340.2</td><td>2324.2</td><td>2382.6</td><td>2358.1</td><td>2219.2</td></tr></tbody></table><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221204210656780.png" alt="image-20221204210656780"></p><p>​从上述实验结果可以看出，在数组完全随机，数组内数据分布不均匀的情况下，粒度从40增加到100时，耗时波动起伏较大；在粒度大小为80时，耗时达到峰值。同时可以看出，在粒度大小等于30时，耗时处于低谷。</p><p>​证明在数组不均匀随机分布的情况下，粒度大小的变化会对耗时产生较大影响，选择合适粒度能够显著提高排序速度。</p><h5 id="线程变化-1"><a href="#线程变化-1" class="headerlink" title="线程变化"></a>线程变化</h5><p>​程序输出样例如下：</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221204210352484.png" alt="image-20221204210352484"></p><p>​经过分析处理后得到的图表结果展示如下：</p><table><thead><tr><th>thread</th><th>2</th><th>4</th><th>6</th><th>8</th><th>10</th><th>12</th><th>14</th><th>16</th><th>18</th><th>20</th></tr></thead><tbody><tr><td>time</td><td>1096.3</td><td>638.9</td><td>448.5</td><td>411.3</td><td>359.3</td><td>345.8</td><td>335.9</td><td>337.1</td><td>279.9</td><td>278.8</td></tr></tbody></table><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221204210638549.png" alt="image-20221204210638549"></p><p>​从实验结果可以看出，在数组不均匀随机分布的情况下，随着线程数增加，实验耗时逐渐减小。当线程数大于6时，耗时趋于平缓。证明在线程数等于6时，排序速度已经达到较高水平，无需再增加线程数。</p><h2 id="高斯消去法解线性方程组的-OpenMP-多线程编程实现"><a href="#高斯消去法解线性方程组的-OpenMP-多线程编程实现" class="headerlink" title="高斯消去法解线性方程组的 OpenMP 多线程编程实现"></a>高斯消去法解线性方程组的 OpenMP 多线程编程实现</h2><h3 id="问题描述-2"><a href="#问题描述-2" class="headerlink" title="问题描述"></a>问题描述</h3><p>​对于给定的方程组 Ax=b，使用 OpenMP多线程编程，同时结合 SSE 向量计算，完成对于线性方程组的高斯消元和回代求解。本实验采取静态划分、动态划分、粗粒度动态划分多个角 度，探索任务分块大小、线程数多少、静态动态多线程结合等方面因素对高斯消去法解线性方程组效率的影响。并探索多线程分配任务的最优方案。</p><h3 id="算法设计与实现-2"><a href="#算法设计与实现-2" class="headerlink" title="算法设计与实现"></a>算法设计与实现</h3><h4 id="使用OpenMP"><a href="#使用OpenMP" class="headerlink" title="使用OpenMP"></a>使用OpenMP</h4><p>​使用SSE，以4个元素为一个单位进行消元，剩余最后三个元素串行处理。</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">// s使用SSE对j行消元void SSE_elimination(int i, int j) {    float tep;    __m128 div, t1, t2, sub;    tep = a[j][i] / a[i][i];    div = _mm_set1_ps(tep);    // 每次处理4个元素    int k;    for (k = n - 3; k &gt;= i + 1; k -= 4) {        t1 = _mm_loadu_ps(a[i] + k);        t2 = _mm_loadu_ps(a[j] + k);        sub = _mm_sub_ps(t2, _mm_mul_ps(t1, div));        _mm_storeu_ps(a[j] + k, sub);    }    for (k += 3; k &gt;= i + 1; k--) {        a[j][k] -= a[i][k] * tep;    }    a[j][i] = 0.00;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​使用 OpenMP 的提供的相关方法，实现高斯消元。并结合 sse 指令向量化求解，提高效率。 具体实现代码如下：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">void OpenMP_func(int next_task) {    int task = 0;    while (true) {#pragma omp critical        {            task = next_task;            next_task += seg;        }        if (task &gt;= n)            break;        else {            for (int i = task; i &lt; (task + seg &lt; n ? task + seg : n); i++)                SSE_elimination(line, i);        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="实验结果分析-2"><a href="#实验结果分析-2" class="headerlink" title="实验结果分析"></a>实验结果分析</h3><h4 id="线程变化-2"><a href="#线程变化-2" class="headerlink" title="线程变化"></a>线程变化</h4><p>​程序输出样例如下：</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221204204651302.png" alt="image-20221204204651302"></p><p>​经过分析处理后得到的图表结果展示如下：</p><table><thead><tr><th>thread</th><th>2</th><th>4</th><th>6</th><th>8</th><th>10</th><th>12</th><th>14</th><th>16</th><th>18</th><th>20</th></tr></thead><tbody><tr><td>time</td><td>123.8</td><td>154</td><td>185.7</td><td>232</td><td>281.3</td><td>321.7</td><td>356</td><td>390.1</td><td>435</td><td>483.1</td></tr></tbody></table><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221204215002447.png" alt="image-20221204215002447"></p><p>​根据以上实验结果，可以看出，实验耗时随着线程数增加而增加，有违理论基础。可能是由于随着线程数增加，不必要的开销增多，执行效率降低。</p><h4 id="粒度变化-2"><a href="#粒度变化-2" class="headerlink" title="粒度变化"></a>粒度变化</h4><p>​程序输出样例如下：</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221204204701976.png" alt="image-20221204204701976"></p><p>​经过分析处理后得到的图表结果展示如下：</p><table><thead><tr><th>seg</th><th>10</th><th>20</th><th>30</th><th>40</th><th>50</th><th>60</th><th>70</th><th>80</th><th>90</th><th>100</th></tr></thead><tbody><tr><td>time</td><td>162.293</td><td>149.935</td><td>147.02</td><td>147.935</td><td>149.626</td><td>151.116</td><td>151.101</td><td>146.928</td><td>147.225</td><td>146.675</td></tr></tbody></table><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221204215102341.png" alt="image-20221204215102341"></p><p>​从上述实验结果可以看出，粒度从30增加到100时，耗时波动起伏较小；在粒度大小为10时，耗时达到峰值。同时可以看出，在粒度大小等于80时，耗时处于低谷。</p><p>​证明粒度大小的变化会对高斯消去法解线性方程组实验耗时产生较大影响，选择合适粒度能够显著提高消元速度。</p>]]></content>
      
      
      <categories>
          
          <category> 并行程序设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 并行程序设计 </tag>
            
            <tag> S5课上 </tag>
            
            <tag> 实验报告 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>并行程序设计-第五讲.openmp编程</title>
      <link href="/2022/10/18/di-wu-jiang-openmp/"/>
      <url>/2022/10/18/di-wu-jiang-openmp/</url>
      
        <content type="html"><![CDATA[<h1 id="第五讲-openmp"><a href="#第五讲-openmp" class="headerlink" title="第五讲 openmp"></a>第五讲 openmp</h1><h2 id="OpenMP并行模型"><a href="#OpenMP并行模型" class="headerlink" title="OpenMP并行模型"></a>OpenMP并行模型</h2><h3 id="程序员视角"><a href="#程序员视角" class="headerlink" title="程序员视角"></a>程序员视角</h3><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114104633837.png" alt="image-20221114104633837"></p><h4 id="执行模型"><a href="#执行模型" class="headerlink" title="执行模型"></a>执行模型</h4><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114104747893.png" alt="image-20221114104747893"></p><h4 id="编程环境配置"><a href="#编程环境配置" class="headerlink" title="编程环境配置"></a>编程环境配置</h4><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114104917033.png" alt="image-20221114104917033"></p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114104938547.png" alt="image-20221114104938547"></p><h3 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h3><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114105212217.png" alt="image-20221114105212217"></p><h4 id="编译指示格式"><a href="#编译指示格式" class="headerlink" title="编译指示格式"></a>编译指示格式</h4><ul><li>编译指示格式<ul><li>#pragma omp directive_name[clause[clause]……]</li></ul></li><li>条件编译<ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114105619319.png" alt="image-20221114105619319"></li><li>如果使用的平台支持openmp则。。</li><li>不支持的话就按照串行方式，保证结果正确</li></ul></li><li>大小写敏感</li><li>使用库函数需要包含头文件</li></ul><h4 id="运行时库，查询函数"><a href="#运行时库，查询函数" class="headerlink" title="运行时库，查询函数"></a>运行时库，查询函数</h4><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114105948585.png" alt="image-20221114105948585"></p><h4 id="并行区域结构"><a href="#并行区域结构" class="headerlink" title="并行区域结构"></a>并行区域结构</h4><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114110155127.png" alt="image-20221114110155127"></p><h4 id="hello-world程序"><a href="#hello-world程序" class="headerlink" title="hello world程序"></a>hello world程序</h4><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;omp.h&gt;void Hello(void);int main(int argc,char* argv[]){  int thread_count=strtol(argv[1],NULL,10);    #pragma omp parallel num_threads(thread_count)  Hello();    return 0;}void Hello(void){  int my_rank=omp_get_thread_num();  int thread_count=omp_get_num_threads();    print("Hello from thread %d of %d\n",my_rank,thread_count);}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>为防止编译器不支持openMP</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114111804810.png" alt="image-20221114111804810"></p><h4 id="梯形积分法"><a href="#梯形积分法" class="headerlink" title="梯形积分法"></a>梯形积分法</h4><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114112046950.png" alt="image-20221114112046950"></p><h4 id="临界区指令"><a href="#临界区指令" class="headerlink" title="临界区指令"></a>临界区指令</h4><p>归约 </p><h2 id="并行循环"><a href="#并行循环" class="headerlink" title="并行循环"></a>并行循环</h2><h3 id="OpenMp数据并行：并行循环"><a href="#OpenMp数据并行：并行循环" class="headerlink" title="OpenMp数据并行：并行循环"></a>OpenMp数据并行：并行循环</h3><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114141348225.png" alt="image-20221114141348225"></p><h3 id="局限和语义"><a href="#局限和语义" class="headerlink" title="局限和语义"></a>局限和语义</h3><p>必须提前看到for循环就能看到有多少任务</p><p>带break、goto之类的不支持</p><p>不支持依赖的（例如斐波那契数列，每次计算都要用到前面的数）</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114142008518.png" alt="image-20221114142008518"></p><h3 id="简单并行化循环的版本"><a href="#简单并行化循环的版本" class="headerlink" title="简单并行化循环的版本"></a>简单并行化循环的版本</h3><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114142232525.png" alt="image-20221114142232525"></p><h3 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h3><p>openmp隐式同步</p><p>在要并行的语句前隐式的有开始并行和join之类的</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114142437576.png" alt="image-20221114142437576"></p><h3 id="并行for指示的各种形式"><a href="#并行for指示的各种形式" class="headerlink" title="并行for指示的各种形式"></a>并行for指示的各种形式</h3><h2 id="数据依赖（中间跳过了一部分，只讲了下面的几个ppt，跳过p39、）"><a href="#数据依赖（中间跳过了一部分，只讲了下面的几个ppt，跳过p39、）" class="headerlink" title="数据依赖（中间跳过了一部分，只讲了下面的几个ppt，跳过p39、）"></a>数据依赖（中间跳过了一部分，只讲了下面的几个ppt，跳过p39、）</h2><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114142745626.png" alt="image-20221114142745626"></p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114143132650.png" alt="image-20221114143132650"></p><p>第一个存在数据依赖</p><p>第二个不存在依赖</p><ul><li><p>例子</p><ul><li><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114143408845.png" alt="image-20221114143408845"></p></li><li><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114143519896.png" alt="image-20221114143519896"></p></li><li><p>气泡排序（🌟）</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114143824119.png" alt="image-20221114143824119"></p><p>内层和外层哪个存在循环依赖？？</p><p>都存在</p><p>外层：每次循环数组的顺序都发生了变化，下一次循环依赖上次循环的结果，存在循环依赖关系</p><p>内层，每次都要比较a[i]和a[i+1],并要交换两者位置，存在循环依赖关系</p></li><li><p>气泡排序内外层都存在依赖，怎么进行并行化</p><ul><li>解决方法</li><li>第一轮奇数项和他的下一个比较，第二轮偶数项和她的下一个比较</li><li>每一轮之间不存在依赖了</li><li>串行的代码<ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114150929703.png" alt="image-20221114150929703"></li></ul></li><li>并行代码<ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114150549415.png" alt="image-20221114150549415"></li><li>有什么问题</li><li>每次大循环的时候频繁地创建线程以及销毁线程，耗费系统资源</li><li>怎么改进？</li><li>把创建线程拿到大循环外面</li><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114150633942.png" alt="image-20221114150633942"></li><li>不用加parrallel_for啥的，因为不是对外循环并行化。只是现在外面生成线程，在执行内循环的时候在写pragma omp for，把任务分到线程上</li></ul></li></ul></li></ul></li></ul><h2 id="循环调度"><a href="#循环调度" class="headerlink" title="循环调度"></a>循环调度</h2><p>什么都不写的话默认static，最大块</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114153015722.png" alt="image-20221114153015722"></p><h3 id="静态分配"><a href="#静态分配" class="headerlink" title="静态分配"></a>静态分配</h3><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114151337679.png" alt="image-20221114151337679"></p><p>不指定的话默认为threads，指定的话变成循环分配，下面是制定了static（2）</p><p>在执行任务之前划分好，执行的时候</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114151712217.png" alt="image-20221114151712217"></p><h3 id="动态分配"><a href="#动态分配" class="headerlink" title="动态分配"></a>动态分配</h3><p>谁先执行好把剩下的最后一块给哪个线程</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114151913079.png" alt="image-20221114151913079"></p><h3 id="guided动态划分"><a href="#guided动态划分" class="headerlink" title="guided动态划分"></a>guided动态划分</h3><p>剩余任务数➗二倍的线程数</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114152516458.png" alt="image-20221114152516458"></p><h3 id="更多属性"><a href="#更多属性" class="headerlink" title="更多属性"></a>更多属性</h3><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114152850597.png" alt="image-20221114152850597"></p><h2 id="局部性"><a href="#局部性" class="headerlink" title="局部性"></a>局部性</h2><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114154109286.png" alt="image-20221114154109286"></p><p>重用</p><p>===========中间跳过了</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114154155141.png" alt="image-20221114154155141"></p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221114154240600.png" alt="image-20221114154240600"></p><p>后面全都跳过了</p><h2 id="任务并行"><a href="#任务并行" class="headerlink" title="任务并行"></a>任务并行</h2>]]></content>
      
      
      <categories>
          
          <category> 并行程序设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 并行程序设计 </tag>
            
            <tag> S5课上 </tag>
            
            <tag> 知识总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>并行程序设计-第四讲.Pthread编程</title>
      <link href="/2022/10/03/di-si-jiang-duo-xian-cheng-pthread-bian-cheng/"/>
      <url>/2022/10/03/di-si-jiang-duo-xian-cheng-pthread-bian-cheng/</url>
      
        <content type="html"><![CDATA[<h1 id="第四讲-多线程Pthread编程"><a href="#第四讲-多线程Pthread编程" class="headerlink" title="第四讲 多线程Pthread编程"></a>第四讲 多线程Pthread编程</h1><h2 id="共享内存系统和分布式内存模型回顾"><a href="#共享内存系统和分布式内存模型回顾" class="headerlink" title="共享内存系统和分布式内存模型回顾"></a>共享内存系统和分布式内存模型回顾</h2><h3 id="伪共享"><a href="#伪共享" class="headerlink" title="伪共享"></a>伪共享</h3><ol><li><p>cache按照行读取</p></li><li><p>当多个处理器访问同一行，即使访问的是不同的机器字，也会潜在竞争</p></li><li><p>会产生不必要的协同开销</p><p><img src="https://tva1.sinaimg.cn/large/008vxvgGly1h7oggjpznoj30m20aiwf1.jpg" alt="image-20221031143000351"></p><ol><li>当数据很少的时候，Core1和Core0访问的是同一行，同一个缓存行里的不同变量在同时被修改</li></ol></li></ol><h3 id="共享内存编程"><a href="#共享内存编程" class="headerlink" title="共享内存编程"></a>共享内存编程</h3><ol><li>动态线程<ol><li>主线程等待计算工作，fork新线程分配工作，工作线程完成任务后结束</li><li>资源利用率高</li></ol></li><li>主线程完成时fork出<strong>所有线程</strong><ol><li>性能更优，但可能浪费系统资源</li></ol></li></ol><h3 id="并行程序设计的复杂性"><a href="#并行程序设计的复杂性" class="headerlink" title="并行程序设计的复杂性"></a>并行程序设计的复杂性</h3><h2 id="POSIX-Threads编程"><a href="#POSIX-Threads编程" class="headerlink" title="POSIX Threads编程"></a>POSIX Threads编程</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>线程库：</p><ul><li>Pthread是POSIX标准<ul><li>相对底层</li><li>可移植</li></ul></li><li>OpenMP是新标准<ul><li>高层编程，适用于共享内存架构上的科学计算</li></ul></li></ul><h4 id="POSIX-Thread"><a href="#POSIX-Thread" class="headerlink" title="POSIX Thread"></a>POSIX Thread</h4><p><img src="https://tva1.sinaimg.cn/large/008vxvgGly1h7oguexqwnj30zo0m8djv.jpg" alt="image-20221031144319854"></p><h3 id="基础API"><a href="#基础API" class="headerlink" title="基础API"></a>基础API</h3><h4 id="创建线程"><a href="#创建线程" class="headerlink" title="创建线程"></a>创建线程</h4><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">int</span> <span class="token function">pthread_create</span><span class="token punctuation">(</span><span class="token class-name">pthread_t</span><span class="token operator">*</span><span class="token punctuation">,</span><span class="token keyword">const</span> <span class="token class-name">pthread_attr_t</span><span class="token operator">*</span><span class="token punctuation">,</span><span class="token keyword">void</span><span class="token operator">*</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token keyword">void</span><span class="token operator">*</span><span class="token punctuation">)</span>    <span class="token comment">//pthread_t不透明，程序员不可操作</span>  <span class="token comment">//调用</span>errcode<span class="token operator">=</span><span class="token function">pthread_create</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>thread_id<span class="token punctuation">,</span><span class="token operator">&amp;</span>thread_attribute<span class="token punctuation">,</span><span class="token operator">&amp;</span>thread_fun<span class="token punctuation">,</span><span class="token operator">&amp;</span>fun_arg<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>thread_id<ul><li>指针：线程ID或句柄（用于停止线程）</li></ul></li><li>thread_attribute:<ul><li>各种属性，通常用空指针<strong>NULL</strong>表示标准默认属性值</li></ul></li><li>thread_fun<ul><li>新线程要运行的函数（参数和返回值类型都是void*）</li></ul></li><li>fun_arg<ul><li>传递给要运行的函数thread_fun的参数</li></ul></li><li>errorocode<ul><li>若创建失败，返回非零值</li></ul></li></ul><p>![image-20221031151330065](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20221031151330065.png)</p><h4 id="Pthread-“hello-world”程序"><a href="#Pthread-“hello-world”程序" class="headerlink" title="Pthread “hello world”程序"></a>Pthread “hello world”程序</h4><p>![image-20221031152746925](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20221031152746925.png)</p><pre class="line-numbers language-c#" data-language="c#"><code class="language-c#">#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;pthread.h&gt; int thread_count;void* Hello(void* rank)int main(int argc,char* argv[]){  long thread;  pthread_t* thread_handles;    thread_count=strto(argv[1],NULL,10);    thread_handles=(pthread_t*)malloc(thread_count*sizeof(pthread_t*));    for(thread=0;thread&lt;thread_count;thread++) pthread_create(&amp;thread_handles[thread],NULL,Hello,(void*)thread);    printf("Hello from the main thread\n");    for(thread=0;thread&lt;thread_count;thread++);  pthread_join(thread_handles[thread],NULL);    free(thread_handles);  return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Pthread其他基础API"><a href="#Pthread其他基础API" class="headerlink" title="Pthread其他基础API"></a>Pthread其他基础API</h4><ul><li><p>取消、结束线程</p><ul><li><p>void pthread_exit(void *value_ptr)</p><ul><li>显式取消线程</li><li>通过value_ptr返回结果给调用者</li></ul></li><li><p>int pthread_cnacel(pthread_t thread)</p><ul><li><p>取消线程thread执行</p></li><li><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221107141515838.png" alt="image-20221107141515838"></p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221107141538026.png" alt="image-20221107141538026"></p></li></ul></li></ul></li></ul><h3 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h3><ul><li><p>例子 估算pai</p><ul><li><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221107142015679.png" alt="image-20221107142015679"></p></li><li><p>多线程版本</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221107142246876.png" alt="image-20221107142246876"></p><p>问题：每个线程都要把数加到<strong>sum</strong>上面，会存在竞争，结果是错误的</p></li></ul></li></ul><h4 id="概念回顾"><a href="#概念回顾" class="headerlink" title="概念回顾"></a>概念回顾</h4><ul><li><p>原子性</p><ul><li>一组操作要么全部执行要么全不执行，则称其是原子性的</li></ul></li><li><p>临界区</p><ul><li>共享资源的代码段，一次只能允许一个线程执行该代码</li></ul></li><li><p>竞争条件</p><ul><li>多个线程/进程尝试更新同一个共享资源时，结果可能是无法预测的，则存在竞争</li><li>如果存在竞争则创建临界区</li></ul></li><li><p>数据依赖</p><ul><li>两个<strong>内存</strong>的序。为了保证结果正确性，必须保持这个序</li></ul></li><li><p>同步</p><ul><li>时间上强制使各执行进程/线程在某一点必须互相等待，确保各进程/线程的正常顺序和对共享可写数据的正确访问。</li></ul></li></ul><h4 id="忙等待"><a href="#忙等待" class="headerlink" title="忙等待"></a>忙等待</h4><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221107143703393.png" alt="image-20221107143703393"></p><ul><li>临界区的这段代码保证了各个进程是按照序号进行相加</li><li>这个等待消耗cpu资源</li></ul><h4 id="显式同步：互斥量（锁）"><a href="#显式同步：互斥量（锁）" class="headerlink" title="显式同步：互斥量（锁）"></a>显式同步：互斥量（锁）</h4><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221107144116394.png" alt="image-20221107144116394"></p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221107144218073.png" alt="image-20221107144218073"></p><ul><li>这个版本线程不一定按照从小到大的顺序来，使用互斥量的效率更高，先执行完的不需要等待<ul><li>操作系统选择顺序，谁先执行完谁先来</li><li>被锁上的处于阻塞态，不占用cpu资源</li></ul></li><li>锁只能保证一段时间内只有线程运行</li></ul><h5 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h5><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221107150037798.png" alt="image-20221107150037798"></p><h4 id="使用信号量同步"><a href="#使用信号量同步" class="headerlink" title="使用信号量同步"></a>使用信号量同步</h4><h4 id="使用barrier同步"><a href="#使用barrier同步" class="headerlink" title="使用barrier同步"></a>使用barrier同步</h4><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221107151930138.png" alt="image-20221107151930138"></p>]]></content>
      
      
      <categories>
          
          <category> 并行程序设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 并行程序设计 </tag>
            
            <tag> S5课上 </tag>
            
            <tag> 知识总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>并行程序设计-第三讲.SIMD编程</title>
      <link href="/2022/09/25/di-san-jiang.simd-bian-cheng/"/>
      <url>/2022/09/25/di-san-jiang.simd-bian-cheng/</url>
      
        <content type="html"><![CDATA[<h1 id="SIMD编程"><a href="#SIMD编程" class="headerlink" title="SIMD编程"></a>SIMD编程</h1><h2 id="SIMD概念"><a href="#SIMD概念" class="headerlink" title="SIMD概念"></a>SIMD概念</h2><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210241415541.png" alt="image-20221024141506247" style="zoom:33%;"><p>SPMD单个程序在不同数据流上执行</p><p>本讲主要介绍单核向量编程</p><h3 id="SIMD编程概述"><a href="#SIMD编程概述" class="headerlink" title="SIMD编程概述"></a>SIMD编程概述</h3><ul><li><p>向量计算机</p></li><li><p>早期的SIMD超级计算机：银河</p></li><li><p>当前的SIMD架构</p><ul><li>多媒体扩展：SSE、AVX</li><li>图形和游戏处理器：CUDA</li><li>协处理器：Xeon Phi</li></ul></li><li><p>没有占压倒优势的SIMD编程模型</p><ul><li>向量计算机都是科学家用来编程 </li><li>多媒体扩展指令集多是系统程序员在用</li><li>GPU多是游戏开发者、大数据分析人员使用</li></ul></li><li><p>标量和SIMD（多媒体扩展架构）差别</p><ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210241428129.png" alt="image-20221024142859008" style="zoom:25%;"></li></ul></li><li><p>多媒体扩展架构的核心</p><ul><li><p>SIMD并行</p></li><li><p>可变大小的数据域</p></li><li><p>向量长度=寄存器宽度➗类型大小</p></li><li><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210241436940.png" alt="image-20221024143637806"></p><p>这里有128位寄存器，存储数据的大小由数据类型决定，比如如果存储长整型（32字节）的话，只能支持4个数同时计算</p></li></ul></li><li><p>适合应用SIMD的特点</p><ul><li><strong>规律</strong>的数据访问模式<ul><li>数据项在内存中<strong>连续存储</strong></li></ul></li><li><strong>短数据</strong>类型：8、16、32位</li><li><strong>流式</strong>数据处理，一系列处理阶段<ul><li>时间局域性，<strong>数据流重用</strong></li></ul></li><li>很多情况下可用来提升计算效率<ul><li>很多常量</li><li>循环迭代短</li></ul></li></ul></li><li><p>为什么采用SIMD</p><ul><li>更大的并发度</li><li>设计简单、重复功能单元即可</li><li>更小的芯片设计</li><li>缺点：代码很底层繁琐</li></ul></li><li><p>多媒体扩展编程</p><ul><li><p>语言/指令集扩展</p><ul><li><p>程序接口类似函数调用</p></li><li><p>C/C++：内置函数、 intrinsics</p></li><li><p>大多数编译器支持多媒体扩展</p><p>➢gcc：-march=corei7, -faltivec </p><p>SSE2: dst= _mm_add_ps(src1, src2); </p><p>AltiVec: dst= vec_add(src1, src2); </p><p>Neon： dst = vaddq_f32(src1, src2) </p><p>➢无统一标准</p></li><li><p>很多编译器支持自动编译</p></li></ul></li></ul></li></ul><h2 id="SIMD并行（不是很重要，了解即可）"><a href="#SIMD并行（不是很重要，了解即可）" class="headerlink" title="SIMD并行（不是很重要，了解即可）"></a>SIMD并行（不是很重要，了解即可）</h2><h3 id="几个例子"><a href="#几个例子" class="headerlink" title="几个例子"></a>几个例子</h3><ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210241454764.png" alt="image-20221024145431584" style="zoom:25%;"><p>把重复的算术运算变成向量运算</p></li><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210241502598.png" alt="image-20221024150231461" style="zoom:25%;"><p>存取数据的次数降低，效率提升</p></li><li><p>可向量化的循环</p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210241503733.png" alt="image-20221024150338675" style="zoom:33%;"><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210241504259.png" alt="image-20221024150422081" style="zoom:33%;"></li><li><p>可部分向量化的循环（有数据依赖）</p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210241506128.png" alt="image-20221024150628063" style="zoom:25%;"><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210241506150.png" alt="image-20221024150649061" style="zoom:25%;"></li></ul><h3 id="SIMD编程的额外开销"><a href="#SIMD编程的额外开销" class="headerlink" title="SIMD编程的额外开销"></a>SIMD编程的额外开销</h3><h4 id="打包-x2F-解包数据的开销：重排数据使之连续"><a href="#打包-x2F-解包数据的开销：重排数据使之连续" class="headerlink" title="打包/解包数据的开销：重排数据使之连续"></a>打包/解包数据的开销：重排数据使之连续</h4><ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210241514360.png" alt="image-20221024151459299" style="zoom:33%;"></li><li>打包源运算对象——拷贝到连续内存区域<ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210241515632.png" alt="image-20221024151536575" style="zoom:33%;"></li></ul></li><li>解包目的运算对象——拷贝回内存<ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210241516236.png" alt="image-20221024151628154"></li></ul></li></ul><h4 id="对齐：调整数据访问，使之对齐"><a href="#对齐：调整数据访问，使之对齐" class="headerlink" title="对齐：调整数据访问，使之对齐"></a>对齐：调整数据访问，使之对齐</h4><ul><li><p>对齐的内存访问 </p><ul><li>地址总是向量长度的倍数（例如16字节）</li><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210241523674.png" alt="image-20221024152331590" style="zoom: 33%;"></li></ul></li><li><p>未对齐的内存访问</p><ul><li><p>地址不是16字节的整数倍</p></li><li><p>静态对齐：对未对齐的读操作，做两次相邻的对齐读操作，然后进行合并</p></li><li><p>有未对齐相应操作函数，仍会产生<strong>多次内存操作</strong></p></li><li><p>底层硬件的操作：<img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210241525183.png" alt="image-20221024152556088"></p></li><li><p><strong>静态</strong>调整循环</p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210241532617.png" alt="image-20221024153232518" style="zoom:25%;"></li><li><p>动态对齐：</p><p>不知道从几开始，虽然有额外的对齐开销，但是结果一定是正确的</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210241533834.png" alt="image-20221024153357734"></p></li></ul></li><li><p>小结</p><ul><li><p>最坏情况需要计算地址，动态对齐</p></li><li><p>编译器/程序员可分析确认对齐</p><ul><li>一般而言数据是从<strong>起始地址处对齐</strong>的</li><li>如果在一个循环中顺序访问数据，<strong>起始位置固定</strong>，则对齐特性是不变的</li></ul></li><li><p>可调整算法，先串行处理到对齐边界， 然后进行SIMD计算 </p></li><li><p>有时对齐开销会完全抵消SIMD的并行收 益</p></li></ul></li></ul><h4 id="控制流可能要求执行所有路径"><a href="#控制流可能要求执行所有路径" class="headerlink" title="控制流可能要求执行所有路径"></a>控制流可能要求执行所有路径</h4><ul><li><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210251621039.png" alt="image-20221025162120878"></p></li><li><p>底层实现</p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210251622289.png" alt="image-20221025162249109" style="zoom:33%;"></li><li><p>能否改进</p><ul><li>假定所有控制流路径执行频率都不同</li><li>应该针对频率最高的路径优化代码</li><li>其他路经按默认方式执行</li><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210251624368.png" alt="image-20221025162455276" style="zoom:33%;"></li></ul></li><li><p>控制流开销小结</p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210251626006.png" alt="image-20221025162609859" style="zoom: 25%;"></li></ul><h3 id="SIMD编程复杂性"><a href="#SIMD编程复杂性" class="headerlink" title="SIMD编程复杂性"></a>SIMD编程复杂性</h3><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210251627096.png" alt="image-20221025162755998" style="zoom:25%;"><h2 id="SSE-x2F-AVX编程"><a href="#SSE-x2F-AVX编程" class="headerlink" title="SSE/AVX编程"></a>SSE/AVX编程</h2><h3 id="X86架构"><a href="#X86架构" class="headerlink" title="X86架构"></a>X86架构</h3><h4 id="发展历史"><a href="#发展历史" class="headerlink" title="发展历史"></a>发展历史</h4><ul><li><p>X86：Intel开发的一种微处理器体系结构 </p></li><li><p>出现：1978年Intel 8086 CPU中 </p><ul><li>但是一般来说<strong>X86指的是X86_32bit，32位系统</strong></li><li>64位就是指X86_64bit。简写为X64</li></ul></li><li><p>发展：</p><ul><li><p>❑ 1971-1992年数字编号：80X86系列</p></li><li><p>❑ 1993-2005年奔腾系列：Pentium</p></li><li><p>❑ 2005酷睿系列：Core</p></li></ul></li></ul><h4 id="基本框架"><a href="#基本框架" class="headerlink" title="基本框架"></a>基本框架</h4><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210251635439.png" alt="image-20221025163551311" style="zoom: 50%;"><ul><li>基本的执行模式 </li><li>数据类型 </li><li>指令集合（只讲这个） <ul><li>❑ 通用指令（传送，算术，逻辑，控制等） </li><li>❑ X87 FPU指令（传送，算术，比较，控制等 ） </li><li>❑ MMX指令（传送，转化，打包，比较等）</li><li>❑ SSE指令（增加寄存器，SIMD浮点数运算）</li><li>❑ SSE2指令（整数指令，64-bit SIMD浮点运 算）</li></ul></li><li>寄存器</li></ul><h4 id="x86架构SIMD支持"><a href="#x86架构SIMD支持" class="headerlink" title="x86架构SIMD支持"></a>x86架构SIMD支持</h4><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210251641729.png" alt="image-20221025164145509" style="zoom: 50%;"><h3 id="SSE指令集"><a href="#SSE指令集" class="headerlink" title="SSE指令集"></a>SSE指令集</h3><h4 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h4><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210251645135.png" alt="image-20221025164554037" style="zoom: 25%;"><h4 id="发展历史-1"><a href="#发展历史-1" class="headerlink" title="发展历史"></a>发展历史</h4><ul><li><p>SSE是MMX的超集</p></li><li><p>MMX</p><ul><li>❑ 1996年Intel在奔腾处理器集成MMX指令， 为应对音频、图片、视频等多媒体应用的密 集的计算需求 </li><li>❑ <strong>64-bit</strong>的MMX寄存器（8个，复用了浮点寄存器的尾部，与x87<strong>共用</strong>寄存器，缺少浮点指令） </li><li>❑ 支持在打包的字，字节，双字整数上的 SIMD操作</li></ul></li><li><p>SSE128bit寄存器与MMX寄存器的区别</p><ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210251650337.png" alt="image-20221025165011232"></li><li><strong>AVX 256位</strong></li></ul></li></ul><h3 id="AVX指令集"><a href="#AVX指令集" class="headerlink" title="AVX指令集"></a>AVX指令集</h3><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210251651766.png" alt="image-20221025165156622" style="zoom: 25%;"><h3 id="SSE编程"><a href="#SSE编程" class="headerlink" title="SSE编程"></a>SSE编程</h3><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210251653652.png" alt="image-20221025165341462" style="zoom:33%;"><h4 id="SSE指令"><a href="#SSE指令" class="headerlink" title="SSE指令"></a>SSE指令</h4><h5 id="数据移动指令"><a href="#数据移动指令" class="headerlink" title="数据移动指令"></a>数据移动指令</h5><p>将数据移入/出向量寄存器</p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210251658603.png" alt="image-20221025165835481" style="zoom:33%;"><h5 id="算术指令"><a href="#算术指令" class="headerlink" title="算术指令"></a>算术指令</h5><p>多个数据（2 doubles、4 floats等） 上的算术运算</p><ul><li>❑ PD：两个双精度，PS：四个单精度，SS：标量 </li><li>❑ ADD、SUB、MUL、DIV、SQRT、MAX、MIN、RCP等 <ul><li>➢ADDPS：四个单精度加法；ADDSS：标量加法</li></ul></li></ul><h5 id="逻辑指令"><a href="#逻辑指令" class="headerlink" title="逻辑指令"></a>逻辑指令</h5><p>多个数据上的逻辑运算</p><ul><li>❑ AND、OR、XOR、ANDN等 <ul><li>➢ANDPS – 运算对象位与 </li><li>➢ANDNPS – 运算对象位与非</li></ul></li></ul><h5 id="比较指令"><a href="#比较指令" class="headerlink" title="比较指令"></a>比较指令</h5><p>多个数据上的比较运算</p><p>❑ CMPPS、CMPSS：比较运算对象，每个比较结果影 响SIMD寄存器中32位——全1或全0</p><h5 id="洗牌指令"><a href="#洗牌指令" class="headerlink" title="洗牌指令"></a>洗牌指令</h5><p>在SIMD寄存器内移动数据</p><ul><li>❑ SHUFPS：从一个运算对象洗牌数据保存到另一个运 算对象 </li><li>❑ UNPCKHPS：解包高位数据到一个SIMD寄存器 <ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210251701303.png" alt="image-20221025170117239" style="zoom:33%;"></li></ul></li><li>❑ UNPCKLPS</li></ul><h5 id="其他指令"><a href="#其他指令" class="headerlink" title="其他指令"></a>其他指令</h5><ul><li>❑ 类型转换：CVTPS2PI mm,xmm/mem64 </li><li>❑ 缓存控制<ul><li>➢MOVNTPS将浮点数据从一个SIMD寄存器保存到内存，绕 过缓存</li></ul></li><li>❑ 状态管理：LDMXCSR读取MXCSR状态寄存器</li></ul><h4 id="SSE-C-x2F-C-编程"><a href="#SSE-C-x2F-C-编程" class="headerlink" title="SSE C/C++编程"></a>SSE C/C++编程</h4><ul><li><p>SSE指令对应C/C++ intrinsic </p><ul><li>❑ intrinsic：编译器能识别的函数，直接映射 为一个或多个汇编语言指令。Intrinsic函数 本质上比调用函数更高效 </li><li>❑ Intrinsics为处理器专有扩展特性提供了一个 C/C++编程接口 </li><li>❑ 主流编译器都支持，如GCC</li></ul></li><li><p>使用SSE intrinsics所需的头文件（<strong>向前兼容</strong>） </p><ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210251706442.png" alt="image-20221025170622370" style="zoom: 50%;"></li><li>向前兼容：比如我想要使用SSE3，其中就包含了SSE和SSE2</li></ul></li><li><p>编译选项： -march=corei7</p></li><li><p>AMD CPU对MMX/SSE/SSE2支持较好，SSE4支持较差</p></li></ul><h4 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a>矩阵乘法</h4><h5 id="串行版本"><a href="#串行版本" class="headerlink" title="串行版本"></a>串行版本</h5><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> <span class="token function">mul</span><span class="token punctuation">(</span><span class="token keyword">int</span> n<span class="token punctuation">,</span><span class="token keyword">float</span> a<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">[</span>maxN<span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token keyword">float</span> b<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">[</span>maxN<span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token keyword">float</span> c<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">[</span>maxN<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">{</span>  <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>n<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> j<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>j<span class="token operator">&lt;</span>n<span class="token punctuation">;</span>j<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>      c<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">;</span>      <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> k<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>k<span class="token operator">&lt;</span>n<span class="token punctuation">;</span>k<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        c<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token operator">=</span>a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token operator">*</span>b<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="cache优化"><a href="#cache优化" class="headerlink" title="cache优化"></a>cache优化</h5><p>把ab两个矩阵都变成行主序  </p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> <span class="token function">trans_mul</span><span class="token punctuation">(</span><span class="token keyword">int</span> n<span class="token punctuation">,</span><span class="token keyword">float</span> a<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">[</span>maxN<span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token keyword">float</span> b<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">[</span>maxN<span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token keyword">float</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">[</span>maxN<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">{</span>  <span class="token comment">//转置</span>  <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>n<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span>    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> j<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>j<span class="token operator">&lt;</span>n<span class="token punctuation">;</span>j<span class="token operator">++</span><span class="token punctuation">)</span>      <span class="token function">swap</span><span class="token punctuation">(</span>b<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span>b<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>      <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>n<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> j<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>j<span class="token operator">&lt;</span>n<span class="token punctuation">;</span>j<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>      c<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">;</span>      <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> k<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>k<span class="token operator">&lt;</span>n<span class="token punctuation">;</span>k<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        c<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token operator">=</span>a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token operator">*</span>b<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment">//⚠️是b[j][k],不是b[k][j]</span>      <span class="token punctuation">}</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span>    <span class="token comment">//转置</span>  <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>n<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span>    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> j<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>j<span class="token operator">&lt;</span>n<span class="token punctuation">;</span>j<span class="token operator">++</span><span class="token punctuation">)</span>      <span class="token function">swap</span><span class="token punctuation">(</span>b<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span>b<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="SSE版本🌟"><a href="#SSE版本🌟" class="headerlink" title="SSE版本🌟"></a>SSE版本🌟</h5><p>不懂</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> <span class="token function">sse_mul</span><span class="token punctuation">(</span><span class="token keyword">int</span> n<span class="token punctuation">,</span><span class="token keyword">float</span> a<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">[</span>maxN<span class="token punctuation">]</span><span class="token punctuation">,</span>b<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">[</span>maxN<span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token keyword">float</span> c<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">[</span>maxN<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">{</span>  __m128t1<span class="token punctuation">,</span>t2<span class="token punctuation">,</span>sum<span class="token punctuation">;</span>  <span class="token comment">//转置</span>  <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>n<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span>    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> j<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>j<span class="token operator">&lt;</span>n<span class="token punctuation">;</span>j<span class="token operator">++</span><span class="token punctuation">)</span>      <span class="token function">swap</span><span class="token punctuation">(</span>b<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span>b<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>n<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> j<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>j<span class="token operator">&lt;</span>n<span class="token punctuation">;</span>j<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>      c<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>      sum<span class="token operator">=</span><span class="token function">_mm_setzero_ps</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> k<span class="token operator">=</span>n<span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">;</span>k<span class="token operator">&gt;=</span><span class="token number">0</span><span class="token punctuation">;</span>k<span class="token operator">-=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        t1<span class="token operator">=</span><span class="token function">_mm_loadu_ps</span><span class="token punctuation">(</span>a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">+</span>k<span class="token punctuation">)</span><span class="token punctuation">;</span>        t2<span class="token operator">=</span><span class="token function">_mm_loadu_ps</span><span class="token punctuation">(</span>b<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token operator">+</span>k<span class="token punctuation">)</span><span class="token punctuation">;</span>        t1<span class="token operator">=</span><span class="token function">_mm_mul_ps</span><span class="token punctuation">(</span>t1<span class="token punctuation">,</span>t2<span class="token punctuation">)</span><span class="token punctuation">;</span>        sum<span class="token operator">=</span><span class="token function">_mm_add_ps</span><span class="token punctuation">(</span>sum<span class="token punctuation">,</span>t1<span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span>      sum<span class="token operator">=</span><span class="token function">_mm_hadd_ps</span><span class="token punctuation">(</span>sum<span class="token punctuation">,</span>sum<span class="token punctuation">)</span><span class="token punctuation">;</span>      sum<span class="token operator">=</span><span class="token function">_mm_hadd_ps</span><span class="token punctuation">(</span>sum<span class="token punctuation">,</span>sum<span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token function">_mm_store_ss</span><span class="token punctuation">(</span>c<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">+</span>j<span class="token punctuation">,</span>sum<span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token comment">//如果还有不能被4整除的部分</span>      <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> k<span class="token operator">=</span><span class="token punctuation">(</span>n<span class="token operator">%</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>k<span class="token operator">&gt;=</span><span class="token number">0</span><span class="token punctuation">;</span>k<span class="token operator">--</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        c<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token operator">+=</span>a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token operator">*</span>b<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span>        <span class="token comment">//转置</span>  <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>n<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span>    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> j<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>j<span class="token operator">&lt;</span>n<span class="token punctuation">;</span>j<span class="token operator">++</span><span class="token punctuation">)</span>      <span class="token function">swap</span><span class="token punctuation">(</span>b<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span>b<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="分片策略"><a href="#分片策略" class="headerlink" title="分片策略"></a>分片策略</h5><p>啥玩意啊</p><p>看不懂</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221101214350768.png" alt="image-20221101214350768"></p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221101214331724.png" alt="image-20221101214331724"></p>]]></content>
      
      
      <categories>
          
          <category> 并行程序设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 并行程序设计 </tag>
            
            <tag> S5课上 </tag>
            
            <tag> 知识总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python-面向对象编程</title>
      <link href="/2022/09/17/mian-xiang-dui-xiang-bian-cheng/"/>
      <url>/2022/09/17/mian-xiang-dui-xiang-bian-cheng/</url>
      
        <content type="html"><![CDATA[<h1 id="面向对象编程"><a href="#面向对象编程" class="headerlink" title="面向对象编程"></a>面向对象编程</h1><h2 id="私有方法"><a href="#私有方法" class="headerlink" title="私有方法"></a>私有方法</h2><ul><li>__private_method:<ul><li>两个下划线开头</li><li>私有方法，只能在类的内部调用，不能在类的外部调用</li></ul></li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Site</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>name<span class="token punctuation">,</span>url<span class="token punctuation">)</span><span class="token punctuation">:</span>    self<span class="token punctuation">,</span>name<span class="token operator">=</span>name<span class="token comment">#public</span>    self<span class="token punctuation">.</span>__url<span class="token operator">=</span>url<span class="token comment">#private</span>      <span class="token keyword">def</span> <span class="token function">who</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="类之间的关系"><a href="#类之间的关系" class="headerlink" title="类之间的关系"></a>类之间的关系</h2><ul><li>is-a<ul><li>继承</li></ul></li><li>Has-a<ul><li>组合或关联</li><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221109160623400.png" alt="image-20221109160623400"></li><li>例：池塘里里面的各种生物</li></ul></li><li>Use-a<ul><li>依赖</li><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221109160605227.png" alt="image-20221109160605227"></li></ul></li></ul><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102162738720.png" alt="image-20221102162738720"></p><h3 id="类的继承"><a href="#类的继承" class="headerlink" title="类的继承"></a>类的继承</h3><ul><li>基类（也叫父类）<ul><li>被继承的类</li></ul></li><li>派生类（也叫子类）<ul><li>继承的类</li></ul></li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">People</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">__init</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>name<span class="token punctuation">,</span>age<span class="token punctuation">)</span><span class="token punctuation">:</span>    self<span class="token punctuation">.</span>name<span class="token operator">=</span>name    self<span class="token punctuation">.</span>age<span class="token operator">=</span>age      <span class="token keyword">def</span> <span class="token function">speak</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token operator">//</span>这里的self不一定是People的    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>self<span class="token punctuation">.</span>name<span class="token punctuation">}</span></span><span class="token string">说：我</span><span class="token interpolation"><span class="token punctuation">{</span>self<span class="token punctuation">.</span>age<span class="token punctuation">}</span></span><span class="token string">岁。"</span></span><span class="token punctuation">)</span>        <span class="token keyword">class</span> <span class="token class-name">Student</span><span class="token punctuation">(</span>People<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">__int__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>name<span class="token punctuation">,</span>age<span class="token punctuation">,</span>weight<span class="token punctuation">,</span>grade<span class="token punctuation">)</span><span class="token punctuation">:</span>    People<span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>self<span class="token punctuation">,</span>name<span class="token punctuation">,</span>age<span class="token punctuation">)</span>    self<span class="token punctuation">.</span>weight<span class="token operator">=</span>weight    self<span class="token punctuation">.</span>grade<span class="token operator">=</span>grade    xm<span class="token operator">=</span>Student<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"小明"</span><span class="token punctuation">,</span>age<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>weight<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>grade<span class="token operator">=</span><span class="token string">"三年级"</span><span class="token punctuation">)</span><span class="token operator">//</span>也可以直接输入值xm<span class="token punctuation">.</span>speak<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">//</span>谁调了他，就是谁传了进去<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="方法的重写"><a href="#方法的重写" class="headerlink" title="方法的重写"></a>方法的重写</h4><p>子类会覆盖父类</p><h4 id="多继承"><a href="#多继承" class="headerlink" title="多继承"></a>多继承</h4><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102163858056.png" alt="image-20221102163858056"></p><ul><li>A(B,E)顺序不能变❕<ul><li>表示A先继承B</li></ul></li><li>G自动继承object类</li></ul><h5 id="MRO算法"><a href="#MRO算法" class="headerlink" title="MRO算法"></a>MRO算法</h5><ul><li>使用_ <em>mro</em> _来查询print(D.__mro _)</li><li>使用merge算法进行推导（不是重点，可以了解）</li></ul><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102164627442.png" alt="image-20221102164627442"></p><ul><li>利用剪枝<ul><li>左优先‼️</li></ul></li><li>找如度为0的把它去掉</li></ul><h4 id="super（）"><a href="#super（）" class="headerlink" title="super（）"></a>super（）</h4><ul><li>super（）语法：</li><li></li></ul><p>🌟考试会考</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102170836759.png" alt="image-20221102170836759"></p><ul><li><p>例<img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102171352784.png" alt="image-20221102171352784"></p><ul><li><p>mro顺序</p></li><li><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102171435329.png" alt="image-20221102171435329"></p></li></ul></li><li><p>例</p><ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102172330714.png" alt="image-20221102172330714"></li><li>看的是mro的顺序</li><li>c➡️a➡️b➡️base</li></ul></li><li><p>例</p><ul><li>理解self是谁</li><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102172943838.png" alt="image-20221102172943838"></li></ul></li><li><p>super0和类分别调用父类实例方法，区别在于super0后跟的方法不需要传self，父类调用实例方法，第一个参数需要传self</p></li></ul><h2 id="类的多态"><a href="#类的多态" class="headerlink" title="类的多态"></a>类的多态</h2><p>只要有方法就可以调用</p><p>python不用定义接口，其他语言需要定义接口</p><ul><li>不同的对象调用同一个接口，从而表现出不同的状态，称为多态</li><li>多态发生的条件：<ul><li>继承：发生在父类子类之间</li><li>重写：子类重写父类方法</li></ul></li><li>增加一个功能<ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221109164508768.png" alt="image-20221109164508768"></li></ul></li></ul><h3 id="多态的约束性方法"><a href="#多态的约束性方法" class="headerlink" title="多态的约束性方法"></a>多态的约束性方法</h3><ul><li><p>通过直接抛异常的方式</p><ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221109170156871.png" alt="image-20221109170156871"></li></ul></li><li><p>通过抽象基类（基类就是父类）和抽象方法来实现</p><ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221109170736639.png" alt="image-20221109170736639"></li></ul></li></ul><h2 id="类的Mixin设计模式"><a href="#类的Mixin设计模式" class="headerlink" title="类的Mixin设计模式"></a>类的Mixin设计模式</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Vehicle</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">fly</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"I am flying"</span><span class="token punctuation">,</span>self<span class="token punctuation">)</span>    <span class="token keyword">class</span> <span class="token class-name">CivilAircraft</span><span class="token punctuation">(</span>Vehicle<span class="token punctuation">)</span>  <span class="token punctuation">:</span>  <span class="token keyword">pass</span><span class="token keyword">class</span> <span class="token class-name">Helicopter</span><span class="token punctuation">(</span>Vehicle<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token keyword">pass</span><span class="token keyword">class</span> <span class="token class-name">Car</span><span class="token punctuation">(</span>Vehicle<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">pass</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>car类继承vehicle类，但是car没有飞行功能</li><li>民航飞机与直升飞机重写fly代码冗余</li></ul><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221109162525708.png" alt="image-20221109162525708"></p><ul><li>一种设计模式</li><li>单独定义一个Mixin类<ul><li>比喻：飞行只是飞机的一个增强属性</li></ul></li><li>python中没有接口一说</li></ul><h3 id="Mixin类实现多继承需要遵循的原则"><a href="#Mixin类实现多继承需要遵循的原则" class="headerlink" title="Mixin类实现多继承需要遵循的原则"></a>Mixin类实现多继承需要遵循的原则</h3><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221109163244822.png" alt="image-20221109163244822"></p><h3 id="不使用Mixin的弊端"><a href="#不使用Mixin的弊端" class="headerlink" title="不使用Mixin的弊端"></a>不使用Mixin的弊端</h3><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221109163332608.png" alt="image-20221109163332608"></p><h2 id="类中的绑定方法（有同学问了讲的）"><a href="#类中的绑定方法（有同学问了讲的）" class="headerlink" title="类中的绑定方法（有同学问了讲的）"></a>类中的绑定方法（有同学问了讲的）</h2><h3 id="实例的绑定方法"><a href="#实例的绑定方法" class="headerlink" title="实例的绑定方法"></a>实例的绑定方法</h3><h3 id="类的绑定方法"><a href="#类的绑定方法" class="headerlink" title="类的绑定方法"></a>类的绑定方法</h3><p>通过classmethod装饰器，将绑定给实例的方法绑定到了类</p><p>谁调用了他就把谁传给cls</p><p>实例调用会把生成实例的类传给cls</p><h3 id="类的非绑定方法"><a href="#类的非绑定方法" class="headerlink" title="类的非绑定方法"></a>类的非绑定方法</h3><p>通过staticmethod装饰器，可以解除绑定关系，既不属于实例也不属于类</p><p>和普通函数相同，不用考虑自动传参</p><h2 id="描述器-描述符-协议"><a href="#描述器-描述符-协议" class="headerlink" title="描述器(描述符)协议"></a>描述器(描述符)协议</h2><ul><li><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221109171624111.png" alt="image-20221109171624111"></p></li><li><p>父类为object，object里面已经实现了。因此可以直接调用a</p></li><li><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221116164118563.png" alt="image-20221116164118563"></p><ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221116164222818.png" alt="image-20221116164222818"><ul><li>动态生成</li></ul></li></ul></li><li><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221109172711106.png" alt="image-20221109172711106"></p><ul><li>M（）成为描述器实例</li><li>AA中把实例m当作自己的属性</li></ul></li></ul><h3 id="数据描述器和非数据描述器"><a href="#数据描述器和非数据描述器" class="headerlink" title="数据描述器和非数据描述器"></a>数据描述器和非数据描述器</h3><p>数据描述器也叫资料描述器</p><p>🌟getattr函数可以做反射</p><p>用字符串映射有没有这个方法</p><p>掌握：</p><p>什么叫描述器</p><p>数据描述器和非数据描述器</p><p>getattr</p><h3 id="描述器用途"><a href="#描述器用途" class="headerlink" title="描述器用途"></a>描述器用途</h3><ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221116164924867.png" alt="image-20221116164924867"></li><li>vars和_ _dict _ _协议相同</li></ul><h3 id="描述器访问顺序（🌟重要）"><a href="#描述器访问顺序（🌟重要）" class="headerlink" title="描述器访问顺序（🌟重要）"></a>描述器访问顺序（🌟重要）</h3><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221116172952732.png" alt="image-20221116172952732"></p><ul><li>只是定义了A类的时候就输出了前两行</li></ul><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221116174035448.png" alt="image-20221116174035448"></p><h2 id="判断类实例的函数"><a href="#判断类实例的函数" class="headerlink" title="判断类实例的函数"></a>判断类实例的函数</h2><ul><li><p>type和isinistance函数的区别</p><ul><li><p>isinstance（obj，cls）：判断obj是否是cls类·或者<strong>他的子类</strong>的实例</p></li><li><p>type（obj）：获取实例obj的类型，<strong>不考虑继承关系</strong></p><ul><li><p>与__class _ _ 作用相同</p></li><li><p>二者等价</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221116161439404.png" alt="image-20221116161439404"></p></li></ul></li></ul></li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span> <span class="token punctuation">:</span>  <span class="token keyword">pass</span><span class="token builtin">type</span><span class="token punctuation">(</span>A（）<span class="token punctuation">)</span><span class="token comment">#结果是A</span><span class="token builtin">type</span>（A）<span class="token comment">#结果是&lt;class 'type'&gt;，type是生成类的类</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><p>元类</p><ul><li><p>创建类的类</p><ul><li><p><strong>默认的元类：type</strong></p></li><li><p>要创建一个class对象，type（）函数依次传入3个参数：</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221116161829260.png" alt="image-20221116161829260"></p></li></ul></li><li><p>通过继承type创建元类</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221116163027470.png" alt="image-20221116163027470"></p><ul><li>什么都不用做都可以输出前两行，只是定义就可以（🌟，考试没准就考）<ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221116162459971.png" alt="image-20221116162459971"></li><li>元类是生成类，</li></ul></li></ul></li></ul></li></ul><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221116163626790.png" alt="image-20221116163626790"></p><ul><li>object可以指这三种类型，具体情况具体分析</li></ul>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> S5课上 </tag>
            
            <tag> 知识总结 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>并行程序设计-实验2.SSE编程练习</title>
      <link href="/2022/09/13/sse-bian-cheng-lian-xi/"/>
      <url>/2022/09/13/sse-bian-cheng-lian-xi/</url>
      
        <content type="html"><![CDATA[<h1 id="SSE编程练习"><a href="#SSE编程练习" class="headerlink" title="SSE编程练习"></a>SSE编程练习</h1><h2 id="矩阵乘法的优化"><a href="#矩阵乘法的优化" class="headerlink" title="矩阵乘法的优化"></a>矩阵乘法的优化</h2><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>一个n行n列的矩阵a与一个n行n列的矩阵b的乘积，是一个n行n列的矩阵c。本实验分别使用了串行算法、Cache 优化、SSE 编程和分片策略四种算法实现了矩阵乘法，并就各算法的执行性能进行比较与分析。</p><h3 id="算法设计实现与复杂性分析"><a href="#算法设计实现与复杂性分析" class="headerlink" title="算法设计实现与复杂性分析"></a>算法设计实现与复杂性分析</h3><h4 id="串行算法"><a href="#串行算法" class="headerlink" title="串行算法"></a>串行算法</h4><p>​依据矩阵乘法规则，矩阵a的每一行与对应b的每一列分别相乘后求和，设计三层循环嵌套，按矩阵a的行主序处理。</p><p>​具体代码如下：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">void mul(float a[maxN][maxN], float b[maxN][maxN]){    for (int i = 0; i &lt; n; ++i) {        for (int j = 0; j &lt; n; ++j) {            c[i][j] = 0.0;            for (int k = 0; k &lt; n; ++k) {                c[i][j] += a[i][k] * b[k][j];            }        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​通过代码可以看出，串行算法的设计中有3个for循环，一个for循环是O(n)，所以串行算法的复杂度为O(n *n *n)=O(n^3)</p><h4 id="cache优化"><a href="#cache优化" class="headerlink" title="cache优化"></a>cache优化</h4><p>​从上面串行算法的代码中可以看出，b [k] [j]在读取内存中的数据时是不连续的。在最底层的循环中，随着k不断加一，b[k] [j]不断地在内存中跳跃。这会引起cache命中率低，循环程序不断的把内存转移到缓存中，引起效率降低。</p><p>​cache优化的思路便是通过将b矩阵转置，以行主序的方式来访问b矩阵，这样保证了b矩阵空间访问的局部性，效率得到提高。</p><p>​具体代码如下：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">void trans_mul(float a[maxN][maxN], float b[maxN][maxN]){    //转置    for (int i = 0; i &lt; n; ++i)        for (int j = 0; j &lt; i; ++j){            swap(b[i][j], b[j][i]);        }    for (int i = 0; i &lt; n; ++i) {        for (int j = 0; j &lt; n; ++j) {            c[i][j] = 0.0;            for (int k = 0; k &lt; n; ++k) {                c[i][j] += a[i][k] * b[j][k];            }        }    }    //转置    for (int i = 0; i &lt; n; ++i)        for (int j = 0; j &lt; i; ++j) {            swap(b[i][j], b[j][i]);        }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​通过代码可以看出，此算法的设计中有3个for循环，一个for循环是O(n)，所以cache优化算法的复杂度为O(n *n *n)=O(n^3)</p><h4 id="SSE版本"><a href="#SSE版本" class="headerlink" title="SSE版本"></a>SSE版本</h4><p>​矩阵乘法向量化，在cache优化的基础上，利用intrisic 中的函数，以4为步长，每次处理四个对应数据，求和后存入sum，两次相邻求和，最终sum为4维向量，均为同一个数。</p><p>​具体代码如下：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">void sse_mul(float a[maxN][maxN], float b[maxN][maxN]){    __m128 t1, t2, sum;    for (int i = 0; i &lt; n; ++i)        for (int j = 0; j &lt; i; ++j) {            swap(b[i][j], b[j][i]);        }    for (int i = 0; i &lt; n; ++i){        for (int j = 0; j &lt; n; ++j){            c[i][j] = 0.0;            sum = _mm_setzero_ps();            for (int k = n - 4; k &gt;= 0; k -= 4){                t1 = _mm_loadu_ps(a[i] + k);                t2 = _mm_loadu_ps(b[j] + k);                t1 = _mm_mul_ps(t1, t2);                sum = _mm_add_ps(sum, t1);            }            sum = _mm_hadd_ps(sum, sum);            sum = _mm_hadd_ps(sum, sum);            _mm_store_ss(c[i] + j, sum);            //不能被4整除部分的处理            for (int k = (n % 4) - 1; k &gt;= 0; --k){                c[i][j] += a[i][k] * b[j][k];            }        }    }    for (int i = 0; i &lt; n; ++i)        for (int j = 0; j &lt; i; ++j) {            swap(b[i][j], b[j][i]);        }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​此算法一次处理四个数据，算法时间复杂度为O((n^3)/4)</p><h4 id="分片策略"><a href="#分片策略" class="headerlink" title="分片策略"></a>分片策略</h4><p>​将矩阵a和b分割成子矩阵，子矩阵分别计算，合并后结果与原结果相同。根据这一原理，将矩阵划分为T个矩阵块，n维矩阵元素进入Cache中的次数为n/T，即在SSE版本未分片的基础上减少循环次数.</p><p>​具体代码如下：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">void sse_tile(float a[maxN][maxN], float b[maxN][maxN]){    __m128 t1, t2, sum;    float t;    for (int i = 0; i &lt; n; ++i)        for (int j = 0; j &lt; i; ++j) {            swap(b[i][j], b[j][i]);        }    for (int r = 0; r &lt; n / T; ++r)        for (int q = 0; q &lt; n / T; ++q){            for (int i = 0; i &lt; T; ++i)                for (int j = 0; j &lt; T; ++j){                    c[r * T + i][q * T + j] = 0.0;                }            for (int p = 0; p &lt; n / T; ++p){                for (int i = 0; i &lt; T; ++i)                    for (int j = 0; j &lt; T; ++j){                        sum = _mm_setzero_ps();                        for (int k = 0; k &lt; T; k += 4){                            t1 = _mm_loadu_ps(a[r * T + i] + p * T + k);                            t2 = _mm_loadu_ps(b[q * T + j] + p * T + k);                            t1 = _mm_mul_ps(t1, t2);                            sum = _mm_add_ps(sum, t1);                        }                        sum = _mm_hadd_ps(sum, sum);                        sum = _mm_hadd_ps(sum, sum);                        _mm_store_ss(&amp;t, sum);                        c[r * T + i][q * T + j] += t;                    }            }        }    for (int i = 0; i &lt; n; ++i)        for (int j = 0; j &lt; i; ++j) {            swap(b[i][j], b[j][i]);        }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​算法的时间复杂度仍然为O(n^3)，但因为充分利用了高速缓存，故计算性能也会有较显著的提升。</p><h3 id="细节设计"><a href="#细节设计" class="headerlink" title="细节设计"></a>细节设计</h3><h4 id="计时方法"><a href="#计时方法" class="headerlink" title="计时方法"></a>计时方法</h4><p>​计时方面，我使用了课件中给出的Windows下精准计时方法，即QueryPerformance系列API。</p><p>​以串行算法的计时为例，具体代码如下：</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/img_v2_2dc2a1b8-4191-4cbe-8c15-681dc3bea3ag.jpg" alt="img_v2_2dc2a1b8-4191-4cbe-8c15-681dc3bea3ag"></p><h4 id="计时精度"><a href="#计时精度" class="headerlink" title="计时精度"></a>计时精度</h4><p>​本实验随机生成了30个矩阵，将计算过程重复了30次，足以匹配计算计时精度，再计算平均时间。</p><p>​以串行算法为例，具体代码如下：</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/img_v2_2dc2a1b8-4191-4cbe-8c15-681dc3bea3ag.jpg" alt="img_v2_2dc2a1b8-4191-4cbe-8c15-681dc3bea3ag"></p><h4 id="实验数据设计"><a href="#实验数据设计" class="headerlink" title="实验数据设计"></a>实验数据设计</h4><p>​本实验测试了不同规模的矩阵，由小至大，分别测试了规模为0、10、20、30……100的矩阵，随机生成矩阵元素值。</p><p>​随机生成矩阵的过程为：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">// 随机生成矩阵void init(Matrix* dataset) {    srand(static_cast &lt;unsigned&gt; (time(0)));    for (int i = 0; i &lt; 30; i++) {        for (int j = 0; j &lt; n; j++) {            for (int k = 0; k &lt; n; k++) {                dataset[i].a[j][k] = static_cast &lt;float&gt; (rand()) / (static_cast &lt;float&gt;(RAND_MAX / 1000));                dataset[i].b[j][k] = static_cast &lt;float&gt; (rand()) / (static_cast &lt;float&gt;(RAND_MAX / 1000));            }        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h4><p>​为了降低误差，本实验重复了两次取平均值。</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/img_v2_83868f60-ccae-47cf-9adb-b636e66fbdeg.jpg" alt="img_v2_83868f60-ccae-47cf-9adb-b636e66fbdeg"></p><h3 id="实验及结果分析"><a href="#实验及结果分析" class="headerlink" title="实验及结果分析"></a>实验及结果分析</h3><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/img_v2_b199d9e4-5be3-4569-86ac-7940008ed5bg.jpg" alt="img_v2_b199d9e4-5be3-4569-86ac-7940008ed5bg"></p><p>​从图中可以看出，算法运行所需要的时间：串行算法&gt;cache优化算法&gt;sse优化&gt;分片策略。</p><p>​当矩阵规模较小时串行算法和cache优化算法的性能相差不大，但随着规模的增大，cache优化算法要优于串行算法。</p><p>​可见，与串行算法相比，cache优化算法、sse版本以及分片策略提升了算法的效率，缩短了运行时间。</p><h2 id="高斯消元法SSE并行化"><a href="#高斯消元法SSE并行化" class="headerlink" title="高斯消元法SSE并行化"></a>高斯消元法SSE并行化</h2><h3 id="问题描述-1"><a href="#问题描述-1" class="headerlink" title="问题描述"></a>问题描述</h3><p>​高斯消元法，是线性代数中的一个算法，可用来求解线性方程组。 高斯消元法的原理是：若用初等行变换将增广矩阵化为行阶梯矩阵 ，则AX = B与CX = D是同解方程组。所以我们可以用初等行变换把增广矩阵转换为行阶梯阵，然后回代求出方程的解。</p><p>​本实验分别使用了串行算法、SSE 编程分别实现了高斯消元法和回代求解的过程，并就各算法的执行性能进行比较与分析。</p><h3 id="算法设计实现与复杂性分析-1"><a href="#算法设计实现与复杂性分析-1" class="headerlink" title="算法设计实现与复杂性分析"></a>算法设计实现与复杂性分析</h3><h4 id="串行算法消元"><a href="#串行算法消元" class="headerlink" title="串行算法消元"></a>串行算法消元</h4><p>​按行处理，以主对角线元素为标准，主对角线右侧的值除以该行主对角线上的值，最后将对角线赋值为1。每一行处理完毕，下一行依次减去上行的值，此时值需要通过当前行的第一个不为0的元素进行还原。将对角线左侧的值均赋值为0。</p><p>​具体代码如下：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">void serialGauss(Matrix* dataset) {    for (int count = 0; count &lt; 50; count++) {        for (int i = 0; i &lt; n; i++) {            for (int j = i + 1; j &lt; n; j++) {                float temp = dataset[count].a[j][i] / dataset[count].a[i][i];                for (int k = i; k &lt; n; k++) {                    dataset[count].a[j][k] = dataset[count].a[j][k] - temp * dataset[count].a[i][k];                }            }        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​通过代码可以看出，此算法的设计中有3个for循环，一个for循环是O(n)，所以串行算法消元的复杂度为O(n *n *n)=O(n^3)</p><h4 id="sse消元"><a href="#sse消元" class="headerlink" title="sse消元"></a>sse消元</h4><p>​以4为处理单位，仍旧按行处理，每一行的数据可一次处理4个。</p><p>​具体代码如下：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">void sseGauss(Matrix* dataset) {    for (int count = 0; count &lt; 50; count++) {        __m128 t1, t2, t3, t4;        for (int k = 0; k &lt; n; k++) {            float tmp[4] = { dataset[count].a[k][k], dataset[count].a[k][k], dataset[count].a[k][k], dataset[count].a[k][k] };            t1 = _mm_loadu_ps(tmp);            for (int j = n - 4; j &gt;= k; j -= 4) {                t2 = _mm_loadu_ps(dataset[count].a[k] + j);                t3 = _mm_div_ps(t2, t1);                _mm_storeu_ps(dataset[count].atemp[k] + j, t3);            }            if (k % 4 != (n % 4)) {                for (int j = k; j % 4 != (n % 4); j++) {                    dataset[count].atemp[k][j] = dataset[count].a[k][j] / tmp[0];                }            }            for (int j = (n % 4) - 1; j &gt;= 0; j--) {                dataset[count].atemp[k][j] = dataset[count].a[k][j] / tmp[0];            }            for (int i = k + 1; i &lt; n; i++) {                float tmp[4] = { dataset[count].a[i][k], dataset[count].a[i][k], dataset[count].a[i][k], dataset[count].a[i][k] };                t1 = _mm_loadu_ps(tmp);                for (int j = n - 4; j &gt; k; j -= 4) {                    t2 = _mm_loadu_ps(dataset[count].a[i] + j);                    t3 = _mm_loadu_ps(dataset[count].atemp[k] + j);                    t4 = _mm_sub_ps(t2, _mm_mul_ps(t1, t3));                    _mm_storeu_ps(dataset[count].a[i] + j, t4);                }                for (int j = k + 1; j % 4 != (n % 4); j++) {                    dataset[count].a[i][j] = dataset[count].a[i][j] - dataset[count].a[i][k] * dataset[count].atemp[k][j];                }                dataset[count].a[i][k] = 0;            }        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​循环每次跳跃4个元素，算法时间复杂度为O((n^3)/4)</p><h4 id="串行实现回代"><a href="#串行实现回代" class="headerlink" title="串行实现回代"></a>串行实现回代</h4><p>​将得到的上三角矩阵，从第 n 行开始，倒序回代到前面的每一行，即可求解 Xn 到 X1 的值。</p><p>​具体代码如下：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">    for (int count = 0; count &lt; 50; count++) {        for (int i = n - 1; i &gt;= 0; i--) {            float sum = 0;            for (int j = n - 1; j &gt; i; j--) {                sum += dataset[count].a[i][j] * dataset[count].x[j];            }            dataset[count].x[i] = (dataset[count].b[i] - sum) / dataset[count].a[i][i];        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​算法的时间复杂度为 O(n) = n^2 </p><h4 id="sse实现回代"><a href="#sse实现回代" class="headerlink" title="sse实现回代"></a>sse实现回代</h4><p>​和串行实现回代相比，向量化计算可以同时处理四个元素。</p><p>​具体代码为：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">void sseBack(Matrix* dataset) {    __m128 t1, t2, sumSSE;    float sum;    for (int count = 0; count &lt; 50; count++) {        for (int i = n - 1; i &gt;= 0; i--) {            if ((n - 1 - i) == 4)break;            float sum = 0;            for (int j = n - 1; j &gt; i; j--) {                sum += dataset[count].a[i][j] * dataset[count].x[j];            }            dataset[count].x[i] = (dataset[count].b[i] - sum) / dataset[count].a[i][i];        }        for (int i = n - 5; i &gt;= 0; i--) {            sumSSE = _mm_setzero_ps();            sum = 0;            int forSerial = (n - i - 1) % 4;            for (int j = i + forSerial + 1; j &lt;= n - 4; j += 4) {                t1 = _mm_loadu_ps(dataset[count].a[i] + j);                t2 = _mm_loadu_ps(dataset[count].x + j);                t1 = _mm_mul_ps(t1, t2);                sumSSE = _mm_add_ps(sumSSE, t1);            }            sumSSE = _mm_hadd_ps(sumSSE, sumSSE);            sumSSE = _mm_hadd_ps(sumSSE, sumSSE);            _mm_store_ss(&amp;sum, sumSSE);            for (int j = i + 1; j &lt;= i + forSerial; j++) {                sum += dataset[count].a[i][j] * dataset[count].x[j];            }            dataset[count].x[i] = (dataset[count].b[i] - sum) / dataset[count].a[i][i];        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​算法时间复杂度 O(n) = ((n^2) / 4)</p><h3 id="细节设计-1"><a href="#细节设计-1" class="headerlink" title="细节设计"></a>细节设计</h3><h4 id="计时方法-1"><a href="#计时方法-1" class="headerlink" title="计时方法"></a>计时方法</h4><p>​计时方面，我使用了课件中给出的Windows下精准计时方法，即QueryPerformance系列API。</p><p>​以串行消元算法的计时为例，具体代码如下：</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/img_v2_bfdf75f4-6f26-4787-b294-c4a1cda649ag.jpg" alt="img_v2_bfdf75f4-6f26-4787-b294-c4a1cda649ag"></p><h4 id="计时精度-1"><a href="#计时精度-1" class="headerlink" title="计时精度"></a>计时精度</h4><p>​本实验随机生成了50个矩阵，将计算过程重复了50次，足以匹配计算计时精度，再计算平均时间。</p><p>​以串行算法为例，具体代码如下：</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/img_v2_bfdf75f4-6f26-4787-b294-c4a1cda649ag.jpg" alt="img_v2_bfdf75f4-6f26-4787-b294-c4a1cda649ag"></p><h4 id="实验数据设计-1"><a href="#实验数据设计-1" class="headerlink" title="实验数据设计"></a>实验数据设计</h4><p>​本实验测试了不同规模的矩阵，由小至大，分别测试了规模为0、50、100、150……400的矩阵，随机生成矩阵元素值。</p><p>​随机生成矩阵的过程为：</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/img_v2_e3f8c442-f0a3-4071-904d-21613cffdb8g.jpg" alt="img_v2_e3f8c442-f0a3-4071-904d-21613cffdb8g"></p><h4 id="实验方法-1"><a href="#实验方法-1" class="headerlink" title="实验方法"></a>实验方法</h4><p>为了降低误差，本实验重复了两次取平均值。</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/img_v2_79adafc4-a4a9-4e25-aaec-9dcb5816256g.jpg" alt="img_v2_79adafc4-a4a9-4e25-aaec-9dcb5816256g"></p><h3 id="实验及结果分析-1"><a href="#实验及结果分析-1" class="headerlink" title="实验及结果分析"></a>实验及结果分析</h3><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/img_v2_081775d8-9d8d-4f52-a840-6b6f7b18085g.jpg" alt="img_v2_081775d8-9d8d-4f52-a840-6b6f7b18085g"></p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/img_v2_4559f7ab-1b62-4521-b9a7-a7a77f98123g.jpg" alt="img_v2_4559f7ab-1b62-4521-b9a7-a7a77f98123g"></p><p>​由图可知，SSE 算法的消元总体来说是运行效率是高于串行算法消元的;串行回代的效率也高于sse回代。</p><p>​同时，通过 Excel 中趋势线的计算，可以得出消元算法的时间复杂度符合O(n^3)，验证了前面对时间复杂度的分析。同时也可以得出回代过程的时间复杂度为 O(n^2)</p><h3 id="不同算法策略对性能的影响"><a href="#不同算法策略对性能的影响" class="headerlink" title="不同算法策略对性能的影响"></a>不同算法策略对性能的影响</h3><h4 id="相同算法对于不同问题规模的性能提升是否有影响，影响情况如何"><a href="#相同算法对于不同问题规模的性能提升是否有影响，影响情况如何" class="headerlink" title="相同算法对于不同问题规模的性能提升是否有影响，影响情况如何"></a>相同算法对于不同问题规模的性能提升是否有影响，影响情况如何</h4><p>​从2.4实验结果的图表中可以看出，在问题规模较小时，串行消元和sse消元运行时间相差不大，sse消元法对于性能的提升不明显；但是当问题的规模逐渐变大sse算法明显要优于串行算法，对性能的提升更大。</p><h4 id="回代过程可否向量化，有的话性能提升情况如何"><a href="#回代过程可否向量化，有的话性能提升情况如何" class="headerlink" title="回代过程可否向量化，有的话性能提升情况如何"></a>回代过程可否向量化，有的话性能提升情况如何</h4><p>​回代过程可以向量化，根据下图可以看出回代过程采用向量化明显提升了运行效率，和串行回代相比缩短了运行时间。随着规模的增大，性能提升更显著。</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/img_v2_4559f7ab-1b62-4521-b9a7-a7a77f98123g.jpg" alt="img_v2_4559f7ab-1b62-4521-b9a7-a7a77f98123g"></p>]]></content>
      
      
      <categories>
          
          <category> 并行程序设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 并行程序设计 </tag>
            
            <tag> S5课上 </tag>
            
            <tag> 实验报告 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>并行程序设计-第二讲.并行硬件与并行软件</title>
      <link href="/2022/09/13/di-er-jiang-bing-xing-ying-jian-he-bing-xing-ruan-jian/"/>
      <url>/2022/09/13/di-er-jiang-bing-xing-ying-jian-he-bing-xing-ruan-jian/</url>
      
        <content type="html"><![CDATA[<h1 id="第二讲-并行硬件和并行软件"><a href="#第二讲-并行硬件和并行软件" class="headerlink" title="第二讲 并行硬件和并行软件"></a>第二讲 并行硬件和并行软件</h1><h2 id="冯诺依曼结构"><a href="#冯诺依曼结构" class="headerlink" title="冯诺依曼结构"></a>冯诺依曼结构</h2><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210102147832.png" alt="image-20221010214750673" style="zoom:50%;"><p>缺点：cpu和存储器离得太远，取指令时间很长</p><h3 id="冯诺依曼模型改进"><a href="#冯诺依曼模型改进" class="headerlink" title="冯诺依曼模型改进"></a>冯诺依曼模型改进</h3><h4 id="利用cache"><a href="#利用cache" class="headerlink" title="利用cache"></a>利用cache</h4><ul><li><p>多级缓存</p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210102209318.png" style="zoom:25%;"></li><li><p>cpu向cache写数据时，cache和主存中的值不一致的问题</p><ul><li>写直达：当CPU 向Cache写数据时，高速缓存行会立即写入 主存中。</li><li>写回：Cache中，数据不是立即 更新到主存中，而是将发生数据更新的高速 缓存行标记称脏(dirty)。当发生高速缓存行 替换时，标记为脏的高速缓存行被写入主存 中。</li></ul></li></ul><h4 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h4><p>内存不够用时，再磁盘中开辟一块区域作为虚拟内存</p><p>但是常用的指令还是要放到内存中</p><h4 id="指令级并行ILP"><a href="#指令级并行ILP" class="headerlink" title="指令级并行ILP"></a>指令级并行ILP</h4><p>通过让多个处理器或者功能单元同时执 行指令来提高处理器的性能。</p><ul><li><p><strong>流水线</strong>：将功能单元分阶段安排</p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210102228662.png" style="zoom:25%;"></li><li><p><strong>多发射</strong>：让多条指令同时启动</p><ul><li><strong>静态</strong>多发射：功能单元在<strong>编译</strong>时调度</li><li><strong>动态</strong>多发射：功能单元再<strong>运行</strong>时间调度<ul><li>支持动态多发射的处理器叫做<strong>超标量</strong></li></ul></li><li>这两种发射方式都是<strong>硬件</strong>级别的，不是程序员控制的</li></ul><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210102231899.png" alt="image-20221010223142729" style="zoom:25%;"></li><li><p>超标量</p><ul><li><p>为了能够利用多发射，系统必须找出能够同时执行的指令</p></li><li><p>在预测技术中，编译器或者处理器对一条指令进行猜测，然后在<strong>猜测</strong>的基础上执行代码。（可能会猜错</p></li><li><p>例1</p><img src="C:\Users\xiaon\AppData\Roaming\Typora\typora-user-images\image-20221021205239913.png" alt="image-20221021205239913" style="zoom: 25%;"><p>如果*a_p指向的是z，那么这两条指令不能同时执行</p></li><li><p>例2</p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210212110457.png" alt="image-20221021211033384" style="zoom:25%;"><p>z可能为正数也可能为负数</p><p>如果系统猜错了，必须返回并重新计算w=y</p></li></ul></li></ul><h2 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h2><ul><li><p><strong>进程</strong>：是运行着的程序的一个实例</p><ul><li><p><strong>多任务操作系统</strong></p><p>给人一种单一处理器系统同时运行多个程序的错觉</p><p>实际上<strong>每个进程轮流运行</strong></p><p>执行了一个时间片的时间后，他会等待一段时间直到再次运行</p></li></ul></li><li><p><strong>线程</strong></p><ul><li><p>线程包含在进程中</p></li><li><p>每个线程相互独立</p><p>当某个任务阻塞时能执行其他任务</p></li><li><p>线程间的切换比进程间的切换要快</p></li></ul></li></ul><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210102203190.png" alt="image-20221010220356970" style="zoom: 33%;"><h3 id="硬件多线程"><a href="#硬件多线程" class="headerlink" title="硬件多线程"></a>硬件多线程</h3><p>硬件多线程为系统提供一种机制，使得当前执行的任务被阻塞时，系统能够继续其他有用的工作</p><p>硬件多线程分为一下三种类型：</p><p>图示？？？？？？？？？？？？？？？？？？？？？？？？？？？？？</p><ul><li><p>细粒度（程序员不可见</p><ul><li>处理器在<strong>每条指令</strong>完成后切换线程，从而跳过被阻塞的线程</li><li><strong>优点</strong>：能够避免因为阻塞而导致机器时间的浪费</li><li><strong>缺点</strong>：执行很长一段指令的线程在执行每条指令的时候都要等待</li></ul></li><li><p>粗粒度（程序员不可见</p><ul><li>只切换那些需要<strong>等待较长时间才能完成操作而被阻塞的线程</strong></li><li><strong>优点</strong>：不需要线程间的立即切换</li><li><strong>缺点</strong>：处理器还是可能在短阻塞时空闲，线程间的切换会导致延迟</li></ul></li><li><p>同步多线程（程序员可见，可以通过写程序来控制</p><ul><li>类似于多核（真正的同时</li><li>允许多个线程同时使用多个功能单元来利用超标量处理器的性能</li><li>局限性：一个核上面不会有太多的线程，常见的是2个线程</li></ul></li></ul><h2 id="并行硬件"><a href="#并行硬件" class="headerlink" title="并行硬件"></a>并行硬件</h2><h3 id="Flynn’s-分类法"><a href="#Flynn’s-分类法" class="headerlink" title="Flynn’s 分类法"></a>Flynn’s 分类法</h3><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210212141324.png" alt="image-20221021214151218" style="zoom:33%;"><h3 id="SIMD（单指令多数据流）"><a href="#SIMD（单指令多数据流）" class="headerlink" title="SIMD（单指令多数据流）"></a>SIMD（单指令多数据流）</h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>通过将<strong>数据</strong>分配给多个处理器实现并行化</p><p>使用<strong>相同的指令</strong>来操纵数据子集</p><p>这种并行称为<strong>数据并行</strong></p><p> 例子</p><ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210220916715.png" alt="image-20221022091601607" style="zoom: 33%;"></li><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210220916572.png" alt="image-20221022091638479"></li></ul><h4 id="SIMD缺点："><a href="#SIMD缺点：" class="headerlink" title="SIMD缺点："></a>SIMD缺点：</h4><ul><li>所有ALU（算术处理单元）<strong>要么执行相同的指令，要么同时处于空闲状态</strong></li><li>ALU<strong>没有指令存储器</strong></li><li>在经典的SIMD系统中，ALU必须<strong>同步</strong>操作</li><li>SIMD并行性在<strong>大型数据</strong>并行问题上非常有用，处理其他并行问题时并不优秀</li></ul><h4 id="SIMD典型应用"><a href="#SIMD典型应用" class="headerlink" title="SIMD典型应用"></a>SIMD典型应用</h4><h5 id="向量处理器"><a href="#向量处理器" class="headerlink" title="向量处理器"></a>向量处理器</h5><ul><li><p>向量处理器是对<strong>数组或者数据向量</strong>进行操作，而传统的cpu是对<strong>单独数据元素或者标量</strong>进行操作</p></li><li><p>原理</p><ul><li><p>向量寄存器</p><p>能够存储由<strong>多个操作数组成的向量</strong>，并且能够同时对其内容进行操作的寄存器</p></li><li><p>向量化和流水化的功能单元</p><p>对向量中每个元素做同样的操作，这些操作需要应用到2个或以上对应元素上</p></li><li><p>向量指令</p><p>在向量上操作而不是在标量上操作</p></li><li><p>交叉存储器（不太重要</p><p>内存系统由多个内存“体”组成，每个内存体能够独立访问</p><p>如果向量中各个元素分布在<strong>不同的内存体</strong>中，那么在装入/存储连续数据时几乎能够<strong>无延迟访问</strong></p></li><li><p>步长式存储器访问和硬件的散射/聚集（不太重要</p><p>程序能够访问向量中固定间隔的元素</p></li></ul></li><li><p>向量处理器优点（理解即可</p><ul><li><p>速度快</p></li><li><p>容易使用</p></li><li><p>向量编译器擅长于识别向量化的代码</p></li><li><p>编译器也能提供代码为什么不能向量化的原因</p><p>帮助程序员重新评估代码</p></li><li><p>很高的内存带宽</p></li><li><p>每个加载的数据都会使用</p></li></ul></li><li><p>向量处理器缺点</p><ul><li>不能处理<strong>不规则</strong>的数据结构和其他并行结构<ul><li>不规则：例如加一个判断语句y&gt;0之类的就不适用</li></ul></li><li>他的<strong>可扩展性</strong>是个限制，可扩展性是指能够处理更大问题的能力<ul><li>想要提高性能就只能增加向量处理器的数量，而不是提高向量处理器的能力</li></ul></li></ul></li></ul><h5 id="GPU（图形处理单元）"><a href="#GPU（图形处理单元）" class="headerlink" title="GPU（图形处理单元）"></a>GPU（图形处理单元）</h5><ul><li>GPU使用图形处理流水线将物体表面的内部表示转化成一个像素的数组</li><li>流水线的许多阶段（通过着色函数实现）是可编程的</li><li>GPU常使用SIMD来优化性能</li><li>现在所有的GPU都使用SIMD并行<ul><li>尽管GPU不是纯粹的SIMD系统（GUP里有很多很多核</li><li>1个控制单元对应多个处理单元？？？</li></ul></li></ul><h3 id="MIMD（多指令多数据流）"><a href="#MIMD（多指令多数据流）" class="headerlink" title="MIMD（多指令多数据流）"></a>MIMD（多指令多数据流）</h3><ul><li><p>支持同时多个指令流在多个数据流上操作</p></li><li><p>通常包括完全独立的处理单元或者核，每个处理单元或者核都有自己的控制单元和ALU</p><ul><li><p>对比SIMD：</p><p>SIMD系统那些指令单元必须<strong>同步执行相同指令</strong></p></li></ul></li></ul><h4 id="MIMD分为两大类"><a href="#MIMD分为两大类" class="headerlink" title="MIMD分为两大类"></a>MIMD分为两大类</h4><h5 id="共享内存系统"><a href="#共享内存系统" class="headerlink" title="共享内存系统"></a>共享内存系统</h5><ul><li><p>一组自治的处理器通过互联网络与内存系统相互连接</p><ul><li>意思是这些处理器<strong>共享所有内存</strong>，每个处理器能够访问每个内存区域</li><li>处理器通过<strong>访问共享的数据结构</strong>来<strong>隐式的通信</strong></li></ul></li><li><p>最广泛使用的共享内存系统使用一个或者多个多核处理器</p><ul><li>在一块芯片上有多个cpu或者核</li></ul></li><li><p>图示</p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210221002252.png" alt="image-20221022100256140" style="zoom: 25%;"></li><li><p>共享内存系统可以分为两类：</p><ul><li><p>UMA一致内存访问系统</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210221006036.png" alt="image-20221022100638935"></p></li><li><p>NUMA非一致内存访问系统</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210221010042.png" alt="image-20221022101055916"></p><p>这是共享内存系统，而不是分布式内存系统！！</p></li></ul></li></ul><h5 id="分布式内存系统"><a href="#分布式内存系统" class="headerlink" title="分布式内存系统"></a>分布式内存系统</h5><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210221010627.png" alt="image-20221022101027522" style="zoom: 25%;"><ul><li>集群（最广泛使用<ul><li>这些系统中的节点是通过通信网络互相连接的独立计算单元</li></ul></li></ul><h4 id="互联网络"><a href="#互联网络" class="headerlink" title="互联网络"></a>互联网络</h4><ul><li><p>在分布式内存系统和共享内存系统都扮演了一个决定性的角色</p></li><li><p>分为两类</p><p>共享内存互联网络</p><p>分布式内存互联网络</p><p>=======================草，从这往后好像都没讲草草草草</p></li></ul><h5 id="共享内存互联网络"><a href="#共享内存互联网络" class="headerlink" title="共享内存互联网络"></a>共享内存互联网络</h5><ul><li><p>总线互连</p><ul><li>需要排队，但成本低</li><li>随着连接到总线的设备数量的增加，对总线 的使用的竞争会增加，性能会下降。</li></ul></li><li><p>交换互连网络</p><p>灵活但造价高</p><p>允许<strong>不同设备</strong>之间<strong>同时</strong>进行通信</p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210231827338.png" alt="image-20221023182726222" style="zoom: 50%;"><h6 id="cache一致性问题"><a href="#cache一致性问题" class="headerlink" title="cache一致性问题"></a>cache一致性问题</h6><p><img src="https://tva1.sinaimg.cn/large/008vxvgGly1h7o682zywcj30gw0osjsp.jpg" alt="image-20221031083552339"></p><p>Y1，z1为1号核的私有变量</p><p>y0为0号核的私有变量</p><p><img src="https://tva1.sinaimg.cn/large/008vxvgGly1h7o6bou6v7j30xu0e2myq.jpg" alt="image-20221031083920604"></p></li><li><p>监听cache一致性协议</p><ul><li>core0更新x时，会在总线上广播更新信息，core1可以监听到（⚠️不是直接传递x的信息，而是广播共享）</li></ul></li><li><p>基于目录的cache一致性协议</p><ul><li>使用一个叫做<strong>目录</strong>的结构，存储每个内存行的状态</li><li>当一个变量需要更新时，就会查询目录，并将所有包含该<strong>变量</strong>的高速缓存行设置为非法</li></ul></li></ul><h5 id="分布式内存互联网络"><a href="#分布式内存互联网络" class="headerlink" title="分布式内存互联网络"></a>分布式内存互联网络</h5><h6 id="分为两种：直接互连（要求全部掌握）、间接互连"><a href="#分为两种：直接互连（要求全部掌握）、间接互连" class="headerlink" title="分为两种：直接互连（要求全部掌握）、间接互连"></a>分为两种：直接互连（要求全部掌握）、间接互连</h6><ul><li><p>直接互连</p><ul><li><p>每个交换器与一个处理器-内存对直接相连，交换器之间也互相连接</p></li><li><p>一个环</p><p>可以同时进行通信</p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210231835525.png" alt="image-20221023183528459" style="zoom:50%;"></li><li><p>二维环面网络</p><p>可以同时进行信息交换的节点更多</p><p>造价更高</p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210231836859.png" alt="image-20221023183648796" style="zoom: 33%;"></li></ul></li><li><p>间接互连</p><ul><li><p>交换器不一定与处理器直接相连</p></li><li><p>间接网络中相对简单的例子：</p><ul><li><p>交叉开关矩阵</p><p>区分<strong>共享互联网络</strong>中的交叉开关矩阵</p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210231925922.png" alt="image-20221023192547825" style="zoom:33%;"></li><li><p>Omega网络</p><p><img src="https://tva1.sinaimg.cn/large/008vxvgGly1h7o5yhbdsaj30p00nymyn.jpg" alt="image-20221031082637682"></p></li></ul></li></ul></li></ul><h6 id="一些定义（直接互连中）"><a href="#一些定义（直接互连中）" class="headerlink" title="一些定义（直接互连中）"></a>一些定义（直接互连中）</h6><ul><li><p>等分宽度（需要会计算</p><ul><li><p>衡量“同时通信的链路数目”或者“连接性”的一个标准</p></li><li><p>想象并行系统被分成两部分，每部分都 有一半的处理器或者节点。在这两部份 之间能同时发生多少通信呢？</p></li><li><p>例1：一个环的两种等分<img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210231845256.png" alt="image-20221023184507171"></p><p>等分宽度求的是最少的情况下的同时通信链路数目</p><p>这个环的等分宽度是2而不是4</p></li><li><p>例2：一个二维环面网格的等分</p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210231852261.png" alt="image-20221023185215144" style="zoom: 25%;"><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210231852924.png" alt="image-20221023185239861" style="zoom: 33%;"><p>把红线全部删掉才能把网格结构<strong>等分成两份</strong>，把两部分完全分开，由图一变成图二，要剪断<strong>8</strong>根线</p><p><strong>总结</strong>：</p><p>二维环面网格的<strong>等分宽度</strong>为<strong>2*p^(0.5)</strong></p><p>p表示处理器的数目</p></li></ul></li><li><p>延迟</p><ul><li>指从发送源开始传送数据到目的地开始接受数据之间的时间</li><li><img src="https://tva1.sinaimg.cn/large/008vxvgGly1h7o611kz3fj30qm0ikwg2.jpg" alt="image-20221031082906633"></li></ul></li><li><p>带宽</p><ul><li>传输数据的速度</li><li>通常用兆位每秒或者兆字节每秒来表示</li></ul></li><li><p>等分带宽</p><ul><li>等分带宽=等分宽度×带宽</li><li>用来衡量网络的质量</li><li>不是计算连接两个等分之间的链路数，而是计算链路的带宽</li></ul></li></ul><h6 id="几个直接互连的例子"><a href="#几个直接互连的例子" class="headerlink" title="几个直接互连的例子"></a>几个直接互连的例子</h6><ul><li><p>全相连网络</p><ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210231906924.png" alt="image-20221023190651837"></li><li>等分宽度太大，造价高，不切实际</li></ul></li><li><p>超立方体</p><ul><li>假如维度为d，则有2^d（p=2^d）个节点，等分宽度为p➗2</li></ul></li></ul><table><thead><tr><th>结构</th><th>图片</th><th>等分宽度（p为交换器数目）</th></tr></thead><tbody><tr><td>环</td><td><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210231915846.png" alt="image-20221023191549780" style="zoom:25%;"></td><td>2</td></tr><tr><td>二维环面网状结构</td><td><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210231917760.png" alt="image-20221023191734686" style="zoom:25%;"></td><td><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210231916152.png" alt="image-20221023191644099" style="zoom:25%;"></td></tr><tr><td>超立方体</td><td><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210231918391.png" alt="image-20221023191804315" style="zoom:25%;"></td><td><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/202210231918813.png" alt="image-20221023191829753" style="zoom:25%;"></td></tr></tbody></table><p>当p&gt;4时，性能：超立方体结构&gt;二维环面网状结构、环</p><h4 id=""><a href="#" class="headerlink" title=""></a></h4><hr><p>下面这块是从w4l2开始的，中间部分老师跳过了</p><h2 id="并行算法分析"><a href="#并行算法分析" class="headerlink" title="并行算法分析"></a>并行算法分析</h2><h3 id="基本指标-🌟必考"><a href="#基本指标-🌟必考" class="headerlink" title="基本指标(🌟必考)"></a>基本指标(🌟必考)</h3><ul><li><p>串行算法评价：</p><ul><li>算法时间复杂度表示为<strong>输入规模</strong>的函数</li></ul></li><li><p>并行算法评价</p><ul><li><p>除了输入规模之外，还需要考虑处理器的树木、处理器相对运算速度、通信速度</p></li><li><p>运行时间</p></li><li><p>加速比：选择串行算法<strong>最优</strong>的时间和并行算法时间做除法</p><ul><li>默认串行算法和并行算法所用的处理器相同</li></ul><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102104746771.png" alt="image-20221102104746771"></p></li></ul></li></ul><h4 id="加速比"><a href="#加速比" class="headerlink" title="加速比"></a>加速比</h4><ul><li><p>例</p><ul><li><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102105459233.png" alt="image-20221102105459233"></p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102105529255.png" alt="image-20221102105529255"></p></li><li><p>初始：每个进程保存一个数，最终由一个进程保存累加和</p></li><li><p>树形结构：logn个步骤</p><p>每个步骤进行一次加法：</p><p>和一个机器字的传输</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102112240099.png" alt="image-20221102112240099"></p><p>没懂？？？</p></li></ul></li><li><p>例。加速比的计算（‼️考试容易考）</p><ul><li><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102112435610.png" alt="image-20221102112435610"></p></li><li><p>p为核数</p></li><li><p>搜索分解导致超线性的例子</p><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102113015030.png" alt="image-20221102113015030"></p></li></ul></li></ul><h5 id="阿姆达尔定律"><a href="#阿姆达尔定律" class="headerlink" title="阿姆达尔定律"></a>阿姆达尔定律</h5><ul><li><p>定义</p><ul><li>除非一个串行程序的执行几乎全部都并行化，否则不论多少可以利用的核，通过并行化所产生的加速比都会是受限的</li><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102200500482.png" alt="image-20221102200500482"></li></ul></li><li><p>例子</p><ul><li><p>理想化：0.9的可完全并行，拥有线性加速比<img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102200035338.png" alt="image-20221102200035338"></p></li><li><p>从公式可以看出来，s和串行程序运行时间是无关的</p></li></ul></li></ul><h4 id="效率"><a href="#效率" class="headerlink" title="效率"></a>效率</h4><ul><li><p>效率：度量有效计算时间</p></li><li><p><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102200902075.png" alt="image-20221102200902075"></p></li><li><p>例1</p><ul><li>n个核对n个数求和</li><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102201204778.png" alt="image-20221102201204778"></li></ul></li><li><p>例2</p><ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102201235794.png" alt="image-20221102201235794"></li></ul></li></ul><h4 id="可扩展性"><a href="#可扩展性" class="headerlink" title="可扩展性"></a>可扩展性</h4><ul><li><p>我们希望，保持问题规模不变时，效率不随着线程数的增加而降低，则称程序是可扩展的</p><ul><li>强扩展的</li></ul></li><li><p>问题规模增大时，效率不随着线程数的增加而降低，则称程序是可扩展的</p><ul><li>弱扩展的</li></ul></li><li><p>例子</p><p> <img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102203837409.png" alt="image-20221102203837409"></p></li><li><p>例子：快速傅立叶变换</p><ul><li><img src="https://zxn-1313885264.cos.ap-beijing.myqcloud.com/images_typora/image-20221102204141865.png" alt="image-20221102204141865"></li></ul></li></ul><h3 id="并行程序设计的复杂性"><a href="#并行程序设计的复杂性" class="headerlink" title="并行程序设计的复杂性"></a>并行程序设计的复杂性</h3><ul><li>足够的并发度</li><li>并发粒度<ul><li>独立的计算任务的大小</li></ul></li><li>局部性<ul><li>对临近数据进行计算</li><li>尽量减少数据的计算，对离得比较近的数据进行计算</li></ul></li><li>负载均衡<ul><li>每个处理器工作量相近</li></ul></li><li>协调和同步</li></ul><h3 id="并行算法额外开销"><a href="#并行算法额外开销" class="headerlink" title="并行算法额外开销"></a>并行算法额外开销</h3><ul><li>进程间通信<ul><li>也可能是线程通信</li><li>最大开销，大部分并行算法都需要</li></ul></li><li>进程空闲<ul><li>负载不均，同步操作，不能并行化的部分</li></ul></li><li>额外计算<ul><li>最优串行算法难以并行化，将很差的串行算法并行化，并行算法计算量&gt;最优串行算法</li><li>最优串行算法并行化也会产生额外计算<ul><li>并行快速傅立叶变换</li><li>旋转因子的重复计算</li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 并行程序设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 并行程序设计 </tag>
            
            <tag> S5课上 </tag>
            
            <tag> 知识总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工智能导论-深度学习实验</title>
      <link href="/2022/09/13/shen-du-shen-jing-wang-luo-shi-yan-bao-gao/"/>
      <url>/2022/09/13/shen-du-shen-jing-wang-luo-shi-yan-bao-gao/</url>
      
        <content type="html"><![CDATA[<h1 id="深度神经网络实验报告"><a href="#深度神经网络实验报告" class="headerlink" title="深度神经网络实验报告"></a>深度神经网络实验报告</h1><h2 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h2><ul><li>分别使用全连接网络，卷积神经网络，循环神经网络去预测数据（图像分类） CIFAR-10 数据集</li><li>使用几个机器学习算法（自选）作为比较。 对预测结果进行分析。<ul><li>SVM算法</li><li>KNN算法</li></ul></li></ul><h2 id="CIFAR-10数据集介绍"><a href="#CIFAR-10数据集介绍" class="headerlink" title="CIFAR-10数据集介绍"></a>CIFAR-10数据集介绍</h2><h3 id="数据集内容"><a href="#数据集内容" class="headerlink" title="数据集内容"></a>数据集内容</h3><p>​CIFAR10数据集共有60000个样本，每个样本都是一张32*32像素的RGB图像（彩色图像），每个RGB图像又必定分为3个通道（R通道、G通道、B通道）。这60000个样本被分成了50000个训练样本和10000个测试样本。<br>CIFAR10数据集是用来监督学习训练的，那么每个样本就一定都配备了一个标签值（用来区分这个样本是什么），不同类别的物体用不同的标签值，CIFAR10中有10类物体，标签值分别按照0~9来区分,他们分别是飞机（ airplane ）、汽车（ automobile ）、鸟（ bird ）、猫（ cat ）、鹿（ deer ）、狗（ dog ）、青蛙（ frog ）、马（ horse ）、船（ ship ）和卡车（ truck ）。</p><p>​CIFAR10数据集的内容，如下图所示：</p><table><thead><tr><th>物体种类</th><th></th><th></th><th></th><th></th><th></th><th>图片</th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>airplane</td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/airplane1.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/airplane2.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/airplane3.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/airplane4.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/airplane5.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/airplane6.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/airplane7.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/airplane8.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/airplane9.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/airplane10.png" alt="img"></td></tr><tr><td>automobile</td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/automobile1.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/automobile2.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/automobile3.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/automobile4.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/automobile5.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/automobile6.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/automobile7.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/automobile8.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/automobile9.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/automobile10.png" alt="img"></td></tr><tr><td>bird</td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/bird1.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/bird2.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/bird3.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/bird4.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/bird5.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/bird6.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/bird7.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/bird8.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/bird9.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/bird10.png" alt="img"></td></tr><tr><td>cat</td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/cat1.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/cat2.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/cat3.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/cat4.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/cat5.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/cat6.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/cat7.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/cat8.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/cat9.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/cat10.png" alt="img"></td></tr><tr><td>deer</td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/deer1.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/deer2.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/deer3.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/deer4.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/deer5.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/deer6.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/deer7.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/deer8.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/deer9.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/deer10.png" alt="img"></td></tr><tr><td>dog</td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/dog1.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/dog2.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/dog3.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/dog4.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/dog5.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/dog6.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/dog7.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/dog8.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/dog9.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/dog10.png" alt="img"></td></tr><tr><td>frog</td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/frog1.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/frog2.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/frog3.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/frog4.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/frog5.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/frog6.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/frog7.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/frog8.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/frog9.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/frog10.png" alt="img"></td></tr><tr><td>horse</td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/horse1.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/horse2.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/horse3.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/horse4.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/horse5.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/horse6.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/horse7.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/horse8.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/horse9.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/horse10.png" alt="img"></td></tr><tr><td>ship</td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/ship1.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/ship2.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/ship3.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/ship4.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/ship5.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/ship6.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/ship7.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/ship8.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/ship9.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/ship10.png" alt="img"></td></tr><tr><td>truck</td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck1.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck2.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck3.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck4.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck5.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck6.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck7.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck8.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck9.png" alt="img"></td><td><img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck10.png" alt="img"></td></tr></tbody></table><h3 id="数据集的结构组成"><a href="#数据集的结构组成" class="headerlink" title="数据集的结构组成"></a>数据集的结构组成</h3><p>​CIFAR10数据集结构组成可分为这四个部分：</p><ul><li>·train_x:(50000, 32, 32, 3)——训练样本</li><li>·train_y:(50000, 1)——训练样本标签</li><li>·test_x:(10000, 32, 32, 3)——测试样本</li><li>·test_y:(10000, 1)——测试样本标签</li></ul><h3 id="数据集的下载方式"><a href="#数据集的下载方式" class="headerlink" title="数据集的下载方式"></a>数据集的下载方式</h3><p>​在Keras中已经内置了多种公共数据集，其中就包含CIFAR-10数据集，如图所示。</p><table><thead><tr><th>序号</th><th>名称</th><th>说明</th></tr></thead><tbody><tr><td>1</td><td>boston_housing</td><td>波士顿房价数据集</td></tr><tr><td>2</td><td>CIFAR10</td><td>10种类别的图片集</td></tr><tr><td>3</td><td>CIFAR100</td><td>100种类别的图片集</td></tr><tr><td>4</td><td>MNIST</td><td>手写数字图片集</td></tr><tr><td>5</td><td>Fashion-MNIST</td><td>10种时尚类别的图片集</td></tr><tr><td>6</td><td>IMDB</td><td>电影点评数据集</td></tr><tr><td>7</td><td>Reuters</td><td>路透社新闻数据集</td></tr></tbody></table><p>​所以可以直接调用 tf.keras.datasets.cifar10，直接下载数据集。</p><p>​使用方法如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> keras<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> cifar10 <span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span> <span class="token operator">=</span> cifar10<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li>返回：<ul><li>2元组：<ul><li>x_train，x_test：具有形状（num_samples ，3，32，32）的RGB图像数据的uint8数组。</li><li>y_train，y_test：uint8具有形状（num_samples，）的类别标签数组（范围0-9中的整数）。</li></ul></li></ul></li></ul><h2 id="深度神经网络的说明"><a href="#深度神经网络的说明" class="headerlink" title="深度神经网络的说明"></a>深度神经网络的说明</h2><h3 id="全连接网络"><a href="#全连接网络" class="headerlink" title="全连接网络"></a>全连接网络</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>​全连接神经网络(DNN)是最朴素的神经网络，它的网络参数最多，计算量最大。</p><p>​DNN的结构不固定，一般神经网络包括<strong>输入层</strong>、<strong>隐藏层</strong>和<strong>输出层</strong>，一个DNN结构只有一个输入层，一个输出层，输入层和输出层之间的都是隐藏层。每一层神经网络有若干神经元(下图中蓝色圆圈)，层与层之间神经元相互连接，层内神经元互不连接，而且下一层神经元连接上一层所有的神经元。</p><p><img src="https://img2018.cnblogs.com/blog/1433301/201907/1433301-20190705201830865-1883632909.png" alt="img"></p><p>​<strong>优点</strong>：由于DNN几乎可以拟合任何函数，所以DNN的非线性拟合能力非常强。往往深而窄的网络要更节约资源。</p><p>​<strong>缺点：</strong>DNN不太容易训练，需要大量的数据，很多技巧才能训练好一个深层网络。</p><h4 id="模型说明"><a href="#模型说明" class="headerlink" title="模型说明"></a>模型说明</h4><p>​创建模型的代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#构建模型</span>layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> nodes <span class="token keyword">in</span> nodes_per_layer<span class="token punctuation">:</span> layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>nodes<span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 使用 l2 正则化 kernel_regularizer=tf.keras.regularizers.l2(l=0.0001)</span> layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout_rate<span class="token punctuation">)</span><span class="token punctuation">)</span>layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Softmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>layers<span class="token punctuation">)</span><span class="token comment">#编译模型</span>model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span>tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">,</span>              loss<span class="token operator">=</span><span class="token string">'sparse_categorical_crossentropy'</span><span class="token punctuation">,</span>              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​我创建了一个 Keras中的Sequential 模型，包含了多个网络层：</p><ul><li><p>模型的第一层是一个 Flatten 层，它将输入的多维数组展平为一维数组，以便于后面的全连接层使用。</p></li><li><p>模型包含了四个 Dense 层。Dense 层就是全连接层，每个节点都与上一层的所有节点连接。第一个 Dense 层有 512 个节点，使用 relu 作为激活函数。第二个 Dense 层有 256 个节点，也使用 relu 作为激活函数。第三个 Dense 层有 128 个节点，也使用 relu 作为激活函数。第四个 Dense 层有 64 个节点，也使用 relu 作为激活函数。在每两层中间插入一个dropout层，这样一来，第一层的输出将对第二层实现Dropout正则化，后续层与此类似。</p></li><li><p>模型的最后一层是一个 Softmax层，有 10 个节点。Softmax函数将多个标量映射为一个概率分布，其输出的每一个值范围在(0,1)。这在分类问题中很常用，因为概率值可以表示模型的置信度。</p></li></ul><p>​配置训练方法时，训练时用的优化器、损失函数和准确率评测标准如下：</p><ul><li><strong>optimizer 优化器</strong>：选用Adam，学习率lr设置为0.001</li><li><strong>loss 损失函数</strong>：选用稀疏的分类交叉熵 sparse_categorical_crossentropy</li><li><strong>metrics</strong> <strong>评价函数</strong>：选用准确率accuracy</li></ul><h4 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h4><p>​起初我训练模型时没有数据增强，代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">overfitting_hist <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> validation_data<span class="token operator">=</span><span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">,</span>                             use_multiprocessing<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#绘制训练和测试准确率</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>overfitting_hist<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>overfitting_hist<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'model accuracy'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230114184455601.png" alt="image-20230114184455601" style="zoom:33%;"><p>​此时，训练精度远高于测试精度（高达35%），此外，测试精度要么是静态的，要么是下降的，这意味着模型严重过度拟合。训练速度很快，使模型达到 50% 左右，但是它之后开始过度拟合，所以我切换到对生成数据进行训练，这些数据速度较慢，但不太可能导致过度拟合。</p><p>​因此，我切换到增强数据，在 50000 个样本上进行训练，在 10000 个样本上进行验证，代码如下；</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">augmented <span class="token operator">=</span> datagen<span class="token punctuation">.</span>flow<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>hist <span class="token operator">=</span> model<span class="token punctuation">.</span>fit_generator<span class="token punctuation">(</span>augmented<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>validation_data<span class="token operator">=</span><span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#绘制精度曲线</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>hist<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>hist<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'model accuracy'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​结果如图：</p><img src="/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230114172148881.png" alt="image-20230114172148881" style="zoom: 33%;"><p>​绘制出的测试和训练集的准确率图像如下：</p><img src="/Users/zhangxiaoni/Library/Containers/com.bytedance.macos.feishu/Data/Library/Application Support/LarkShell/sdk_storage/407120424b82e9e84d5a9fe5984b53e7/resources/images/img_v2_a4ac7ee4-f1da-47fa-b870-c0efba09a04g.jpg" alt="img_v2_a4ac7ee4-f1da-47fa-b870-c0efba09a04g" style="zoom: 33%;"><p>​从上图可以看出；一开始，测试精度优于训练精度，但在第一个时期之后，训练精度仅比测试精度高出 4%，这意味着模型不会过度拟合。</p><h4 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h4><p>​模型在测试集上的准确率如下：</p><p>![image-20230114172401122](/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230114172401122.png)</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>​一方面使用未增强的数据集进行训练会导致过度拟合；另一方面立即使用增强的数据集会导致欠拟合。因此，我想出的最好的方法是先使用未增强的数据进行训练，直到导致过度拟合，然后切换到增强数据。该模型在增强数据上进行训练的难度较小，因为它已经了解了类的许多主要特征，然后数据增强使学习变得更加困难，但不易过度拟合。</p><h4 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf<span class="token keyword">from</span> tensorflow <span class="token keyword">import</span> keras<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> os<span class="token comment">#超参数</span>epochs <span class="token operator">=</span> <span class="token number">30</span>nodes_per_layer <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">]</span>layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>batch_size <span class="token operator">=</span> <span class="token number">64</span>dropout_rate <span class="token operator">=</span> <span class="token number">0.3</span>num_classes <span class="token operator">=</span> <span class="token number">10</span><span class="token comment">#===========================</span><span class="token comment">#一.加载和标准化数据</span><span class="token comment">#===========================</span><span class="token comment">#加载数据</span><span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span> <span class="token operator">=</span> keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>cifar10<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#标准化图像</span>x_train <span class="token operator">=</span> tf<span class="token punctuation">.</span>map_fn<span class="token punctuation">(</span><span class="token keyword">lambda</span> image<span class="token punctuation">:</span> tf<span class="token punctuation">.</span>image<span class="token punctuation">.</span>per_image_standardization<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">,</span> x_train<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>x_train <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>run<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>x_test <span class="token operator">=</span> tf<span class="token punctuation">.</span>map_fn<span class="token punctuation">(</span><span class="token keyword">lambda</span> image<span class="token punctuation">:</span> tf<span class="token punctuation">.</span>image<span class="token punctuation">.</span>per_image_standardization<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>x_test <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>run<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token comment">#===========================</span><span class="token comment">#二.构建、编译模型</span><span class="token comment">#===========================</span><span class="token comment">#我没有使用 l2 正则化，因为它使使用生成的数据的学习速度变慢并且不会减少过度拟合</span>layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> nodes <span class="token keyword">in</span> nodes_per_layer<span class="token punctuation">:</span> layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>nodes<span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 使用 l2 正则化 kernel_regularizer=tf.keras.regularizers.l2(l=0.0001)</span> layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout_rate<span class="token punctuation">)</span><span class="token punctuation">)</span>layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Softmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>layers<span class="token punctuation">)</span><span class="token comment">#编译模型</span>model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span>tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">,</span>              loss<span class="token operator">=</span><span class="token string">'sparse_categorical_crossentropy'</span><span class="token punctuation">,</span>              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment">#===========================</span><span class="token comment">#三.训练模型</span><span class="token comment">#===========================</span><span class="token comment">#1. 没有使用数据增强</span><span class="token comment">#这种训练速度很快，使模型达到 50% 左右，但是它之后开始过度拟合，所以我切换到对生成数据进行训练，这些数据速度较慢，但不太可能导致过度拟合</span>overfitting_hist <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> validation_data<span class="token operator">=</span><span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">,</span>                             use_multiprocessing<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#绘制训练和测试准确率</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>overfitting_hist<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>overfitting_hist<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'model accuracy'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span><span class="token comment">#数据生成</span><span class="token comment">#定义数据生成器以生成更多样化的数据</span>datagen <span class="token operator">=</span> keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>image<span class="token punctuation">.</span>ImageDataGenerator<span class="token punctuation">(</span>    featurewise_center<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>    featurewise_std_normalization<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>    samplewise_center<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>    samplewise_std_normalization<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>    rotation_range<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span>    zoom_range<span class="token operator">=</span><span class="token number">0.07</span><span class="token punctuation">,</span>    width_shift_range<span class="token operator">=</span><span class="token number">0.15</span><span class="token punctuation">,</span>    height_shift_range<span class="token operator">=</span><span class="token number">0.15</span><span class="token punctuation">,</span>    shear_range<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>    horizontal_flip<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#初始化数据生成所需的变量</span>datagen<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span><span class="token comment">#2. 使用数据增强</span><span class="token comment">#使用生成的数据训练模型以避免过度拟合</span>augmented <span class="token operator">=</span> datagen<span class="token punctuation">.</span>flow<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>hist <span class="token operator">=</span> model<span class="token punctuation">.</span>fit_generator<span class="token punctuation">(</span>augmented<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>validation_data<span class="token operator">=</span><span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#绘制精度曲线</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>hist<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>hist<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'model accuracy'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span><span class="token comment">#===========================</span><span class="token comment">#四.评估模型</span><span class="token comment">#===========================</span>test_loss<span class="token punctuation">,</span> test_acc <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test accuracy:'</span><span class="token punctuation">,</span> test_acc<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h3><h4 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h4><p>如果用全连接神经网络处理大尺寸图像具有三个明显的缺点：</p><ul><li>将图像展开为向量会丢失空间信息；</li><li>参数过多效率低下，训练困难；</li><li>大量的参数也很快会导致网络过拟合。</li></ul><p>而使用卷积神经网络可以很好地解决上面的三个问题。</p><p>一个卷积神经网络主要由以下 5 层组成：</p><ul><li>数据输入层/ Input layer</li><li>卷积计算层/ CONV layer</li><li>ReLU 激励层 / ReLU layer</li><li>池化层 / Pooling layer</li><li>全连接层 / FC layer</li></ul><h4 id="模型说明-1"><a href="#模型说明-1" class="headerlink" title="模型说明"></a>模型说明</h4><p>​创建模型的代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#卷积层 32个3*3的卷积核 激活函数relu输入形状32*32*3</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#池化层 2*2</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#卷积层 64个3*3的卷积核 激活函数relu</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#池化层 2*2</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#卷积层 64个3*3的卷积核 激活函数relu</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#展平</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#全连接层 64个神经元 激活函数relu</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#全连接层 10个神经元 激活函数softmax</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"softmax"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​我创建了一个 Keras中的Sequential 模型，包含了多个网络层：</p><ul><li>模型的第一部分包含了三个卷积层，分别包含32个3 * 3、 64 个 3 * 3 、64 个 3 * 3的卷积核，和两个2*2的池化层</li><li>模型包含了一个Flatten层，将前一层的输出展平为一维张量。</li><li>模型的最后包含了两个全连接层，一个全连接层有64个神经元，激活函数为relu；另一个全连接层有10个单元，激活函数为softmax。</li></ul><h4 id="训练模型-1"><a href="#训练模型-1" class="headerlink" title="训练模型"></a>训练模型</h4><p>​将epochs设置为40，在 50000 个样本上进行训练，在 10000 个样本上进行验证，代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_images<span class="token punctuation">,</span> train_labels<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">40</span><span class="token punctuation">,</span>                    validation_data<span class="token operator">=</span><span class="token punctuation">(</span>test_images<span class="token punctuation">,</span> test_labels<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><img src="/Users/zhangxiaoni/Library/Containers/com.bytedance.macos.feishu/Data/Library/Application Support/LarkShell/sdk_storage/407120424b82e9e84d5a9fe5984b53e7/resources/images/img_v2_15fd61a7-6d0f-450f-8139-1f3aed0baa1g.jpg" alt="img_v2_15fd61a7-6d0f-450f-8139-1f3aed0baa1g" style="zoom:33%;"><img src="/Users/zhangxiaoni/Library/Containers/com.bytedance.macos.feishu/Data/Library/Application Support/LarkShell/sdk_storage/407120424b82e9e84d5a9fe5984b53e7/resources/images/img_v2_bed4c8ec-8e37-4ffd-8839-abcb5183df1g.jpg" alt="img_v2_bed4c8ec-8e37-4ffd-8839-abcb5183df1g" style="zoom:33%;"><h4 id="模型评估-1"><a href="#模型评估-1" class="headerlink" title="模型评估"></a>模型评估</h4><p>​模型在测试集上的准确率如下：</p><p>![img_v2_f2bb69a8-ea6b-4cb8-b976-53e6907612ag](/Users/zhangxiaoni/Library/Containers/com.bytedance.macos.feishu/Data/Library/Application Support/LarkShell/sdk_storage/407120424b82e9e84d5a9fe5984b53e7/resources/images/img_v2_f2bb69a8-ea6b-4cb8-b976-53e6907612ag.jpg)</p><h4 id="完整代码-1"><a href="#完整代码-1" class="headerlink" title="完整代码"></a>完整代码</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token comment">#===========================</span><span class="token comment">#一.加载和标准化数据</span><span class="token comment">#===========================</span><span class="token punctuation">(</span>train_images<span class="token punctuation">,</span> train_labels<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>test_images<span class="token punctuation">,</span> test_labels<span class="token punctuation">)</span> <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>cifar10<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>train_images<span class="token punctuation">,</span> test_images <span class="token operator">=</span> train_images <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> test_images <span class="token operator">/</span> <span class="token number">255.0</span><span class="token comment">#===========================</span><span class="token comment">#二.构建、编译模型</span><span class="token comment">#===========================</span>model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#卷积层 32个3*3的卷积核 激活函数relu输入形状32*32*3</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#池化层 2*2</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#卷积层 64个3*3的卷积核 激活函数relu</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#池化层 2*2</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#卷积层 64个3*3的卷积核 激活函数relu</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#展平</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#全连接层 64个神经元 激活函数relu</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#全连接层 10个神经元 激活函数softmax</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"softmax"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">"adam"</span><span class="token punctuation">,</span>              loss<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>SparseCategoricalCrossentropy<span class="token punctuation">(</span>from_logits<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"accuracy"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment">#===========================</span><span class="token comment">#三.训练模型</span><span class="token comment">#===========================</span>history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_images<span class="token punctuation">,</span> train_labels<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">40</span><span class="token punctuation">,</span>                    validation_data<span class="token operator">=</span><span class="token punctuation">(</span>test_images<span class="token punctuation">,</span> test_labels<span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">"accuracy"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"accuracy"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">"val_accuracy"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"val_accuracy"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Epoch"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"Accuracy"</span><span class="token punctuation">)</span><span class="token comment"># plt.ylim([0.0, 1])</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'model accuracy'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#===========================</span><span class="token comment">#四.评估模型</span><span class="token comment">#===========================</span>test_loss<span class="token punctuation">,</span> test_acc <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>test_images<span class="token punctuation">,</span> test_labels<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test accuracy:'</span><span class="token punctuation">,</span> test_acc<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h3><h4 id="简介-2"><a href="#简介-2" class="headerlink" title="简介"></a>简介</h4><p>​RNNs的目的使用来处理序列数据。在传统的神经网络模型中，是从输入层到隐含层再到输出层，层与层之间是全连接的，每层之间的节点是无连接的。但是这种普通的神经网络对于很多问题却无能无力。</p><p>​RNNs之所以称为循环神经网路，即一个序列当前的输出与前面的输出也有关。具体的表现形式为网络会对前面的信息进行记忆并应用于当前输出的计算中，即隐藏层之间的节点不再无连接而是有连接的，并且隐藏层的输入不仅包括输入层的输出还包括上一时刻隐藏层的输出。理论上，RNNs能够对任何长度的序列数据进行处理。但是在实践中，为了降低复杂性往往假设当前的状态只与前面的几个状态相关，下图便是一个典型的RNNs： </p><p><img src="https://img-blog.csdn.net/20150921225357857" alt="img"></p><h4 id="模型说明-2"><a href="#模型说明-2" class="headerlink" title="模型说明"></a>模型说明</h4><p>​创建模型的代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Bidirectional<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Bidirectional<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">"adam"</span><span class="token punctuation">,</span>              loss<span class="token operator">=</span><span class="token string">"sparse_categorical_crossentropy"</span><span class="token punctuation">,</span>              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'sparse_categorical_accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​我创建了一个 Keras中的Sequential 模型，包含了多个网络层：</p><ul><li>模型的第一层是一个双向 LSTM 层，它具有 32 个神经元，并返回序列。</li><li>模型的第二层是一个双向 LSTM 层，它也具有 32 个神经元。</li><li>第三层是一个池化层，它可以防止过拟合。</li><li>第四层是一个 Flatten 层，它把输入展平。</li><li>第五层是一个全连接层，它具有 128 个神经元和 ReLU 激活函数。</li><li>第六层是一个池化层，防止过拟合。</li><li>第七层是一个全连接层，它具有 64 个神经元和 ReLU 激活函数。</li><li>最后一层是一个全连接层，它具有 10 个神经元，激活函数为 softmax 。</li></ul><h4 id="训练模型-2"><a href="#训练模型-2" class="headerlink" title="训练模型"></a>训练模型</h4><p>​将epochs设置为10，在 50000 个样本上进行训练，在 10000 个样本上进行验证，代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_images<span class="token punctuation">,</span> train_labels<span class="token punctuation">,</span> batch<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>                    validation_data<span class="token operator">=</span><span class="token punctuation">(</span>test_images<span class="token punctuation">,</span> test_labels<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>![img_v2_eaf8d3c3-da3d-424e-a759-5b43f838492g](/Users/zhangxiaoni/Library/Containers/com.bytedance.macos.feishu/Data/Library/Application Support/LarkShell/sdk_storage/407120424b82e9e84d5a9fe5984b53e7/resources/images/img_v2_eaf8d3c3-da3d-424e-a759-5b43f838492g.jpg)</p><p>​绘制出的图像如下；</p><img src="/Users/zhangxiaoni/Library/Containers/com.bytedance.macos.feishu/Data/Library/Application Support/LarkShell/sdk_storage/407120424b82e9e84d5a9fe5984b53e7/resources/images/img_v2_80be0f27-a53b-45a9-9658-d9b2eb8f6abg.jpg" alt="img_v2_80be0f27-a53b-45a9-9658-d9b2eb8f6abg" style="zoom:33%;"><h4 id="模型评估-2"><a href="#模型评估-2" class="headerlink" title="模型评估"></a>模型评估</h4><p>​模型在测试集上的准确率如下：</p><p>![img_v2_6d331709-f95a-4fd1-8010-865f4940bbeg](/Users/zhangxiaoni/Library/Containers/com.bytedance.macos.feishu/Data/Library/Application Support/LarkShell/sdk_storage/407120424b82e9e84d5a9fe5984b53e7/resources/images/img_v2_6d331709-f95a-4fd1-8010-865f4940bbeg.jpg)</p><h4 id="完整代码-2"><a href="#完整代码-2" class="headerlink" title="完整代码"></a>完整代码</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token comment">#===========================</span><span class="token comment">#一.加载和标准化数据</span><span class="token comment">#===========================</span><span class="token punctuation">(</span>train_images<span class="token punctuation">,</span> train_labels<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>test_images<span class="token punctuation">,</span> test_labels<span class="token punctuation">)</span> <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>cifar10<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>train_images<span class="token punctuation">,</span> test_images <span class="token operator">=</span> train_images <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> test_images <span class="token operator">/</span> <span class="token number">255.0</span><span class="token comment">#===========================</span><span class="token comment">#二.构建、编译模型</span><span class="token comment">#===========================</span>model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Bidirectional<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Bidirectional<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">"adam"</span><span class="token punctuation">,</span>              loss<span class="token operator">=</span><span class="token string">"sparse_categorical_crossentropy"</span><span class="token punctuation">,</span>              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'sparse_categorical_accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment">#===========================</span><span class="token comment">#三.训练模型</span><span class="token comment">#===========================</span>history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_images<span class="token punctuation">,</span> train_labels<span class="token punctuation">,</span> batch<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>                    validation_data<span class="token operator">=</span><span class="token punctuation">(</span>test_images<span class="token punctuation">,</span> test_labels<span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">"accuracy"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"accuracy"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">"val_accuracy"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"val_accuracy"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Epoch"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"Accuracy"</span><span class="token punctuation">)</span><span class="token comment"># plt.ylim([0.0, 1])</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'model accuracy'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#===========================</span><span class="token comment">#四.评估模型</span><span class="token comment">#===========================</span>test_loss<span class="token punctuation">,</span> test_acc <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>test_images<span class="token punctuation">,</span> test_labels<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test accuracy:'</span><span class="token punctuation">,</span> test_acc<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="机器学习算法"><a href="#机器学习算法" class="headerlink" title="机器学习算法"></a>机器学习算法</h2><h3 id="SVM算法"><a href="#SVM算法" class="headerlink" title="SVM算法"></a>SVM算法</h3><h4 id="简介-3"><a href="#简介-3" class="headerlink" title="简介"></a>简介</h4><p>​支持向量机（SVM）是一种广泛使用的监督学习算法，可用于分类和回归。它的工作原理是找到一条决策边界，将不同类别的数据尽可能分开。</p><p>​使用 SVM 分类 CIFAR-10 数据集的一般步骤如下：</p><ul><li>准备数据：将 CIFAR-10 数据集加载到 Python 中，并将其转换为适合模型使用的格式。可能需要对图像进行预处理，例如缩放或归一化。</li><li>选择 SVM 模型：选择要使用的 SVM 模型（例如线性 SVM 或非线性 SVM）和决策函数。</li><li>训练模型：使用训练数据训练 SVM 模型。</li><li>评估模型：使用测试数据评估SVM模型</li></ul><h4 id="模型构建"><a href="#模型构建" class="headerlink" title="模型构建"></a>模型构建</h4><p>​我构建的svm模型如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">svm</span><span class="token punctuation">(</span>c<span class="token punctuation">,</span> kernel<span class="token operator">=</span><span class="token string">'poly'</span><span class="token punctuation">,</span> degree<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> kernel <span class="token operator">==</span> <span class="token string">'poly'</span><span class="token punctuation">:</span>        svm_model <span class="token operator">=</span> SVC<span class="token punctuation">(</span>kernel<span class="token operator">=</span>kernel<span class="token punctuation">,</span> degree<span class="token operator">=</span>degree<span class="token punctuation">,</span> C<span class="token operator">=</span>c<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        svm_model <span class="token operator">=</span> SVC<span class="token punctuation">(</span>kernel<span class="token operator">=</span>kernel<span class="token punctuation">,</span> C<span class="token operator">=</span>c<span class="token punctuation">)</span>    svm_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>    <span class="token keyword">return</span> svm_model<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​我使用 sklearn 中的 SVC，构建 SVM 分类模型，令核函数的默认参数为 poly 多项式核函数。</p><h4 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h4><p>当惩罚参数C为5时，模型的训练结果如下：</p><p>![img_v2_20b0e3f9-349d-4fb8-aa81-24387d864bfg](/Users/zhangxiaoni/Library/Containers/com.bytedance.macos.feishu/Data/Library/Application Support/LarkShell/sdk_storage/407120424b82e9e84d5a9fe5984b53e7/resources/images/img_v2_20b0e3f9-349d-4fb8-aa81-24387d864bfg.jpg)</p><p>此时模型在测试集上的正确率为0.47</p><p>手动调节惩罚参数C，模型在测试集上的正确率也在不断变化如下：</p><table><thead><tr><th>C</th><th>1</th><th>3</th><th>5</th><th>7</th><th>10</th><th>50</th><th>100</th></tr></thead><tbody><tr><td>acc</td><td>0.42</td><td>0.45</td><td>0.47</td><td>0.38</td><td>0.43</td><td>0.41</td><td>0.41</td></tr></tbody></table><p>从上表可知，当C=5时正确率最高。</p><h4 id="模型评估-3"><a href="#模型评估-3" class="headerlink" title="模型评估"></a>模型评估</h4><p>模型在训练集和测试集上的准确率如下：</p><p>![img_v2_b2e15a6d-7ab1-4d11-b9fb-a207b972160g](/Users/zhangxiaoni/Library/Containers/com.bytedance.macos.feishu/Data/Library/Application Support/LarkShell/sdk_storage/407120424b82e9e84d5a9fe5984b53e7/resources/images/img_v2_b2e15a6d-7ab1-4d11-b9fb-a207b972160g.jpg)</p><p>模型在测试集上的表现如下：</p><p>![img_v2_20b0e3f9-349d-4fb8-aa81-24387d864bfg](/Users/zhangxiaoni/Library/Containers/com.bytedance.macos.feishu/Data/Library/Application Support/LarkShell/sdk_storage/407120424b82e9e84d5a9fe5984b53e7/resources/images/img_v2_20b0e3f9-349d-4fb8-aa81-24387d864bfg.jpg)</p><h4 id="完整代码-3"><a href="#完整代码-3" class="headerlink" title="完整代码"></a>完整代码</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> make_pipeline<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler<span class="token punctuation">,</span> MinMaxScaler<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVC<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> GridSearchCV<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> classification_report<span class="token keyword">from</span> time <span class="token keyword">import</span> time<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf<span class="token keyword">from</span> tensorflow <span class="token keyword">import</span> keras<span class="token comment">#===========================</span><span class="token comment">#加载和标准化数据</span><span class="token comment">#===========================</span><span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span> <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>cifar10<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>X_train <span class="token operator">=</span> X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10000</span><span class="token punctuation">]</span>y_train <span class="token operator">=</span> y_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10000</span><span class="token punctuation">]</span>X_test <span class="token operator">=</span> X_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2000</span><span class="token punctuation">]</span>y_test <span class="token operator">=</span> y_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2000</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>X_test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>X_train_length <span class="token operator">=</span> X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">*</span> X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>X_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X_train_length<span class="token punctuation">)</span>X_test <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X_test<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X_train_length<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>X_test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token comment">#===========================</span><span class="token comment">#构建、编译模型</span><span class="token comment">#===========================</span><span class="token keyword">def</span> <span class="token function">svm</span><span class="token punctuation">(</span>c<span class="token punctuation">,</span> kernel<span class="token operator">=</span><span class="token string">'poly'</span><span class="token punctuation">,</span> degree<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> kernel <span class="token operator">==</span> <span class="token string">'poly'</span><span class="token punctuation">:</span>        svm_model <span class="token operator">=</span> SVC<span class="token punctuation">(</span>kernel<span class="token operator">=</span>kernel<span class="token punctuation">,</span> degree<span class="token operator">=</span>degree<span class="token punctuation">,</span> C<span class="token operator">=</span>c<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        svm_model <span class="token operator">=</span> SVC<span class="token punctuation">(</span>kernel<span class="token operator">=</span>kernel<span class="token punctuation">,</span> C<span class="token operator">=</span>c<span class="token punctuation">)</span>    svm_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>    <span class="token keyword">return</span> svm_model<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    kernel <span class="token operator">=</span> <span class="token string">'rbf'</span>    c <span class="token operator">=</span> <span class="token number">5.0</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'%s(C=%.1f):'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>kernel<span class="token punctuation">,</span> c<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment">#===========================</span>    <span class="token comment">#训练模型</span>    <span class="token comment">#===========================</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'正在训练...'</span><span class="token punctuation">)</span>    start <span class="token operator">=</span> time<span class="token punctuation">(</span><span class="token punctuation">)</span>    model <span class="token operator">=</span> svm<span class="token punctuation">(</span>c<span class="token punctuation">,</span> kernel<span class="token operator">=</span>kernel<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练完成所需时间： %.2fs'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment">#===========================</span>    <span class="token comment">#评估模型</span>    <span class="token comment">#===========================</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Train accuracy: %.2f'</span> <span class="token operator">%</span> model<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test accuracy: %.2f'</span> <span class="token operator">%</span> model<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># 测试集</span>    y_pred <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>classification_report<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">,</span> digits<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="KNN算法"><a href="#KNN算法" class="headerlink" title="KNN算法"></a>KNN算法</h3><h4 id="简介-4"><a href="#简介-4" class="headerlink" title="简介"></a>简介</h4><p>​KNN算法的实现步骤如下：</p><ul><li><p>计算待分类的测试数据的特征向量与已知类别的训练样本的特征向量的欧氏距离。距离公式为：</p><img src="/Users/zhangxiaoni/Library/Application Support/typora-user-images/image-20230115011443638.png" alt="image-20230115011443638" style="zoom:50%;"></li><li><p>将距离从小到大排序。</p></li><li><p>去前k个值并统计k个值中每个类别出现的频数。</p></li><li><p>频数最大的训练样本的类别即为测试样本的与预测类别。</p></li></ul><h4 id="模型构建-1"><a href="#模型构建-1" class="headerlink" title="模型构建"></a>模型构建</h4><p>​调用 sklearn 中的 KNeighborsClassifier，设置 n_neighbors=10，即临近的节点数量 为 10。构建模型的代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">knn <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="模型训练-1"><a href="#模型训练-1" class="headerlink" title="模型训练"></a>模型训练</h4><p>模型训练过程如下：</p><p>![img_v2_aa0a16c1-2447-4fb2-8528-fbfffd3a832g](/Users/zhangxiaoni/Library/Containers/com.bytedance.macos.feishu/Data/Library/Application Support/LarkShell/sdk_storage/407120424b82e9e84d5a9fe5984b53e7/resources/images/img_v2_aa0a16c1-2447-4fb2-8528-fbfffd3a832g.jpg)</p><h4 id="模型评估-4"><a href="#模型评估-4" class="headerlink" title="模型评估"></a>模型评估</h4><p>模型在训练集和测试集上的准确率如下：</p><img src="/Users/zhangxiaoni/Library/Containers/com.bytedance.macos.feishu/Data/Library/Application Support/LarkShell/sdk_storage/407120424b82e9e84d5a9fe5984b53e7/resources/images/img_v2_789e6f0a-9b73-4e15-849a-abca1faabf4g.jpg" alt="img_v2_789e6f0a-9b73-4e15-849a-abca1faabf4g" style="zoom: 67%;"><h4 id="完整代码-4"><a href="#完整代码-4" class="headerlink" title="完整代码"></a>完整代码</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> time <span class="token keyword">import</span> time<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf<span class="token comment">#===========================</span><span class="token comment">#加载和标准化数据</span><span class="token comment">#===========================</span><span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span> <span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>cifar10<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>X_test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>X_train_length <span class="token operator">=</span> X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">*</span> X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>X_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X_train_length<span class="token punctuation">)</span>X_test <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X_test<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X_train_length<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>X_test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'training...'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"neighbors_settings:"</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>start <span class="token operator">=</span> time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#===========================</span><span class="token comment">#构建、编译模型</span><span class="token comment">#===========================</span>knn <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token comment">#===========================</span><span class="token comment">#训练模型</span><span class="token comment">#===========================</span>knn<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token comment">#===========================</span><span class="token comment">#评估模型</span><span class="token comment">#===========================</span>train_acc <span class="token operator">=</span> knn<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>test_acc <span class="token operator">=</span> knn<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'training finished in %.2fs'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'train_accuracy:'</span><span class="token punctuation">,</span> train_acc<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'test_acccuacy:'</span><span class="token punctuation">,</span> test_acc<span class="token punctuation">)</span>y_pred <span class="token operator">=</span> knn<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>classification_report<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">,</span> digits<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="结果对比分析"><a href="#结果对比分析" class="headerlink" title="结果对比分析"></a>结果对比分析</h2><h3 id="可视化图像对比"><a href="#可视化图像对比" class="headerlink" title="可视化图像对比"></a>可视化图像对比</h3><p>​不同深度神经网络的表现对比如下：</p><table><thead><tr><th>深度神经网络</th><th>acc</th></tr></thead><tbody><tr><td>全连接网络</td><td><img src="/Users/zhangxiaoni/Library/Containers/com.bytedance.macos.feishu/Data/Library/Application Support/LarkShell/sdk_storage/407120424b82e9e84d5a9fe5984b53e7/resources/images/img_v2_a4ac7ee4-f1da-47fa-b870-c0efba09a04g.jpg" alt="img_v2_a4ac7ee4-f1da-47fa-b870-c0efba09a04g" style="zoom:33%;"></td></tr><tr><td>卷积神经网络</td><td><img src="/Users/zhangxiaoni/Library/Containers/com.bytedance.macos.feishu/Data/Library/Application Support/LarkShell/sdk_storage/407120424b82e9e84d5a9fe5984b53e7/resources/images/img_v2_bed4c8ec-8e37-4ffd-8839-abcb5183df1g.jpg" alt="img_v2_bed4c8ec-8e37-4ffd-8839-abcb5183df1g" style="zoom:33%;"></td></tr><tr><td>循环神经网络</td><td><img src="/Users/zhangxiaoni/Library/Containers/com.bytedance.macos.feishu/Data/Library/Application Support/LarkShell/sdk_storage/407120424b82e9e84d5a9fe5984b53e7/resources/images/img_v2_80be0f27-a53b-45a9-9658-d9b2eb8f6abg.jpg" alt="img_v2_80be0f27-a53b-45a9-9658-d9b2eb8f6abg" style="zoom:33%;"></td></tr></tbody></table><p>​从以上结果可知，深度神经网络中，模型适配度：卷积神经网络&gt;全连接网络&gt;循环神经网络</p><h3 id="acc对比"><a href="#acc对比" class="headerlink" title="acc对比"></a>acc对比</h3><p>​不同算法在测试集上的准确率如下：</p><table><thead><tr><th>算法</th><th>accuracy</th></tr></thead><tbody><tr><td>全连接网络</td><td>0.6424</td></tr><tr><td>卷积神经网络</td><td>0.6864</td></tr><tr><td>循环神经网络</td><td>0.4893</td></tr><tr><td>SVM算法</td><td>0.47</td></tr><tr><td>KNN算法</td><td>0.3386</td></tr></tbody></table><p>​从以上结果可知，本实验所选取的方案中，模型适配度：卷积神经网络&gt;全连接网络&gt;循环神经网络&gt;SVM算法&gt;KNN算法</p><p>​可以直观看出，本实验中深度学习模型效果好于机器学习模型。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能导论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> S5课上 </tag>
            
            <tag> 实验报告 </tag>
            
            <tag> 人工智能导论 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>blog 说明</title>
      <link href="/2021/09/07/hello-world/"/>
      <url>/2021/09/07/hello-world/</url>
      
        <content type="html"><![CDATA[<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo generatehexo g<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo deployhexo d<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="hexo常用命令"><a href="#hexo常用命令" class="headerlink" title="hexo常用命令"></a>hexo常用命令</h2><pre class="line-numbers language-text" data-language="text"><code class="language-text">hexo new "name"       # 新建文章hexo new page "name"  # 新建页面hexo g                # 生成页面hexo d                # 部署hexo g -d             # 生成页面并部署hexo s                # 本地预览hexo clean            # 清除缓存和已生成的静态文件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Font-matter"><a href="#Font-matter" class="headerlink" title="Font-matter"></a>Font-matter</h2><table><thead><tr><th>配置选项</th><th>默认值</th><th>描述</th></tr></thead><tbody><tr><td>title</td><td><code>Markdown</code> 的文件标题</td><td>文章标题，强烈建议填写此选项</td></tr><tr><td>date</td><td>文件创建时的日期时间</td><td>发布时间，强烈建议填写此选项，且最好保证全局唯一</td></tr><tr><td>author</td><td>根 <code>_config.yml</code> 中的 <code>author</code></td><td>文章作者</td></tr><tr><td>img</td><td><code>featureImages</code> 中的某个值</td><td>文章特征图，推荐使用图床(腾讯云、七牛云、又拍云等)来做图片的路径.如: <code>http://xxx.com/xxx.jpg</code></td></tr><tr><td>top</td><td><code>true</code></td><td>推荐文章（文章是否置顶），如果 <code>top</code> 值为 <code>true</code>，则会作为首页推荐文章</td></tr><tr><td>cover</td><td><code>false</code></td><td><code>v1.0.2</code>版本新增，表示该文章是否需要加入到首页轮播封面中</td></tr><tr><td>coverImg</td><td>无</td><td><code>v1.0.2</code>版本新增，表示该文章在首页轮播封面需要显示的图片路径，如果没有，则默认使用文章的特色图片</td></tr><tr><td>password</td><td>无</td><td>文章阅读密码，如果要对文章设置阅读验证密码的话，就可以设置 <code>password</code> 的值，该值必须是用 <code>SHA256</code> 加密后的密码，防止被他人识破。前提是在主题的 <code>config.yml</code> 中激活了 <code>verifyPassword</code> 选项</td></tr><tr><td>toc</td><td><code>true</code></td><td>是否开启 TOC，可以针对某篇文章单独关闭 TOC 的功能。前提是在主题的 <code>config.yml</code> 中激活了 <code>toc</code> 选项</td></tr><tr><td>mathjax</td><td><code>false</code></td><td>是否开启数学公式支持 ，本文章是否开启 <code>mathjax</code>，且需要在主题的 <code>_config.yml</code> 文件中也需要开启才行</td></tr><tr><td>summary</td><td>无</td><td>文章摘要，自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要</td></tr><tr><td>categories</td><td>无</td><td>文章分类，本主题的分类表示宏观上大的分类，只建议一篇文章一个分类</td></tr><tr><td>tags</td><td>无</td><td>文章标签，一篇文章可以多个标签</td></tr><tr><td>keywords</td><td>文章标题</td><td>文章关键字，SEO 时需要</td></tr><tr><td>reprintPolicy</td><td>cc_by</td><td>文章转载规则， 可以是 cc_by, cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd, cc_by_nc_sa, cc0, noreprint 或 pay 中的一个</td></tr></tbody></table><h3 id="最简示例"><a href="#最简示例" class="headerlink" title="最简示例"></a>最简示例</h3><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> typora<span class="token punctuation">-</span>vue<span class="token punctuation">-</span>theme主题介绍<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-07 09:25:00</span><span class="token punctuation">---</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="最全示例"><a href="#最全示例" class="headerlink" title="最全示例"></a>最全示例</h3><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> typora<span class="token punctuation">-</span>vue<span class="token punctuation">-</span>theme主题介绍<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-07 09:25:00</span><span class="token key atrule">author</span><span class="token punctuation">:</span> 赵奇<span class="token key atrule">img</span><span class="token punctuation">:</span> /source/images/xxx.jpg<span class="token key atrule">top</span><span class="token punctuation">:</span> <span class="token boolean important">true</span><span class="token key atrule">cover</span><span class="token punctuation">:</span> <span class="token boolean important">true</span><span class="token key atrule">coverImg</span><span class="token punctuation">:</span> /images/1.jpg<span class="token key atrule">password</span><span class="token punctuation">:</span> 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92<span class="token key atrule">toc</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">mathjax</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">summary</span><span class="token punctuation">:</span> 这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要<span class="token key atrule">categories</span><span class="token punctuation">:</span> Markdown<span class="token key atrule">tags</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> Typora  <span class="token punctuation">-</span> Markdown<span class="token punctuation">---</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="文章分类"><a href="#文章分类" class="headerlink" title="文章分类"></a>文章分类</h2><p>每篇博文都是按照 <strong>“科目/项目-名字”</strong> 的形式命名的。其中归类是按照 <strong>“科目/项目”</strong> 进行归类</p><p>对于标签，呈现 <strong>“2 + n”</strong> 的结构，<strong>2</strong> 指的是每个博文都有一个“科目/项目”标签，一个“时间标签”，每个学期都会分为“课上”，“复习”，“假期”3个标签，用于细化时间节点。<strong>n</strong> 文章的属性，应该有以下几种：</p><table><thead><tr><th align="left">类别</th><th align="left">解释</th></tr></thead><tbody><tr><td align="left">工具总结</td><td align="left">包括数学工具，办公工具，各种软件的使用方法</td></tr><tr><td align="left">知识总结</td><td align="left">是对所学内容的系统梳理，这种文章应该都是比较系统、全面，但是也比较死板</td></tr><tr><td align="left">直观理解</td><td align="left">这方面记录了很多直观化的知识，但是相应的，也比较跳脱，不严谨</td></tr><tr><td align="left">实验报告</td><td align="left">这是课程实验的一些总结报告</td></tr><tr><td align="left">吃喝玩乐</td><td align="left">生活记录</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> blog说明 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> blog 说明 </tag>
            
            <tag> S6课上 </tag>
            
            <tag> 工具使用 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
